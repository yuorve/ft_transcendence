import {
  EffectWrapper
} from "./chunk-2MEDEKMN.js";
import {
  PostProcessManager,
  RenderingManager,
  SmartArray
} from "./chunk-MCEHMZHU.js";
import {
  PerfCounter
} from "./chunk-LJSODA3L.js";
import {
  BaseTexture,
  Texture
} from "./chunk-KTDED253.js";
import {
  SerializationHelper
} from "./chunk-GY7MF23I.js";
import {
  __decorate,
  serialize,
  serializeAsColor4
} from "./chunk-3FJRTHLS.js";
import {
  Color3
} from "./chunk-YZQDNKZM.js";
import {
  Matrix,
  TmpVectors,
  ToLinearSpace,
  Vector2,
  Vector3,
  _ObserveArray
} from "./chunk-NSQZ6PEP.js";
import {
  HasStencilAspect,
  ThinEngine,
  WebGLDataBuffer,
  WebGLHardwareTexture
} from "./chunk-GPK3H7XW.js";
import {
  GetClass,
  RegisterClass
} from "./chunk-LMH7SWDS.js";
import {
  Clamp
} from "./chunk-X4PSP3XC.js";
import {
  AbstractEngine,
  Effect,
  FloorPOT,
  GetExponentOfTwo,
  InternalTexture,
  IsExponentOfTwo,
  NearestPOT,
  _retryWithInterval,
  allocateAndCopyTypedBuffer
} from "./chunk-M4GEDTPQ.js";
import {
  IsDocumentAvailable,
  IsWindowObjectExist,
  PrecisionDate
} from "./chunk-AZNEH5GV.js";
import {
  EngineStore
} from "./chunk-AYMFJBP3.js";
import {
  Observable
} from "./chunk-GWFZRJMO.js";
import {
  Logger
} from "./chunk-OJJXGLTO.js";

// node_modules/@babylonjs/core/Maths/sphericalPolynomial.js
var SH3ylmBasisConstants = [
  Math.sqrt(1 / (4 * Math.PI)),
  // l00
  -Math.sqrt(3 / (4 * Math.PI)),
  // l1_1
  Math.sqrt(3 / (4 * Math.PI)),
  // l10
  -Math.sqrt(3 / (4 * Math.PI)),
  // l11
  Math.sqrt(15 / (4 * Math.PI)),
  // l2_2
  -Math.sqrt(15 / (4 * Math.PI)),
  // l2_1
  Math.sqrt(5 / (16 * Math.PI)),
  // l20
  -Math.sqrt(15 / (4 * Math.PI)),
  // l21
  Math.sqrt(15 / (16 * Math.PI))
  // l22
];
var SH3ylmBasisTrigonometricTerms = [
  () => 1,
  // l00
  (direction) => direction.y,
  // l1_1
  (direction) => direction.z,
  // l10
  (direction) => direction.x,
  // l11
  (direction) => direction.x * direction.y,
  // l2_2
  (direction) => direction.y * direction.z,
  // l2_1
  (direction) => 3 * direction.z * direction.z - 1,
  // l20
  (direction) => direction.x * direction.z,
  // l21
  (direction) => direction.x * direction.x - direction.y * direction.y
  // l22
];
var applySH3 = (lm, direction) => {
  return SH3ylmBasisConstants[lm] * SH3ylmBasisTrigonometricTerms[lm](direction);
};
var SHCosKernelConvolution = [Math.PI, 2 * Math.PI / 3, 2 * Math.PI / 3, 2 * Math.PI / 3, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4, Math.PI / 4];
var SphericalHarmonics = class _SphericalHarmonics {
  constructor() {
    this.preScaled = false;
    this.l00 = Vector3.Zero();
    this.l1_1 = Vector3.Zero();
    this.l10 = Vector3.Zero();
    this.l11 = Vector3.Zero();
    this.l2_2 = Vector3.Zero();
    this.l2_1 = Vector3.Zero();
    this.l20 = Vector3.Zero();
    this.l21 = Vector3.Zero();
    this.l22 = Vector3.Zero();
  }
  /**
   * Adds a light to the spherical harmonics
   * @param direction the direction of the light
   * @param color the color of the light
   * @param deltaSolidAngle the delta solid angle of the light
   */
  addLight(direction, color, deltaSolidAngle) {
    TmpVectors.Vector3[0].set(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    const c = TmpVectors.Vector3[1];
    colorVector.scaleToRef(deltaSolidAngle, c);
    c.scaleToRef(applySH3(0, direction), TmpVectors.Vector3[2]);
    this.l00.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(1, direction), TmpVectors.Vector3[2]);
    this.l1_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(2, direction), TmpVectors.Vector3[2]);
    this.l10.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(3, direction), TmpVectors.Vector3[2]);
    this.l11.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(4, direction), TmpVectors.Vector3[2]);
    this.l2_2.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(5, direction), TmpVectors.Vector3[2]);
    this.l2_1.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(6, direction), TmpVectors.Vector3[2]);
    this.l20.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(7, direction), TmpVectors.Vector3[2]);
    this.l21.addInPlace(TmpVectors.Vector3[2]);
    c.scaleToRef(applySH3(8, direction), TmpVectors.Vector3[2]);
    this.l22.addInPlace(TmpVectors.Vector3[2]);
  }
  /**
   * Scales the spherical harmonics by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.l00.scaleInPlace(scale);
    this.l1_1.scaleInPlace(scale);
    this.l10.scaleInPlace(scale);
    this.l11.scaleInPlace(scale);
    this.l2_2.scaleInPlace(scale);
    this.l2_1.scaleInPlace(scale);
    this.l20.scaleInPlace(scale);
    this.l21.scaleInPlace(scale);
    this.l22.scaleInPlace(scale);
  }
  /**
   * Convert from incident radiance (Li) to irradiance (E) by applying convolution with the cosine-weighted hemisphere.
   *
   * ```
   * E_lm = A_l * L_lm
   * ```
   *
   * In spherical harmonics this convolution amounts to scaling factors for each frequency band.
   * This corresponds to equation 5 in "An Efficient Representation for Irradiance Environment Maps", where
   * the scaling factors are given in equation 9.
   */
  convertIncidentRadianceToIrradiance() {
    this.l00.scaleInPlace(SHCosKernelConvolution[0]);
    this.l1_1.scaleInPlace(SHCosKernelConvolution[1]);
    this.l10.scaleInPlace(SHCosKernelConvolution[2]);
    this.l11.scaleInPlace(SHCosKernelConvolution[3]);
    this.l2_2.scaleInPlace(SHCosKernelConvolution[4]);
    this.l2_1.scaleInPlace(SHCosKernelConvolution[5]);
    this.l20.scaleInPlace(SHCosKernelConvolution[6]);
    this.l21.scaleInPlace(SHCosKernelConvolution[7]);
    this.l22.scaleInPlace(SHCosKernelConvolution[8]);
  }
  /**
   * Convert from irradiance to outgoing radiance for Lambertian BDRF, suitable for efficient shader evaluation.
   *
   * ```
   * L = (1/pi) * E * rho
   * ```
   *
   * This is done by an additional scale by 1/pi, so is a fairly trivial operation but important conceptually.
   */
  convertIrradianceToLambertianRadiance() {
    this.scaleInPlace(1 / Math.PI);
  }
  /**
   * Integrates the reconstruction coefficients directly in to the SH preventing further
   * required operations at run time.
   *
   * This is simply done by scaling back the SH with Ylm constants parameter.
   * The trigonometric part being applied by the shader at run time.
   */
  preScaleForRendering() {
    this.preScaled = true;
    this.l00.scaleInPlace(SH3ylmBasisConstants[0]);
    this.l1_1.scaleInPlace(SH3ylmBasisConstants[1]);
    this.l10.scaleInPlace(SH3ylmBasisConstants[2]);
    this.l11.scaleInPlace(SH3ylmBasisConstants[3]);
    this.l2_2.scaleInPlace(SH3ylmBasisConstants[4]);
    this.l2_1.scaleInPlace(SH3ylmBasisConstants[5]);
    this.l20.scaleInPlace(SH3ylmBasisConstants[6]);
    this.l21.scaleInPlace(SH3ylmBasisConstants[7]);
    this.l22.scaleInPlace(SH3ylmBasisConstants[8]);
  }
  /**
   * update the spherical harmonics coefficients from the given array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromArray(data) {
    Vector3.FromArrayToRef(data[0], 0, this.l00);
    Vector3.FromArrayToRef(data[1], 0, this.l1_1);
    Vector3.FromArrayToRef(data[2], 0, this.l10);
    Vector3.FromArrayToRef(data[3], 0, this.l11);
    Vector3.FromArrayToRef(data[4], 0, this.l2_2);
    Vector3.FromArrayToRef(data[5], 0, this.l2_1);
    Vector3.FromArrayToRef(data[6], 0, this.l20);
    Vector3.FromArrayToRef(data[7], 0, this.l21);
    Vector3.FromArrayToRef(data[8], 0, this.l22);
    return this;
  }
  /**
   * update the spherical harmonics coefficients from the given floats array
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics (this)
   */
  updateFromFloatsArray(data) {
    Vector3.FromFloatsToRef(data[0], data[1], data[2], this.l00);
    Vector3.FromFloatsToRef(data[3], data[4], data[5], this.l1_1);
    Vector3.FromFloatsToRef(data[6], data[7], data[8], this.l10);
    Vector3.FromFloatsToRef(data[9], data[10], data[11], this.l11);
    Vector3.FromFloatsToRef(data[12], data[13], data[14], this.l2_2);
    Vector3.FromFloatsToRef(data[15], data[16], data[17], this.l2_1);
    Vector3.FromFloatsToRef(data[18], data[19], data[20], this.l20);
    Vector3.FromFloatsToRef(data[21], data[22], data[23], this.l21);
    Vector3.FromFloatsToRef(data[24], data[25], data[26], this.l22);
    return this;
  }
  /**
   * Constructs a spherical harmonics from an array.
   * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
   * @returns the spherical harmonics
   */
  static FromArray(data) {
    const sh = new _SphericalHarmonics();
    return sh.updateFromArray(data);
  }
  // Keep for references.
  /**
   * Gets the spherical harmonics from polynomial
   * @param polynomial the spherical polynomial
   * @returns the spherical harmonics
   */
  static FromPolynomial(polynomial) {
    const result = new _SphericalHarmonics();
    result.l00 = polynomial.xx.scale(0.376127).add(polynomial.yy.scale(0.376127)).add(polynomial.zz.scale(0.376126));
    result.l1_1 = polynomial.y.scale(0.977204);
    result.l10 = polynomial.z.scale(0.977204);
    result.l11 = polynomial.x.scale(0.977204);
    result.l2_2 = polynomial.xy.scale(1.16538);
    result.l2_1 = polynomial.yz.scale(1.16538);
    result.l20 = polynomial.zz.scale(1.34567).subtract(polynomial.xx.scale(0.672834)).subtract(polynomial.yy.scale(0.672834));
    result.l21 = polynomial.zx.scale(1.16538);
    result.l22 = polynomial.xx.scale(1.16538).subtract(polynomial.yy.scale(1.16538));
    result.l1_1.scaleInPlace(-1);
    result.l11.scaleInPlace(-1);
    result.l2_1.scaleInPlace(-1);
    result.l21.scaleInPlace(-1);
    result.scaleInPlace(Math.PI);
    return result;
  }
};
var SphericalPolynomial = class _SphericalPolynomial {
  constructor() {
    this.x = Vector3.Zero();
    this.y = Vector3.Zero();
    this.z = Vector3.Zero();
    this.xx = Vector3.Zero();
    this.yy = Vector3.Zero();
    this.zz = Vector3.Zero();
    this.xy = Vector3.Zero();
    this.yz = Vector3.Zero();
    this.zx = Vector3.Zero();
  }
  /**
   * The spherical harmonics used to create the polynomials.
   */
  get preScaledHarmonics() {
    if (!this._harmonics) {
      this._harmonics = SphericalHarmonics.FromPolynomial(this);
    }
    if (!this._harmonics.preScaled) {
      this._harmonics.preScaleForRendering();
    }
    return this._harmonics;
  }
  /**
   * Adds an ambient color to the spherical polynomial
   * @param color the color to add
   */
  addAmbient(color) {
    TmpVectors.Vector3[0].copyFromFloats(color.r, color.g, color.b);
    const colorVector = TmpVectors.Vector3[0];
    this.xx.addInPlace(colorVector);
    this.yy.addInPlace(colorVector);
    this.zz.addInPlace(colorVector);
  }
  /**
   * Scales the spherical polynomial by the given amount
   * @param scale the amount to scale
   */
  scaleInPlace(scale) {
    this.x.scaleInPlace(scale);
    this.y.scaleInPlace(scale);
    this.z.scaleInPlace(scale);
    this.xx.scaleInPlace(scale);
    this.yy.scaleInPlace(scale);
    this.zz.scaleInPlace(scale);
    this.yz.scaleInPlace(scale);
    this.zx.scaleInPlace(scale);
    this.xy.scaleInPlace(scale);
  }
  /**
   * Updates the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  updateFromHarmonics(harmonics) {
    this._harmonics = harmonics;
    this.x.copyFrom(harmonics.l11);
    this.x.scaleInPlace(1.02333).scaleInPlace(-1);
    this.y.copyFrom(harmonics.l1_1);
    this.y.scaleInPlace(1.02333).scaleInPlace(-1);
    this.z.copyFrom(harmonics.l10);
    this.z.scaleInPlace(1.02333);
    this.xx.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.247708);
    TmpVectors.Vector3[1].copyFrom(harmonics.l22).scaleInPlace(0.429043);
    this.xx.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).addInPlace(TmpVectors.Vector3[1]);
    this.yy.copyFrom(harmonics.l00);
    this.yy.scaleInPlace(0.886277).subtractInPlace(TmpVectors.Vector3[0]).subtractInPlace(TmpVectors.Vector3[1]);
    this.zz.copyFrom(harmonics.l00);
    TmpVectors.Vector3[0].copyFrom(harmonics.l20).scaleInPlace(0.495417);
    this.zz.scaleInPlace(0.886277).addInPlace(TmpVectors.Vector3[0]);
    this.yz.copyFrom(harmonics.l2_1);
    this.yz.scaleInPlace(0.858086).scaleInPlace(-1);
    this.zx.copyFrom(harmonics.l21);
    this.zx.scaleInPlace(0.858086).scaleInPlace(-1);
    this.xy.copyFrom(harmonics.l2_2);
    this.xy.scaleInPlace(0.858086);
    this.scaleInPlace(1 / Math.PI);
    return this;
  }
  /**
   * Gets the spherical polynomial from harmonics
   * @param harmonics the spherical harmonics
   * @returns the spherical polynomial
   */
  static FromHarmonics(harmonics) {
    const result = new _SphericalPolynomial();
    return result.updateFromHarmonics(harmonics);
  }
  /**
   * Constructs a spherical polynomial from an array.
   * @param data defines the 9x3 coefficients (x, y, z, xx, yy, zz, yz, zx, xy)
   * @returns the spherical polynomial
   */
  static FromArray(data) {
    const sp = new _SphericalPolynomial();
    Vector3.FromArrayToRef(data[0], 0, sp.x);
    Vector3.FromArrayToRef(data[1], 0, sp.y);
    Vector3.FromArrayToRef(data[2], 0, sp.z);
    Vector3.FromArrayToRef(data[3], 0, sp.xx);
    Vector3.FromArrayToRef(data[4], 0, sp.yy);
    Vector3.FromArrayToRef(data[5], 0, sp.zz);
    Vector3.FromArrayToRef(data[6], 0, sp.yz);
    Vector3.FromArrayToRef(data[7], 0, sp.zx);
    Vector3.FromArrayToRef(data[8], 0, sp.xy);
    return sp;
  }
};

// node_modules/@babylonjs/core/Misc/HighDynamicRange/cubemapToSphericalPolynomial.js
var FileFaceOrientation = class {
  constructor(name, worldAxisForNormal, worldAxisForFileX, worldAxisForFileY) {
    this.name = name;
    this.worldAxisForNormal = worldAxisForNormal;
    this.worldAxisForFileX = worldAxisForFileX;
    this.worldAxisForFileY = worldAxisForFileY;
  }
};
var CubeMapToSphericalPolynomialTools = class {
  /**
   * Converts a texture to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param texture The texture to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapTextureToSphericalPolynomial(texture) {
    var _a;
    if (!texture.isCube) {
      return null;
    }
    (_a = texture.getScene()) == null ? void 0 : _a.getEngine().flushFramebuffer();
    const size = texture.getSize().width;
    const rightPromise = texture.readPixels(0, void 0, void 0, false);
    const leftPromise = texture.readPixels(1, void 0, void 0, false);
    let upPromise;
    let downPromise;
    if (texture.isRenderTarget) {
      upPromise = texture.readPixels(3, void 0, void 0, false);
      downPromise = texture.readPixels(2, void 0, void 0, false);
    } else {
      upPromise = texture.readPixels(2, void 0, void 0, false);
      downPromise = texture.readPixels(3, void 0, void 0, false);
    }
    const frontPromise = texture.readPixels(4, void 0, void 0, false);
    const backPromise = texture.readPixels(5, void 0, void 0, false);
    const gammaSpace = texture.gammaSpace;
    const format = 5;
    let type = 0;
    if (texture.textureType == 1 || texture.textureType == 2) {
      type = 1;
    }
    return new Promise((resolve) => {
      Promise.all([leftPromise, rightPromise, upPromise, downPromise, frontPromise, backPromise]).then(([left, right, up, down, front, back]) => {
        const cubeInfo = {
          size,
          right,
          left,
          up,
          down,
          front,
          back,
          format,
          type,
          gammaSpace
        };
        resolve(this.ConvertCubeMapToSphericalPolynomial(cubeInfo));
      });
    });
  }
  /**
   * Compute the area on the unit sphere of the rectangle defined by (x,y) and the origin
   * See https://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/
   * @param x
   * @param y
   * @returns the area
   */
  static _AreaElement(x, y) {
    return Math.atan2(x * y, Math.sqrt(x * x + y * y + 1));
  }
  /**
   * Converts a cubemap to the according Spherical Polynomial data.
   * This extracts the first 3 orders only as they are the only one used in the lighting.
   *
   * @param cubeInfo The Cube map to extract the information from.
   * @returns The Spherical Polynomial data.
   */
  static ConvertCubeMapToSphericalPolynomial(cubeInfo) {
    const sphericalHarmonics = new SphericalHarmonics();
    let totalSolidAngle = 0;
    const du = 2 / cubeInfo.size;
    const dv = du;
    const halfTexel = 0.5 * du;
    const minUV = halfTexel - 1;
    for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
      const fileFace = this._FileFaces[faceIndex];
      const dataArray = cubeInfo[fileFace.name];
      let v = minUV;
      const stride = cubeInfo.format === 5 ? 4 : 3;
      for (let y = 0; y < cubeInfo.size; y++) {
        let u = minUV;
        for (let x = 0; x < cubeInfo.size; x++) {
          const worldDirection = fileFace.worldAxisForFileX.scale(u).add(fileFace.worldAxisForFileY.scale(v)).add(fileFace.worldAxisForNormal);
          worldDirection.normalize();
          const deltaSolidAngle = this._AreaElement(u - halfTexel, v - halfTexel) - this._AreaElement(u - halfTexel, v + halfTexel) - this._AreaElement(u + halfTexel, v - halfTexel) + this._AreaElement(u + halfTexel, v + halfTexel);
          let r = dataArray[y * cubeInfo.size * stride + x * stride + 0];
          let g = dataArray[y * cubeInfo.size * stride + x * stride + 1];
          let b = dataArray[y * cubeInfo.size * stride + x * stride + 2];
          if (isNaN(r)) {
            r = 0;
          }
          if (isNaN(g)) {
            g = 0;
          }
          if (isNaN(b)) {
            b = 0;
          }
          if (cubeInfo.type === 0) {
            r /= 255;
            g /= 255;
            b /= 255;
          }
          if (cubeInfo.gammaSpace) {
            r = Math.pow(Clamp(r), ToLinearSpace);
            g = Math.pow(Clamp(g), ToLinearSpace);
            b = Math.pow(Clamp(b), ToLinearSpace);
          }
          const max = this.MAX_HDRI_VALUE;
          if (this.PRESERVE_CLAMPED_COLORS) {
            const currentMax = Math.max(r, g, b);
            if (currentMax > max) {
              const factor = max / currentMax;
              r *= factor;
              g *= factor;
              b *= factor;
            }
          } else {
            r = Clamp(r, 0, max);
            g = Clamp(g, 0, max);
            b = Clamp(b, 0, max);
          }
          const color = new Color3(r, g, b);
          sphericalHarmonics.addLight(worldDirection, color, deltaSolidAngle);
          totalSolidAngle += deltaSolidAngle;
          u += du;
        }
        v += dv;
      }
    }
    const sphereSolidAngle = 4 * Math.PI;
    const facesProcessed = 6;
    const expectedSolidAngle = sphereSolidAngle * facesProcessed / 6;
    const correctionFactor = expectedSolidAngle / totalSolidAngle;
    sphericalHarmonics.scaleInPlace(correctionFactor);
    sphericalHarmonics.convertIncidentRadianceToIrradiance();
    sphericalHarmonics.convertIrradianceToLambertianRadiance();
    return SphericalPolynomial.FromHarmonics(sphericalHarmonics);
  }
};
CubeMapToSphericalPolynomialTools._FileFaces = [
  new FileFaceOrientation("right", new Vector3(1, 0, 0), new Vector3(0, 0, -1), new Vector3(0, -1, 0)),
  // +X east
  new FileFaceOrientation("left", new Vector3(-1, 0, 0), new Vector3(0, 0, 1), new Vector3(0, -1, 0)),
  // -X west
  new FileFaceOrientation("up", new Vector3(0, 1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, 1)),
  // +Y north
  new FileFaceOrientation("down", new Vector3(0, -1, 0), new Vector3(1, 0, 0), new Vector3(0, 0, -1)),
  // -Y south
  new FileFaceOrientation("front", new Vector3(0, 0, 1), new Vector3(1, 0, 0), new Vector3(0, -1, 0)),
  // +Z top
  new FileFaceOrientation("back", new Vector3(0, 0, -1), new Vector3(-1, 0, 0), new Vector3(0, -1, 0))
  // -Z bottom
];
CubeMapToSphericalPolynomialTools.MAX_HDRI_VALUE = 4096;
CubeMapToSphericalPolynomialTools.PRESERVE_CLAMPED_COLORS = false;

// node_modules/@babylonjs/core/Rendering/objectRenderer.js
var ObjectRenderer = class _ObjectRenderer {
  /**
   * Use this list to define the list of mesh you want to render.
   */
  get renderList() {
    return this._renderList;
  }
  set renderList(value) {
    if (this._renderList === value) {
      return;
    }
    if (this._unObserveRenderList) {
      this._unObserveRenderList();
      this._unObserveRenderList = null;
    }
    if (value) {
      this._unObserveRenderList = _ObserveArray(value, this._renderListHasChanged);
    }
    this._renderList = value;
  }
  /**
   * If true, the object renderer will render all objects in linear space (default: false)
   */
  get renderInLinearSpace() {
    return this._renderInLinearSpace;
  }
  set renderInLinearSpace(value) {
    if (value === this._renderInLinearSpace) {
      return;
    }
    this._renderInLinearSpace = value;
    this._scene.markAllMaterialsAsDirty(64);
  }
  /**
   * Friendly name of the object renderer
   */
  get name() {
    return this._name;
  }
  set name(value) {
    if (this._name === value) {
      return;
    }
    this._name = value;
    if (!this._scene) {
      return;
    }
    const engine = this._scene.getEngine();
    for (let i = 0; i < this._renderPassIds.length; ++i) {
      const renderPassId = this._renderPassIds[i];
      engine._renderPassNames[renderPassId] = `${this._name}#${i}`;
    }
  }
  /**
   * Gets the render pass ids used by the object renderer.
   */
  get renderPassIds() {
    return this._renderPassIds;
  }
  /**
   * Gets the current value of the refreshId counter
   */
  get currentRefreshId() {
    return this._currentRefreshId;
  }
  /**
   * Sets a specific material to be used to render a mesh/a list of meshes with this object renderer
   * @param mesh mesh or array of meshes
   * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering pass.
   */
  setMaterialForRendering(mesh, material) {
    let meshes;
    if (!Array.isArray(mesh)) {
      meshes = [mesh];
    } else {
      meshes = mesh;
    }
    for (let j = 0; j < meshes.length; ++j) {
      for (let i = 0; i < this.options.numPasses; ++i) {
        meshes[j].setMaterialForRenderPass(this._renderPassIds[i], material !== void 0 ? Array.isArray(material) ? material[i] : material : void 0);
      }
    }
  }
  /**
   * Instantiates an object renderer.
   * @param name The friendly name of the object renderer
   * @param scene The scene the renderer belongs to
   * @param options The options used to create the renderer (optional)
   */
  constructor(name, scene, options) {
    this._unObserveRenderList = null;
    this._renderListHasChanged = (_functionName, previousLength) => {
      const newLength = this._renderList ? this._renderList.length : 0;
      if (previousLength === 0 && newLength > 0 || newLength === 0) {
        this._scene.meshes.forEach((mesh) => {
          mesh._markSubMeshesAsLightDirty();
        });
      }
    };
    this.particleSystemList = null;
    this.getCustomRenderList = null;
    this.renderParticles = true;
    this.renderSprites = false;
    this.forceLayerMaskCheck = false;
    this._renderInLinearSpace = false;
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this.onBeforeRenderingManagerRenderObservable = new Observable();
    this.onAfterRenderingManagerRenderObservable = new Observable();
    this.onFastPathRenderObservable = new Observable();
    this._currentRefreshId = -1;
    this._refreshRate = 1;
    this._currentApplyByPostProcessSetting = false;
    this._currentSceneCamera = null;
    this.name = name;
    this._scene = scene;
    this.renderList = [];
    this._renderPassIds = [];
    this.options = {
      numPasses: 1,
      doNotChangeAspectRatio: true,
      ...options
    };
    this._createRenderPassId();
    this.renderPassId = this._renderPassIds[0];
    this._renderingManager = new RenderingManager(scene);
    this._renderingManager._useSceneAutoClearSetup = true;
  }
  _releaseRenderPassId() {
    const engine = this._scene.getEngine();
    for (let i = 0; i < this.options.numPasses; ++i) {
      engine.releaseRenderPassId(this._renderPassIds[i]);
    }
    this._renderPassIds.length = 0;
  }
  _createRenderPassId() {
    this._releaseRenderPassId();
    const engine = this._scene.getEngine();
    for (let i = 0; i < this.options.numPasses; ++i) {
      this._renderPassIds[i] = engine.createRenderPassId(`${this.name}#${i}`);
    }
  }
  /**
   * Resets the refresh counter of the renderer and start back from scratch.
   * Could be useful to re-render if it is setup to render only once.
   */
  resetRefreshCounter() {
    this._currentRefreshId = -1;
  }
  /**
   * Defines the refresh rate of the rendering or the rendering frequency.
   * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
   */
  get refreshRate() {
    return this._refreshRate;
  }
  set refreshRate(value) {
    this._refreshRate = value;
    this.resetRefreshCounter();
  }
  /**
   * Indicates if the renderer should render the current frame.
   * The output is based on the specified refresh rate.
   * @returns true if the renderer should render the current frame
   */
  shouldRender() {
    if (this._currentRefreshId === -1) {
      this._currentRefreshId = 1;
      return true;
    }
    if (this.refreshRate === this._currentRefreshId) {
      this._currentRefreshId = 1;
      return true;
    }
    this._currentRefreshId++;
    return false;
  }
  /**
   * This function will check if the renderer is ready to render (textures are loaded, shaders are compiled)
   * @param viewportWidth defines the width of the viewport
   * @param viewportHeight defines the height of the viewport
   * @returns true if all required resources are ready
   */
  isReadyForRendering(viewportWidth, viewportHeight) {
    this.prepareRenderList();
    this.initRender(viewportWidth, viewportHeight);
    const isReady = this._checkReadiness();
    this.finishRender();
    return isReady;
  }
  /**
   * Makes sure the list of meshes is ready to be rendered
   * You should call this function before "initRender", but if you know the render list is ok, you may call "initRender" directly
   */
  prepareRenderList() {
    const scene = this._scene;
    if (this._waitingRenderList) {
      if (!this.renderListPredicate) {
        this.renderList = [];
        for (let index = 0; index < this._waitingRenderList.length; index++) {
          const id = this._waitingRenderList[index];
          const mesh = scene.getMeshById(id);
          if (mesh) {
            this.renderList.push(mesh);
          }
        }
      }
      this._waitingRenderList = void 0;
    }
    if (this.renderListPredicate) {
      if (this.renderList) {
        this.renderList.length = 0;
      } else {
        this.renderList = [];
      }
      const sceneMeshes = this._scene.meshes;
      for (let index = 0; index < sceneMeshes.length; index++) {
        const mesh = sceneMeshes[index];
        if (this.renderListPredicate(mesh)) {
          this.renderList.push(mesh);
        }
      }
    }
    this._currentApplyByPostProcessSetting = this._scene.imageProcessingConfiguration.applyByPostProcess;
    this._scene.imageProcessingConfiguration._applyByPostProcess = !!this._renderInLinearSpace;
  }
  /**
   * This method makes sure everything is setup before "render" can be called
   * @param viewportWidth Width of the viewport to render to
   * @param viewportHeight Height of the viewport to render to
   */
  initRender(viewportWidth, viewportHeight) {
    const engine = this._scene.getEngine();
    const camera = this.activeCamera ?? this._scene.activeCamera;
    this._currentSceneCamera = this._scene.activeCamera;
    if (camera) {
      if (camera !== this._scene.activeCamera) {
        this._scene.setTransformMatrix(camera.getViewMatrix(), camera.getProjectionMatrix(true));
        this._scene.activeCamera = camera;
      }
      engine.setViewport(camera.rigParent ? camera.rigParent.viewport : camera.viewport, viewportWidth, viewportHeight);
    }
    this._defaultRenderListPrepared = false;
  }
  /**
   * This method must be called after the "render" call(s), to complete the rendering process.
   */
  finishRender() {
    const scene = this._scene;
    scene.imageProcessingConfiguration._applyByPostProcess = this._currentApplyByPostProcessSetting;
    scene.activeCamera = this._currentSceneCamera;
    if (this._currentSceneCamera) {
      if (this.activeCamera && this.activeCamera !== scene.activeCamera) {
        scene.setTransformMatrix(this._currentSceneCamera.getViewMatrix(), this._currentSceneCamera.getProjectionMatrix(true));
      }
      scene.getEngine().setViewport(this._currentSceneCamera.viewport);
    }
    scene.resetCachedMaterial();
  }
  /**
   * Renders all the objects (meshes, particles systems, sprites) to the currently bound render target texture.
   * @param passIndex defines the pass index to use (default: 0)
   * @param skipOnAfterRenderObservable defines a flag to skip raising the onAfterRenderObservable
   */
  render(passIndex = 0, skipOnAfterRenderObservable = false) {
    const scene = this._scene;
    const engine = scene.getEngine();
    const currentRenderPassId = engine.currentRenderPassId;
    engine.currentRenderPassId = this._renderPassIds[passIndex];
    this.onBeforeRenderObservable.notifyObservers(passIndex);
    const fastPath = engine.snapshotRendering && engine.snapshotRenderingMode === 1;
    if (!fastPath) {
      let currentRenderList = null;
      const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
      const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
      if (this.getCustomRenderList) {
        currentRenderList = this.getCustomRenderList(passIndex, defaultRenderList, defaultRenderListLength);
      }
      if (!currentRenderList) {
        if (!this._defaultRenderListPrepared) {
          this._prepareRenderingManager(defaultRenderList, defaultRenderListLength, !this.renderList || this.forceLayerMaskCheck);
          this._defaultRenderListPrepared = true;
        }
        currentRenderList = defaultRenderList;
      } else {
        this._prepareRenderingManager(currentRenderList, currentRenderList.length, this.forceLayerMaskCheck);
      }
      this.onBeforeRenderingManagerRenderObservable.notifyObservers(passIndex);
      this._renderingManager.render(this.customRenderFunction, currentRenderList, this.renderParticles, this.renderSprites);
      this.onAfterRenderingManagerRenderObservable.notifyObservers(passIndex);
    } else {
      this.onFastPathRenderObservable.notifyObservers(passIndex);
    }
    if (!skipOnAfterRenderObservable) {
      this.onAfterRenderObservable.notifyObservers(passIndex);
    }
    engine.currentRenderPassId = currentRenderPassId;
  }
  /** @internal */
  _checkReadiness() {
    const scene = this._scene;
    const engine = scene.getEngine();
    const currentRenderPassId = engine.currentRenderPassId;
    let returnValue = true;
    if (!scene.getViewMatrix()) {
      scene.updateTransformMatrix();
    }
    const numPasses = this.options.numPasses;
    for (let passIndex = 0; passIndex < numPasses && returnValue; passIndex++) {
      let currentRenderList = null;
      const defaultRenderList = this.renderList ? this.renderList : scene.getActiveMeshes().data;
      const defaultRenderListLength = this.renderList ? this.renderList.length : scene.getActiveMeshes().length;
      engine.currentRenderPassId = this._renderPassIds[passIndex];
      this.onBeforeRenderObservable.notifyObservers(passIndex);
      if (this.getCustomRenderList) {
        currentRenderList = this.getCustomRenderList(passIndex, defaultRenderList, defaultRenderListLength);
      }
      if (!currentRenderList) {
        currentRenderList = defaultRenderList;
      }
      if (!this.options.doNotChangeAspectRatio) {
        scene.updateTransformMatrix(true);
      }
      for (let i = 0; i < currentRenderList.length && returnValue; ++i) {
        const mesh = currentRenderList[i];
        if (!mesh.isEnabled() || mesh.isBlocked || !mesh.isVisible || !mesh.subMeshes) {
          continue;
        }
        if (this.customIsReadyFunction) {
          if (!this.customIsReadyFunction(mesh, this.refreshRate, true)) {
            returnValue = false;
            continue;
          }
        } else if (!mesh.isReady(true)) {
          returnValue = false;
          continue;
        }
      }
      this.onAfterRenderObservable.notifyObservers(passIndex);
      if (numPasses > 1) {
        scene.incrementRenderId();
        scene.resetCachedMaterial();
      }
    }
    const particleSystems = this.particleSystemList || scene.particleSystems;
    for (const particleSystem of particleSystems) {
      if (!particleSystem.isReady()) {
        returnValue = false;
      }
    }
    engine.currentRenderPassId = currentRenderPassId;
    return returnValue;
  }
  _prepareRenderingManager(currentRenderList, currentRenderListLength, checkLayerMask) {
    const scene = this._scene;
    const camera = scene.activeCamera;
    const cameraForLOD = this.cameraForLOD ?? camera;
    this._renderingManager.reset();
    const sceneRenderId = scene.getRenderId();
    const currentFrameId = scene.getFrameId();
    for (let meshIndex = 0; meshIndex < currentRenderListLength; meshIndex++) {
      const mesh = currentRenderList[meshIndex];
      if (mesh && !mesh.isBlocked) {
        if (this.customIsReadyFunction) {
          if (!this.customIsReadyFunction(mesh, this.refreshRate, false)) {
            this.resetRefreshCounter();
            continue;
          }
        } else if (!mesh.isReady(this.refreshRate === 0)) {
          this.resetRefreshCounter();
          continue;
        }
        let meshToRender = null;
        if (cameraForLOD) {
          const meshToRenderAndFrameId = mesh._internalAbstractMeshDataInfo._currentLOD.get(cameraForLOD);
          if (!meshToRenderAndFrameId || meshToRenderAndFrameId[1] !== currentFrameId) {
            meshToRender = scene.customLODSelector ? scene.customLODSelector(mesh, cameraForLOD) : mesh.getLOD(cameraForLOD);
            if (!meshToRenderAndFrameId) {
              mesh._internalAbstractMeshDataInfo._currentLOD.set(cameraForLOD, [meshToRender, currentFrameId]);
            } else {
              meshToRenderAndFrameId[0] = meshToRender;
              meshToRenderAndFrameId[1] = currentFrameId;
            }
          } else {
            meshToRender = meshToRenderAndFrameId[0];
          }
        } else {
          meshToRender = mesh;
        }
        if (!meshToRender) {
          continue;
        }
        if (meshToRender !== mesh && meshToRender.billboardMode !== 0) {
          meshToRender.computeWorldMatrix();
        }
        meshToRender._preActivateForIntermediateRendering(sceneRenderId);
        let isMasked;
        if (checkLayerMask && camera) {
          isMasked = (mesh.layerMask & camera.layerMask) === 0;
        } else {
          isMasked = false;
        }
        if (mesh.isEnabled() && mesh.isVisible && mesh.subMeshes && !isMasked) {
          if (meshToRender !== mesh) {
            meshToRender._activate(sceneRenderId, true);
          }
          if (mesh._activate(sceneRenderId, true) && mesh.subMeshes.length) {
            if (!mesh.isAnInstance) {
              meshToRender._internalAbstractMeshDataInfo._onlyForInstancesIntermediate = false;
            } else {
              if (mesh._internalAbstractMeshDataInfo._actAsRegularMesh) {
                meshToRender = mesh;
              }
            }
            meshToRender._internalAbstractMeshDataInfo._isActiveIntermediate = true;
            scene._prepareSkeleton(meshToRender);
            for (let subIndex = 0; subIndex < meshToRender.subMeshes.length; subIndex++) {
              const subMesh = meshToRender.subMeshes[subIndex];
              this._renderingManager.dispatch(subMesh, meshToRender);
            }
          }
          mesh._postActivate();
        }
      }
    }
    const particleSystems = this.particleSystemList || scene.particleSystems;
    for (let particleIndex = 0; particleIndex < particleSystems.length; particleIndex++) {
      const particleSystem = particleSystems[particleIndex];
      const emitter = particleSystem.emitter;
      if (!particleSystem.isStarted() || !emitter || emitter.position && !emitter.isEnabled()) {
        continue;
      }
      this._renderingManager.dispatchParticles(particleSystem);
    }
  }
  /**
   * Overrides the default sort function applied in the rendering group to prepare the meshes.
   * This allowed control for front to back rendering or reversely depending of the special needs.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
   * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
   * @param transparentSortCompareFn The transparent queue comparison function use to sort.
   */
  setRenderingOrder(renderingGroupId, opaqueSortCompareFn = null, alphaTestSortCompareFn = null, transparentSortCompareFn = null) {
    this._renderingManager.setRenderingOrder(renderingGroupId, opaqueSortCompareFn, alphaTestSortCompareFn, transparentSortCompareFn);
  }
  /**
   * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
   * @param depth Automatically clears depth between groups if true and autoClear is true.
   * @param stencil Automatically clears stencil between groups if true and autoClear is true.
   */
  setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil, depth = true, stencil = true) {
    this._renderingManager.setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil, depth, stencil);
    this._renderingManager._useSceneAutoClearSetup = false;
  }
  /**
   * Clones the renderer.
   * @returns the cloned renderer
   */
  clone() {
    const newRenderer = new _ObjectRenderer(this.name, this._scene, this.options);
    if (this.renderList) {
      newRenderer.renderList = this.renderList.slice(0);
    }
    return newRenderer;
  }
  /**
   * Dispose the renderer and release its associated resources.
   */
  dispose() {
    const renderList = this.renderList ? this.renderList : this._scene.getActiveMeshes().data;
    const renderListLength = this.renderList ? this.renderList.length : this._scene.getActiveMeshes().length;
    for (let i = 0; i < renderListLength; i++) {
      const mesh = renderList[i];
      if (mesh.getMaterialForRenderPass(this.renderPassId) !== void 0) {
        mesh.setMaterialForRenderPass(this.renderPassId, void 0);
      }
    }
    this.onBeforeRenderObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onBeforeRenderingManagerRenderObservable.clear();
    this.onAfterRenderingManagerRenderObservable.clear();
    this.onFastPathRenderObservable.clear();
    this._releaseRenderPassId();
    this.renderList = null;
  }
  /** @internal */
  _rebuild() {
    if (this.refreshRate === _ObjectRenderer.REFRESHRATE_RENDER_ONCE) {
      this.refreshRate = _ObjectRenderer.REFRESHRATE_RENDER_ONCE;
    }
  }
  /**
   * Clear the info related to rendering groups preventing retention point in material dispose.
   */
  freeRenderingGroups() {
    if (this._renderingManager) {
      this._renderingManager.freeRenderingGroups();
    }
  }
};
ObjectRenderer.REFRESHRATE_RENDER_ONCE = 0;
ObjectRenderer.REFRESHRATE_RENDER_ONEVERYFRAME = 1;
ObjectRenderer.REFRESHRATE_RENDER_ONEVERYTWOFRAMES = 2;

// node_modules/@babylonjs/core/Materials/Textures/renderTargetTexture.js
Effect.prototype.setDepthStencilTexture = function(channel, texture) {
  this._engine.setDepthStencilTexture(this._samplers[channel], this._uniforms[channel], texture, channel);
};
var RenderTargetTexture = class _RenderTargetTexture extends Texture {
  /**
   * Use this predicate to dynamically define the list of mesh you want to render.
   * If set, the renderList property will be overwritten.
   */
  get renderListPredicate() {
    return this._objectRenderer.renderListPredicate;
  }
  set renderListPredicate(value) {
    this._objectRenderer.renderListPredicate = value;
  }
  /**
   * Use this list to define the list of mesh you want to render.
   */
  get renderList() {
    return this._objectRenderer.renderList;
  }
  set renderList(value) {
    this._objectRenderer.renderList = value;
  }
  /**
   * Define the list of particle systems to render in the texture. If not provided, will render all the particle systems of the scene.
   * Note that the particle systems are rendered only if renderParticles is set to true.
   */
  get particleSystemList() {
    return this._objectRenderer.particleSystemList;
  }
  set particleSystemList(value) {
    this._objectRenderer.particleSystemList = value;
  }
  /**
   * Use this function to overload the renderList array at rendering time.
   * Return null to render with the current renderList, else return the list of meshes to use for rendering.
   * For 2DArray RTT, layerOrFace is the index of the layer that is going to be rendered, else it is the faceIndex of
   * the cube (if the RTT is a cube, else layerOrFace=0).
   * The renderList passed to the function is the current render list (the one that will be used if the function returns null).
   * The length of this list is passed through renderListLength: don't use renderList.length directly because the array can
   * hold dummy elements!
   */
  get getCustomRenderList() {
    return this._objectRenderer.getCustomRenderList;
  }
  set getCustomRenderList(value) {
    this._objectRenderer.getCustomRenderList = value;
  }
  /**
   * Define if particles should be rendered in your texture (default: true).
   */
  get renderParticles() {
    return this._objectRenderer.renderParticles;
  }
  set renderParticles(value) {
    this._objectRenderer.renderParticles = value;
  }
  /**
   * Define if sprites should be rendered in your texture (default: false).
   */
  get renderSprites() {
    return this._objectRenderer.renderSprites;
  }
  set renderSprites(value) {
    this._objectRenderer.renderSprites = value;
  }
  /**
   * Force checking the layerMask property even if a custom list of meshes is provided (ie. if renderList is not undefined) (default: false).
   */
  get forceLayerMaskCheck() {
    return this._objectRenderer.forceLayerMaskCheck;
  }
  set forceLayerMaskCheck(value) {
    this._objectRenderer.forceLayerMaskCheck = value;
  }
  /**
   * Define the camera used to render the texture.
   */
  get activeCamera() {
    return this._objectRenderer.activeCamera;
  }
  set activeCamera(value) {
    this._objectRenderer.activeCamera = value;
  }
  /**
   * Define the camera used to calculate the LOD of the objects.
   * If not defined, activeCamera will be used. If not defined nor activeCamera, scene's active camera will be used.
   */
  get cameraForLOD() {
    return this._objectRenderer.cameraForLOD;
  }
  set cameraForLOD(value) {
    this._objectRenderer.cameraForLOD = value;
  }
  /**
   * If true, all objects will be rendered in linear space (default: false)
   */
  get renderInLinearSpace() {
    return this._objectRenderer.renderInLinearSpace;
  }
  set renderInLinearSpace(value) {
    this._objectRenderer.renderInLinearSpace = value;
  }
  /**
   * Override the mesh isReady function with your own one.
   */
  get customIsReadyFunction() {
    return this._objectRenderer.customIsReadyFunction;
  }
  set customIsReadyFunction(value) {
    this._objectRenderer.customIsReadyFunction = value;
  }
  /**
   * Override the render function of the texture with your own one.
   */
  get customRenderFunction() {
    return this._objectRenderer.customRenderFunction;
  }
  set customRenderFunction(value) {
    this._objectRenderer.customRenderFunction = value;
  }
  /**
   * Post-processes for this render target
   */
  get postProcesses() {
    return this._postProcesses;
  }
  get _prePassEnabled() {
    return !!this._prePassRenderTarget && this._prePassRenderTarget.enabled;
  }
  /**
   * Set a after unbind callback in the texture.
   * This has been kept for backward compatibility and use of onAfterUnbindObservable is recommended.
   */
  set onAfterUnbind(callback) {
    if (this._onAfterUnbindObserver) {
      this.onAfterUnbindObservable.remove(this._onAfterUnbindObserver);
    }
    this._onAfterUnbindObserver = this.onAfterUnbindObservable.add(callback);
  }
  /**
   * An event triggered before rendering the texture
   */
  get onBeforeRenderObservable() {
    return this._objectRenderer.onBeforeRenderObservable;
  }
  /**
   * Set a before render callback in the texture.
   * This has been kept for backward compatibility and use of onBeforeRenderObservable is recommended.
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * An event triggered after rendering the texture
   */
  get onAfterRenderObservable() {
    return this._objectRenderer.onAfterRenderObservable;
  }
  /**
   * Set a after render callback in the texture.
   * This has been kept for backward compatibility and use of onAfterRenderObservable is recommended.
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * Set a clear callback in the texture.
   * This has been kept for backward compatibility and use of onClearObservable is recommended.
   */
  set onClear(callback) {
    if (this._onClearObserver) {
      this.onClearObservable.remove(this._onClearObserver);
    }
    this._onClearObserver = this.onClearObservable.add(callback);
  }
  /** @internal */
  get _waitingRenderList() {
    return this._objectRenderer._waitingRenderList;
  }
  /** @internal */
  set _waitingRenderList(value) {
    this._objectRenderer._waitingRenderList = value;
  }
  /**
   * Current render pass id of the render target texture. Note it can change over the rendering as there's a separate id for each face of a cube / each layer of an array layer!
   */
  get renderPassId() {
    return this._objectRenderer.renderPassId;
  }
  /**
   * Gets the render pass ids used by the render target texture. For a single render target the array length will be 1, for a cube texture it will be 6 and for
   * a 2D texture array it will return an array of ids the size of the 2D texture array
   */
  get renderPassIds() {
    return this._objectRenderer.renderPassIds;
  }
  /**
   * Gets the current value of the refreshId counter
   */
  get currentRefreshId() {
    return this._objectRenderer.currentRefreshId;
  }
  /**
   * Sets a specific material to be used to render a mesh/a list of meshes in this render target texture
   * @param mesh mesh or array of meshes
   * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering in the case of a cube texture (6 rendering) and a 2D texture array (as many rendering as the length of the array)
   */
  setMaterialForRendering(mesh, material) {
    this._objectRenderer.setMaterialForRendering(mesh, material);
  }
  /**
   * Define if the texture has multiple draw buffers or if false a single draw buffer.
   */
  get isMulti() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.isMulti) ?? false;
  }
  /**
   * Gets render target creation options that were used.
   */
  get renderTargetOptions() {
    return this._renderTargetOptions;
  }
  /**
   * Gets the render target wrapper associated with this render target
   */
  get renderTarget() {
    return this._renderTarget;
  }
  _onRatioRescale() {
    if (this._sizeRatio) {
      this.resize(this._initialSizeParameter);
    }
  }
  /**
   * Gets or sets the size of the bounding box associated with the texture (when in cube mode)
   * When defined, the cubemap will switch to local mode
   * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
   * @example https://www.babylonjs-playground.com/#RNASML
   */
  set boundingBoxSize(value) {
    if (this._boundingBoxSize && this._boundingBoxSize.equals(value)) {
      return;
    }
    this._boundingBoxSize = value;
    const scene = this.getScene();
    if (scene) {
      scene.markAllMaterialsAsDirty(1);
    }
  }
  get boundingBoxSize() {
    return this._boundingBoxSize;
  }
  /**
   * In case the RTT has been created with a depth texture, get the associated
   * depth texture.
   * Otherwise, return null.
   */
  get depthStencilTexture() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a._depthStencilTexture) ?? null;
  }
  /** @internal */
  constructor(name, size, scene, generateMipMaps = false, doNotChangeAspectRatio = true, type = 0, isCube = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, generateDepthBuffer = true, generateStencilBuffer = false, isMulti = false, format = 5, delayAllocation = false, samples, creationFlags, noColorAttachment = false, useSRGBBuffer = false) {
    let colorAttachment = void 0;
    let gammaSpace = true;
    let existingObjectRenderer = void 0;
    if (typeof generateMipMaps === "object") {
      const options = generateMipMaps;
      generateMipMaps = !!options.generateMipMaps;
      doNotChangeAspectRatio = options.doNotChangeAspectRatio ?? true;
      type = options.type ?? 0;
      isCube = !!options.isCube;
      samplingMode = options.samplingMode ?? Texture.TRILINEAR_SAMPLINGMODE;
      generateDepthBuffer = options.generateDepthBuffer ?? true;
      generateStencilBuffer = !!options.generateStencilBuffer;
      isMulti = !!options.isMulti;
      format = options.format ?? 5;
      delayAllocation = !!options.delayAllocation;
      samples = options.samples;
      creationFlags = options.creationFlags;
      noColorAttachment = !!options.noColorAttachment;
      useSRGBBuffer = !!options.useSRGBBuffer;
      colorAttachment = options.colorAttachment;
      gammaSpace = options.gammaSpace ?? gammaSpace;
      existingObjectRenderer = options.existingObjectRenderer;
    }
    super(null, scene, !generateMipMaps, void 0, samplingMode, void 0, void 0, void 0, void 0, format);
    this.ignoreCameraViewport = false;
    this.onBeforeBindObservable = new Observable();
    this.onAfterUnbindObservable = new Observable();
    this.onClearObservable = new Observable();
    this.onResizeObservable = new Observable();
    this._cleared = false;
    this.skipInitialClear = false;
    this._samples = 1;
    this._canRescale = true;
    this._renderTarget = null;
    this._dontDisposeObjectRenderer = false;
    this.boundingBoxPosition = Vector3.Zero();
    this._disableEngineStages = false;
    this._dumpToolsLoading = false;
    scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = this.getScene().getEngine();
    this._gammaSpace = gammaSpace;
    this._coordinatesMode = Texture.PROJECTION_MODE;
    this.name = name;
    this.isRenderTarget = true;
    this._initialSizeParameter = size;
    this._dontDisposeObjectRenderer = !!existingObjectRenderer;
    this._processSizeParameter(size);
    this._objectRenderer = existingObjectRenderer ?? new ObjectRenderer(name, scene, {
      numPasses: isCube ? 6 : this.getRenderLayers() || 1,
      doNotChangeAspectRatio
    });
    this._onBeforeRenderingManagerRenderObserver = this._objectRenderer.onBeforeRenderingManagerRenderObservable.add(() => {
      if (!this._disableEngineStages) {
        for (const step of this._scene._beforeRenderTargetClearStage) {
          step.action(this, this._currentFaceIndex, this._currentLayer);
        }
      }
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else if (!this.skipInitialClear) {
        engine.clear(this.clearColor || this._scene.clearColor, true, true, true);
      }
      if (!this._doNotChangeAspectRatio) {
        this._scene.updateTransformMatrix(true);
      }
      if (!this._disableEngineStages) {
        for (const step of this._scene._beforeRenderTargetDrawStage) {
          step.action(this, this._currentFaceIndex, this._currentLayer);
        }
      }
    });
    this._onAfterRenderingManagerRenderObserver = this._objectRenderer.onAfterRenderingManagerRenderObservable.add(() => {
      var _a;
      if (!this._disableEngineStages) {
        for (const step of this._scene._afterRenderTargetDrawStage) {
          step.action(this, this._currentFaceIndex, this._currentLayer);
        }
      }
      const saveGenerateMipMaps = ((_a = this._texture) == null ? void 0 : _a.generateMipMaps) ?? false;
      if (this._texture) {
        this._texture.generateMipMaps = false;
      }
      if (this._postProcessManager) {
        this._postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, this._currentFaceIndex, this._postProcesses, this.ignoreCameraViewport);
      } else if (this._currentUseCameraPostProcess) {
        this._scene.postProcessManager._finalizeFrame(false, this._renderTarget ?? void 0, this._currentFaceIndex);
      }
      if (!this._disableEngineStages) {
        for (const step of this._scene._afterRenderTargetPostProcessStage) {
          step.action(this, this._currentFaceIndex, this._currentLayer);
        }
      }
      if (this._texture) {
        this._texture.generateMipMaps = saveGenerateMipMaps;
      }
      if (!this._doNotChangeAspectRatio) {
        this._scene.updateTransformMatrix(true);
      }
      if (this._currentDumpForDebug) {
        if (!this._dumpTools) {
          Logger.Error("dumpTools module is still being loaded. To speed up the process import dump tools directly in your project");
        } else {
          this._dumpTools.DumpFramebuffer(this.getRenderWidth(), this.getRenderHeight(), engine);
        }
      }
    });
    this._onFastPathRenderObserver = this._objectRenderer.onFastPathRenderObservable.add(() => {
      if (this.onClearObservable.hasObservers()) {
        this.onClearObservable.notifyObservers(engine);
      } else {
        if (!this.skipInitialClear) {
          engine.clear(this.clearColor || this._scene.clearColor, true, true, true);
        }
      }
    });
    this._resizeObserver = engine.onResizeObservable.add(() => {
    });
    this._generateMipMaps = generateMipMaps ? true : false;
    this._doNotChangeAspectRatio = doNotChangeAspectRatio;
    if (isMulti) {
      return;
    }
    this._renderTargetOptions = {
      generateMipMaps,
      type,
      format: this._format ?? void 0,
      samplingMode: this.samplingMode,
      generateDepthBuffer,
      generateStencilBuffer,
      samples,
      creationFlags,
      noColorAttachment,
      useSRGBBuffer,
      colorAttachment,
      label: this.name
    };
    if (this.samplingMode === Texture.NEAREST_SAMPLINGMODE) {
      this.wrapU = Texture.CLAMP_ADDRESSMODE;
      this.wrapV = Texture.CLAMP_ADDRESSMODE;
    }
    if (!delayAllocation) {
      if (isCube) {
        this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
        this.coordinatesMode = Texture.INVCUBIC_MODE;
        this._textureMatrix = Matrix.Identity();
      } else {
        this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
      }
      this._texture = this._renderTarget.texture;
      if (samples !== void 0) {
        this.samples = samples;
      }
    }
  }
  /**
   * Creates a depth stencil texture.
   * This is only available in WebGL 2 or with the depth texture extension available.
   * @param comparisonFunction Specifies the comparison function to set on the texture. If 0 or undefined, the texture is not in comparison mode (default: 0)
   * @param bilinearFiltering Specifies whether or not bilinear filtering is enable on the texture (default: true)
   * @param generateStencil Specifies whether or not a stencil should be allocated in the texture (default: false)
   * @param samples sample count of the depth/stencil texture (default: 1)
   * @param format format of the depth texture (default: 14)
   * @param label defines the label of the texture (for debugging purpose)
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.createDepthStencilTexture(comparisonFunction, bilinearFiltering, generateStencil, samples, format, label);
  }
  _processSizeParameter(size) {
    if (size.ratio) {
      this._sizeRatio = size.ratio;
      const engine = this._getEngine();
      this._size = {
        width: this._bestReflectionRenderTargetDimension(engine.getRenderWidth(), this._sizeRatio),
        height: this._bestReflectionRenderTargetDimension(engine.getRenderHeight(), this._sizeRatio)
      };
    } else {
      this._size = size;
    }
  }
  /**
   * Define the number of samples to use in case of MSAA.
   * It defaults to one meaning no MSAA has been enabled.
   */
  get samples() {
    var _a;
    return ((_a = this._renderTarget) == null ? void 0 : _a.samples) ?? this._samples;
  }
  set samples(value) {
    if (this._renderTarget) {
      this._samples = this._renderTarget.setSamples(value);
    }
  }
  /**
   * Adds a post process to the render target rendering passes.
   * @param postProcess define the post process to add
   */
  addPostProcess(postProcess) {
    if (!this._postProcessManager) {
      const scene = this.getScene();
      if (!scene) {
        return;
      }
      this._postProcessManager = new PostProcessManager(scene);
      this._postProcesses = new Array();
    }
    this._postProcesses.push(postProcess);
    this._postProcesses[0].autoClear = false;
  }
  /**
   * Clear all the post processes attached to the render target
   * @param dispose define if the cleared post processes should also be disposed (false by default)
   */
  clearPostProcesses(dispose = false) {
    if (!this._postProcesses) {
      return;
    }
    if (dispose) {
      for (const postProcess of this._postProcesses) {
        postProcess.dispose();
      }
    }
    this._postProcesses = [];
  }
  /**
   * Remove one of the post process from the list of attached post processes to the texture
   * @param postProcess define the post process to remove from the list
   */
  removePostProcess(postProcess) {
    if (!this._postProcesses) {
      return;
    }
    const index = this._postProcesses.indexOf(postProcess);
    if (index === -1) {
      return;
    }
    this._postProcesses.splice(index, 1);
    if (this._postProcesses.length > 0) {
      this._postProcesses[0].autoClear = false;
    }
  }
  /**
   * Resets the refresh counter of the texture and start bak from scratch.
   * Could be useful to regenerate the texture if it is setup to render only once.
   */
  resetRefreshCounter() {
    this._objectRenderer.resetRefreshCounter();
  }
  /**
   * Define the refresh rate of the texture or the rendering frequency.
   * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
   */
  get refreshRate() {
    return this._objectRenderer.refreshRate;
  }
  set refreshRate(value) {
    this._objectRenderer.refreshRate = value;
  }
  /** @internal */
  _shouldRender() {
    return this._objectRenderer.shouldRender();
  }
  /**
   * Gets the actual render size of the texture.
   * @returns the width of the render size
   */
  getRenderSize() {
    return this.getRenderWidth();
  }
  /**
   * Gets the actual render width of the texture.
   * @returns the width of the render size
   */
  getRenderWidth() {
    if (this._size.width) {
      return this._size.width;
    }
    return this._size;
  }
  /**
   * Gets the actual render height of the texture.
   * @returns the height of the render size
   */
  getRenderHeight() {
    if (this._size.width) {
      return this._size.height;
    }
    return this._size;
  }
  /**
   * Gets the actual number of layers of the texture or, in the case of a 3D texture, return the depth.
   * @returns the number of layers
   */
  getRenderLayers() {
    const layers = this._size.layers;
    if (layers) {
      return layers;
    }
    const depth = this._size.depth;
    if (depth) {
      return depth;
    }
    return 0;
  }
  /**
   * Don't allow this render target texture to rescale. Mainly used to prevent rescaling by the scene optimizer.
   */
  disableRescaling() {
    this._canRescale = false;
  }
  /**
   * Get if the texture can be rescaled or not.
   */
  get canRescale() {
    return this._canRescale;
  }
  /**
   * Resize the texture using a ratio.
   * @param ratio the ratio to apply to the texture size in order to compute the new target size
   */
  scale(ratio) {
    const newSize = Math.max(1, this.getRenderSize() * ratio);
    this.resize(newSize);
  }
  /**
   * Get the texture reflection matrix used to rotate/transform the reflection.
   * @returns the reflection matrix
   */
  getReflectionTextureMatrix() {
    if (this.isCube) {
      return this._textureMatrix;
    }
    return super.getReflectionTextureMatrix();
  }
  /**
   * Resize the texture to a new desired size.
   * Be careful as it will recreate all the data in the new texture.
   * @param size Define the new size. It can be:
   *   - a number for squared texture,
   *   - an object containing { width: number, height: number }
   *   - or an object containing a ratio { ratio: number }
   */
  resize(size) {
    var _a;
    const wasCube = this.isCube;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this._processSizeParameter(size);
    if (wasCube) {
      this._renderTarget = scene.getEngine().createRenderTargetCubeTexture(this.getRenderSize(), this._renderTargetOptions);
    } else {
      this._renderTarget = scene.getEngine().createRenderTargetTexture(this._size, this._renderTargetOptions);
    }
    this._texture = this._renderTarget.texture;
    if (this._renderTargetOptions.samples !== void 0) {
      this.samples = this._renderTargetOptions.samples;
    }
    if (this.onResizeObservable.hasObservers()) {
      this.onResizeObservable.notifyObservers(this);
    }
  }
  /**
   * Renders all the objects from the render list into the texture.
   * @param useCameraPostProcess Define if camera post processes should be used during the rendering
   * @param dumpForDebug Define if the rendering result should be dumped (copied) for debugging purpose
   */
  render(useCameraPostProcess = false, dumpForDebug = false) {
    this._render(useCameraPostProcess, dumpForDebug);
  }
  /**
   * This function will check if the render target texture can be rendered (textures are loaded, shaders are compiled)
   * @returns true if all required resources are ready
   */
  isReadyForRendering() {
    if (!this._dumpToolsLoading) {
      this._dumpToolsLoading = true;
      import("./dumpTools-ZOFRUI6S.js").then((module) => this._dumpTools = module);
    }
    this._objectRenderer.prepareRenderList();
    this.onBeforeBindObservable.notifyObservers(this);
    this._objectRenderer.initRender(this.getRenderWidth(), this.getRenderHeight());
    const isReady = this._objectRenderer._checkReadiness();
    this.onAfterUnbindObservable.notifyObservers(this);
    this._objectRenderer.finishRender();
    return isReady;
  }
  _render(useCameraPostProcess = false, dumpForDebug = false) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    if (this.useCameraPostProcesses !== void 0) {
      useCameraPostProcess = this.useCameraPostProcesses;
    }
    this._objectRenderer.prepareRenderList();
    this.onBeforeBindObservable.notifyObservers(this);
    this._objectRenderer.initRender(this.getRenderWidth(), this.getRenderHeight());
    if ((this.is2DArray || this.is3D) && !this.isMulti) {
      for (let layer = 0; layer < this.getRenderLayers(); layer++) {
        this._renderToTarget(0, useCameraPostProcess, dumpForDebug, layer);
        scene.incrementRenderId();
        scene.resetCachedMaterial();
      }
    } else if (this.isCube && !this.isMulti) {
      for (let face = 0; face < 6; face++) {
        this._renderToTarget(face, useCameraPostProcess, dumpForDebug);
        scene.incrementRenderId();
        scene.resetCachedMaterial();
      }
    } else {
      this._renderToTarget(0, useCameraPostProcess, dumpForDebug);
    }
    this.onAfterUnbindObservable.notifyObservers(this);
    this._objectRenderer.finishRender();
  }
  _bestReflectionRenderTargetDimension(renderDimension, scale) {
    const minimum = 128;
    const x = renderDimension * scale;
    const curved = NearestPOT(x + minimum * minimum / (minimum + x));
    return Math.min(FloorPOT(renderDimension), curved);
  }
  /**
   * @internal
   * @param faceIndex face index to bind to if this is a cubetexture
   * @param layer defines the index of the texture to bind in the array
   */
  _bindFrameBuffer(faceIndex = 0, layer = 0) {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    if (this._renderTarget) {
      engine.bindFramebuffer(this._renderTarget, this.isCube ? faceIndex : void 0, void 0, void 0, this.ignoreCameraViewport, 0, layer);
    }
  }
  _unbindFrameBuffer(engine, faceIndex) {
    if (!this._renderTarget) {
      return;
    }
    engine.unBindFramebuffer(this._renderTarget, this.isCube, () => {
      this.onAfterRenderObservable.notifyObservers(faceIndex);
    });
  }
  /**
   * @internal
   */
  _prepareFrame(scene, faceIndex, layer, useCameraPostProcess) {
    if (this._postProcessManager) {
      if (!this._prePassEnabled) {
        this._postProcessManager._prepareFrame(this._texture, this._postProcesses);
      }
    } else if (!useCameraPostProcess || !scene.postProcessManager._prepareFrame(this._texture)) {
      this._bindFrameBuffer(faceIndex, layer);
    }
  }
  _renderToTarget(faceIndex, useCameraPostProcess, dumpForDebug, layer = 0) {
    var _a, _b;
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    const engine = scene.getEngine();
    this._currentFaceIndex = faceIndex;
    this._currentLayer = layer;
    this._currentUseCameraPostProcess = useCameraPostProcess;
    this._currentDumpForDebug = dumpForDebug;
    this._prepareFrame(scene, faceIndex, layer, useCameraPostProcess);
    (_a = engine._debugPushGroup) == null ? void 0 : _a.call(engine, `render to face #${faceIndex} layer #${layer}`, 2);
    this._objectRenderer.render(faceIndex + layer, true);
    (_b = engine._debugPopGroup) == null ? void 0 : _b.call(engine, 2);
    this._unbindFrameBuffer(engine, faceIndex);
    if (this._texture && this.isCube && faceIndex === 5) {
      engine.generateMipMapsForCubemap(this._texture, true);
    }
  }
  /**
   * Overrides the default sort function applied in the rendering group to prepare the meshes.
   * This allowed control for front to back rendering or reversely depending of the special needs.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
   * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
   * @param transparentSortCompareFn The transparent queue comparison function use to sort.
   */
  setRenderingOrder(renderingGroupId, opaqueSortCompareFn = null, alphaTestSortCompareFn = null, transparentSortCompareFn = null) {
    this._objectRenderer.setRenderingOrder(renderingGroupId, opaqueSortCompareFn, alphaTestSortCompareFn, transparentSortCompareFn);
  }
  /**
   * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
   *
   * @param renderingGroupId The rendering group id corresponding to its index
   * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
   */
  setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil) {
    this._objectRenderer.setRenderingAutoClearDepthStencil(renderingGroupId, autoClearDepthStencil);
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    const textureSize = this.getSize();
    const newTexture = new _RenderTargetTexture(this.name, textureSize, this.getScene(), this._renderTargetOptions.generateMipMaps, this._doNotChangeAspectRatio, this._renderTargetOptions.type, this.isCube, this._renderTargetOptions.samplingMode, this._renderTargetOptions.generateDepthBuffer, this._renderTargetOptions.generateStencilBuffer, void 0, this._renderTargetOptions.format, void 0, this._renderTargetOptions.samples);
    newTexture.hasAlpha = this.hasAlpha;
    newTexture.level = this.level;
    newTexture.coordinatesMode = this.coordinatesMode;
    if (this.renderList) {
      newTexture.renderList = this.renderList.slice(0);
    }
    return newTexture;
  }
  /**
   * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
   * @returns The JSON representation of the texture
   */
  serialize() {
    if (!this.name) {
      return null;
    }
    const serializationObject = super.serialize();
    serializationObject.renderTargetSize = this.getRenderSize();
    serializationObject.renderList = [];
    if (this.renderList) {
      for (let index = 0; index < this.renderList.length; index++) {
        serializationObject.renderList.push(this.renderList[index].id);
      }
    }
    return serializationObject;
  }
  /**
   *  This will remove the attached framebuffer objects. The texture will not be able to be used as render target anymore
   */
  disposeFramebufferObjects() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.dispose(true);
  }
  /**
   * Release and destroy the underlying lower level texture aka internalTexture.
   */
  releaseInternalTexture() {
    var _a;
    (_a = this._renderTarget) == null ? void 0 : _a.releaseTextures();
    this._texture = null;
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    var _a;
    this.onResizeObservable.clear();
    this.onClearObservable.clear();
    this.onAfterUnbindObservable.clear();
    this.onBeforeBindObservable.clear();
    if (this._postProcessManager) {
      this._postProcessManager.dispose();
      this._postProcessManager = null;
    }
    if (this._prePassRenderTarget) {
      this._prePassRenderTarget.dispose();
    }
    this._objectRenderer.onBeforeRenderingManagerRenderObservable.remove(this._onBeforeRenderingManagerRenderObserver);
    this._objectRenderer.onAfterRenderingManagerRenderObservable.remove(this._onAfterRenderingManagerRenderObserver);
    this._objectRenderer.onFastPathRenderObservable.remove(this._onFastPathRenderObserver);
    if (!this._dontDisposeObjectRenderer) {
      this._objectRenderer.dispose();
    }
    this.clearPostProcesses(true);
    if (this._resizeObserver) {
      this.getScene().getEngine().onResizeObservable.remove(this._resizeObserver);
      this._resizeObserver = null;
    }
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    let index = scene.customRenderTargets.indexOf(this);
    if (index >= 0) {
      scene.customRenderTargets.splice(index, 1);
    }
    for (const camera of scene.cameras) {
      index = camera.customRenderTargets.indexOf(this);
      if (index >= 0) {
        camera.customRenderTargets.splice(index, 1);
      }
    }
    (_a = this._renderTarget) == null ? void 0 : _a.dispose();
    this._renderTarget = null;
    this._texture = null;
    super.dispose();
  }
  /** @internal */
  _rebuild() {
    this._objectRenderer._rebuild();
    if (this._postProcessManager) {
      this._postProcessManager._rebuild();
    }
  }
  /**
   * Clear the info related to rendering groups preventing retention point in material dispose.
   */
  freeRenderingGroups() {
    this._objectRenderer.freeRenderingGroups();
  }
  /**
   * Gets the number of views the corresponding to the texture (eg. a MultiviewRenderTarget will have > 1)
   * @returns the view count
   */
  getViewCount() {
    return 1;
  }
};
RenderTargetTexture.REFRESHRATE_RENDER_ONCE = ObjectRenderer.REFRESHRATE_RENDER_ONCE;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYFRAME = ObjectRenderer.REFRESHRATE_RENDER_ONEVERYFRAME;
RenderTargetTexture.REFRESHRATE_RENDER_ONEVERYTWOFRAMES = ObjectRenderer.REFRESHRATE_RENDER_ONEVERYTWOFRAMES;
Texture._CreateRenderTargetTexture = (name, renderTargetSize, scene, generateMipMaps, creationFlags) => {
  return new RenderTargetTexture(name, renderTargetSize, scene, generateMipMaps);
};

// node_modules/@babylonjs/core/PostProcesses/postProcess.js
AbstractEngine.prototype.setTextureFromPostProcess = function(channel, postProcess, name) {
  let postProcessInput = null;
  if (postProcess) {
    if (postProcess._forcedOutputTexture) {
      postProcessInput = postProcess._forcedOutputTexture;
    } else if (postProcess._textures.data[postProcess._currentRenderTextureInd]) {
      postProcessInput = postProcess._textures.data[postProcess._currentRenderTextureInd];
    }
  }
  this._bindTexture(channel, (postProcessInput == null ? void 0 : postProcessInput.texture) ?? null, name);
};
AbstractEngine.prototype.setTextureFromPostProcessOutput = function(channel, postProcess, name) {
  var _a;
  this._bindTexture(channel, ((_a = postProcess == null ? void 0 : postProcess._outputTexture) == null ? void 0 : _a.texture) ?? null, name);
};
Effect.prototype.setTextureFromPostProcess = function(channel, postProcess) {
  this._engine.setTextureFromPostProcess(this._samplers[channel], postProcess, channel);
};
Effect.prototype.setTextureFromPostProcessOutput = function(channel, postProcess) {
  this._engine.setTextureFromPostProcessOutput(this._samplers[channel], postProcess, channel);
};
var PostProcess = class _PostProcess {
  /**
   * Force all the postprocesses to compile to glsl even on WebGPU engines.
   * False by default. This is mostly meant for backward compatibility.
   */
  static get ForceGLSL() {
    return EffectWrapper.ForceGLSL;
  }
  static set ForceGLSL(force) {
    EffectWrapper.ForceGLSL = force;
  }
  /**
   * Registers a shader code processing with a post process name.
   * @param postProcessName name of the post process. Use null for the fallback shader code processing. This is the shader code processing that will be used in case no specific shader code processing has been associated to a post process name
   * @param customShaderCodeProcessing shader code processing to associate to the post process name
   */
  static RegisterShaderCodeProcessing(postProcessName, customShaderCodeProcessing) {
    EffectWrapper.RegisterShaderCodeProcessing(postProcessName, customShaderCodeProcessing);
  }
  /** Name of the PostProcess. */
  get name() {
    return this._effectWrapper.name;
  }
  set name(value) {
    this._effectWrapper.name = value;
  }
  /**
   * Type of alpha mode to use when performing the post process (default: Engine.ALPHA_DISABLE)
   */
  get alphaMode() {
    return this._effectWrapper.alphaMode;
  }
  set alphaMode(value) {
    this._effectWrapper.alphaMode = value;
  }
  /**
   * Number of sample textures (default: 1)
   */
  get samples() {
    return this._samples;
  }
  set samples(n) {
    this._samples = Math.min(n, this._engine.getCaps().maxMSAASamples);
    this._textures.forEach((texture) => {
      texture.setSamples(this._samples);
    });
  }
  /**
   * Gets the shader language type used to generate vertex and fragment source code.
   */
  get shaderLanguage() {
    return this._shaderLanguage;
  }
  /**
   * Returns the fragment url or shader name used in the post process.
   * @returns the fragment url or name in the shader store.
   */
  getEffectName() {
    return this._fragmentUrl;
  }
  /**
   * A function that is added to the onActivateObservable
   */
  set onActivate(callback) {
    if (this._onActivateObserver) {
      this.onActivateObservable.remove(this._onActivateObserver);
    }
    if (callback) {
      this._onActivateObserver = this.onActivateObservable.add(callback);
    }
  }
  /**
   * A function that is added to the onSizeChangedObservable
   */
  set onSizeChanged(callback) {
    if (this._onSizeChangedObserver) {
      this.onSizeChangedObservable.remove(this._onSizeChangedObserver);
    }
    this._onSizeChangedObserver = this.onSizeChangedObservable.add(callback);
  }
  /**
   * A function that is added to the onApplyObservable
   */
  set onApply(callback) {
    if (this._onApplyObserver) {
      this.onApplyObservable.remove(this._onApplyObserver);
    }
    this._onApplyObserver = this.onApplyObservable.add(callback);
  }
  /**
   * A function that is added to the onBeforeRenderObservable
   */
  set onBeforeRender(callback) {
    if (this._onBeforeRenderObserver) {
      this.onBeforeRenderObservable.remove(this._onBeforeRenderObserver);
    }
    this._onBeforeRenderObserver = this.onBeforeRenderObservable.add(callback);
  }
  /**
   * A function that is added to the onAfterRenderObservable
   */
  set onAfterRender(callback) {
    if (this._onAfterRenderObserver) {
      this.onAfterRenderObservable.remove(this._onAfterRenderObserver);
    }
    this._onAfterRenderObserver = this.onAfterRenderObservable.add(callback);
  }
  /**
   * The input texture for this post process and the output texture of the previous post process. When added to a pipeline the previous post process will
   * render it's output into this texture and this texture will be used as textureSampler in the fragment shader of this post process.
   */
  get inputTexture() {
    return this._textures.data[this._currentRenderTextureInd];
  }
  set inputTexture(value) {
    this._forcedOutputTexture = value;
  }
  /**
   * Since inputTexture should always be defined, if we previously manually set `inputTexture`,
   * the only way to unset it is to use this function to restore its internal state
   */
  restoreDefaultInputTexture() {
    if (this._forcedOutputTexture) {
      this._forcedOutputTexture = null;
      this.markTextureDirty();
    }
  }
  /**
   * Gets the camera which post process is applied to.
   * @returns The camera the post process is applied to.
   */
  getCamera() {
    return this._camera;
  }
  /**
   * Gets the texel size of the postprocess.
   * See https://en.wikipedia.org/wiki/Texel_(graphics)
   */
  get texelSize() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.texelSize;
    }
    if (this._forcedOutputTexture) {
      this._texelSize.copyFromFloats(1 / this._forcedOutputTexture.width, 1 / this._forcedOutputTexture.height);
    }
    return this._texelSize;
  }
  /** @internal */
  constructor(name, fragmentUrl, parameters, samplers, _size, camera, samplingMode = 1, engine, reusable, defines = null, textureType = 0, vertexUrl = "postprocess", indexParameters, blockCompilation = false, textureFormat = 5, shaderLanguage, extraInitializations) {
    this._parentContainer = null;
    this.width = -1;
    this.height = -1;
    this.nodeMaterialSource = null;
    this._outputTexture = null;
    this.autoClear = true;
    this.forceAutoClearInAlphaMode = false;
    this.animations = [];
    this.enablePixelPerfectMode = false;
    this.forceFullscreenViewport = true;
    this.scaleMode = 1;
    this.alwaysForcePOT = false;
    this._samples = 1;
    this.adaptScaleToCurrentViewport = false;
    this._webGPUReady = false;
    this._reusable = false;
    this._renderId = 0;
    this.externalTextureSamplerBinding = false;
    this._textures = new SmartArray(2);
    this._textureCache = [];
    this._currentRenderTextureInd = 0;
    this._scaleRatio = new Vector2(1, 1);
    this._texelSize = Vector2.Zero();
    this.onActivateObservable = new Observable();
    this.onSizeChangedObservable = new Observable();
    this.onApplyObservable = new Observable();
    this.onBeforeRenderObservable = new Observable();
    this.onAfterRenderObservable = new Observable();
    this.onDisposeObservable = new Observable();
    let size = 1;
    let uniformBuffers = null;
    let effectWrapper;
    if (parameters && !Array.isArray(parameters)) {
      const options = parameters;
      parameters = options.uniforms ?? null;
      samplers = options.samplers ?? null;
      size = options.size ?? 1;
      camera = options.camera ?? null;
      samplingMode = options.samplingMode ?? 1;
      engine = options.engine;
      reusable = options.reusable;
      defines = Array.isArray(options.defines) ? options.defines.join("\n") : options.defines ?? null;
      textureType = options.textureType ?? 0;
      vertexUrl = options.vertexUrl ?? "postprocess";
      indexParameters = options.indexParameters;
      blockCompilation = options.blockCompilation ?? false;
      textureFormat = options.textureFormat ?? 5;
      shaderLanguage = options.shaderLanguage ?? 0;
      uniformBuffers = options.uniformBuffers ?? null;
      extraInitializations = options.extraInitializations;
      effectWrapper = options.effectWrapper;
    } else if (_size) {
      if (typeof _size === "number") {
        size = _size;
      } else {
        size = { width: _size.width, height: _size.height };
      }
    }
    this._useExistingThinPostProcess = !!effectWrapper;
    this._effectWrapper = effectWrapper ?? new EffectWrapper({
      name,
      useShaderStore: true,
      useAsPostProcess: true,
      fragmentShader: fragmentUrl,
      engine: engine || (camera == null ? void 0 : camera.getScene().getEngine()),
      uniforms: parameters,
      samplers,
      uniformBuffers,
      defines,
      vertexUrl,
      indexParameters,
      blockCompilation: true,
      shaderLanguage,
      extraInitializations: void 0
    });
    this.name = name;
    this.onEffectCreatedObservable = this._effectWrapper.onEffectCreatedObservable;
    if (camera != null) {
      this._camera = camera;
      this._scene = camera.getScene();
      camera.attachPostProcess(this);
      this._engine = this._scene.getEngine();
      this._scene.postProcesses.push(this);
      this.uniqueId = this._scene.getUniqueId();
    } else if (engine) {
      this._engine = engine;
      this._engine.postProcesses.push(this);
    }
    this._options = size;
    this.renderTargetSamplingMode = samplingMode ? samplingMode : 1;
    this._reusable = reusable || false;
    this._textureType = textureType;
    this._textureFormat = textureFormat;
    this._shaderLanguage = shaderLanguage || 0;
    this._samplers = samplers || [];
    if (this._samplers.indexOf("textureSampler") === -1) {
      this._samplers.push("textureSampler");
    }
    this._fragmentUrl = fragmentUrl;
    this._vertexUrl = vertexUrl;
    this._parameters = parameters || [];
    if (this._parameters.indexOf("scale") === -1) {
      this._parameters.push("scale");
    }
    this._uniformBuffers = uniformBuffers || [];
    this._indexParameters = indexParameters;
    if (!this._useExistingThinPostProcess) {
      this._webGPUReady = this._shaderLanguage === 1;
      const importPromises = [];
      this._gatherImports(this._engine.isWebGPU && !_PostProcess.ForceGLSL, importPromises);
      this._effectWrapper._webGPUReady = this._webGPUReady;
      this._effectWrapper._postConstructor(blockCompilation, defines, extraInitializations, importPromises);
    }
  }
  _gatherImports(useWebGPU = false, list) {
    if (useWebGPU && this._webGPUReady) {
      list.push(Promise.all([import("./postprocess.vertex-VGN2RRLI.js")]));
    } else {
      list.push(Promise.all([import("./postprocess.vertex-GM7GA5CR.js")]));
    }
  }
  /**
   * Gets a string identifying the name of the class
   * @returns "PostProcess" string
   */
  getClassName() {
    return "PostProcess";
  }
  /**
   * Gets the engine which this post process belongs to.
   * @returns The engine the post process was enabled with.
   */
  getEngine() {
    return this._engine;
  }
  /**
   * The effect that is created when initializing the post process.
   * @returns The created effect corresponding to the postprocess.
   */
  getEffect() {
    return this._effectWrapper.drawWrapper.effect;
  }
  /**
   * To avoid multiple redundant textures for multiple post process, the output the output texture for this post process can be shared with another.
   * @param postProcess The post process to share the output with.
   * @returns This post process.
   */
  shareOutputWith(postProcess) {
    this._disposeTextures();
    this._shareOutputWithPostProcess = postProcess;
    return this;
  }
  /**
   * Reverses the effect of calling shareOutputWith and returns the post process back to its original state.
   * This should be called if the post process that shares output with this post process is disabled/disposed.
   */
  useOwnOutput() {
    if (this._textures.length == 0) {
      this._textures = new SmartArray(2);
    }
    this._shareOutputWithPostProcess = null;
  }
  /**
   * Updates the effect with the current post process compile time values and recompiles the shader.
   * @param defines Define statements that should be added at the beginning of the shader. (default: null)
   * @param uniforms Set of uniform variables that will be passed to the shader. (default: null)
   * @param samplers Set of Texture2D variables that will be passed to the shader. (default: null)
   * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
   * @param onCompiled Called when the shader has been compiled.
   * @param onError Called if there is an error when compiling a shader.
   * @param vertexUrl The url of the vertex shader to be used (default: the one given at construction time)
   * @param fragmentUrl The url of the fragment shader to be used (default: the one given at construction time)
   */
  updateEffect(defines = null, uniforms = null, samplers = null, indexParameters, onCompiled, onError, vertexUrl, fragmentUrl) {
    this._effectWrapper.updateEffect(defines, uniforms, samplers, indexParameters, onCompiled, onError, vertexUrl, fragmentUrl);
    this._postProcessDefines = Array.isArray(this._effectWrapper.options.defines) ? this._effectWrapper.options.defines.join("\n") : this._effectWrapper.options.defines;
  }
  /**
   * The post process is reusable if it can be used multiple times within one frame.
   * @returns If the post process is reusable
   */
  isReusable() {
    return this._reusable;
  }
  /** invalidate frameBuffer to hint the postprocess to create a depth buffer */
  markTextureDirty() {
    this.width = -1;
  }
  _createRenderTargetTexture(textureSize, textureOptions, channel = 0) {
    for (let i = 0; i < this._textureCache.length; i++) {
      if (this._textureCache[i].texture.width === textureSize.width && this._textureCache[i].texture.height === textureSize.height && this._textureCache[i].postProcessChannel === channel && this._textureCache[i].texture._generateDepthBuffer === textureOptions.generateDepthBuffer && this._textureCache[i].texture.samples === textureOptions.samples) {
        return this._textureCache[i].texture;
      }
    }
    const tex = this._engine.createRenderTargetTexture(textureSize, textureOptions);
    this._textureCache.push({ texture: tex, postProcessChannel: channel, lastUsedRenderId: -1 });
    return tex;
  }
  _flushTextureCache() {
    const currentRenderId = this._renderId;
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      if (currentRenderId - this._textureCache[i].lastUsedRenderId > 100) {
        let currentlyUsed = false;
        for (let j = 0; j < this._textures.length; j++) {
          if (this._textures.data[j] === this._textureCache[i].texture) {
            currentlyUsed = true;
            break;
          }
        }
        if (!currentlyUsed) {
          this._textureCache[i].texture.dispose();
          this._textureCache.splice(i, 1);
        }
      }
    }
  }
  /**
   * Resizes the post-process texture
   * @param width Width of the texture
   * @param height Height of the texture
   * @param camera The camera this post-process is applied to. Pass null if the post-process is used outside the context of a camera post-process chain (default: null)
   * @param needMipMaps True if mip maps need to be generated after render (default: false)
   * @param forceDepthStencil True to force post-process texture creation with stencil depth and buffer (default: false)
   */
  resize(width, height, camera = null, needMipMaps = false, forceDepthStencil = false) {
    if (this._textures.length > 0) {
      this._textures.reset();
    }
    this.width = width;
    this.height = height;
    let firstPP = null;
    if (camera) {
      for (let i = 0; i < camera._postProcesses.length; i++) {
        if (camera._postProcesses[i] !== null) {
          firstPP = camera._postProcesses[i];
          break;
        }
      }
    }
    const textureSize = { width: this.width, height: this.height };
    const textureOptions = {
      generateMipMaps: needMipMaps,
      generateDepthBuffer: forceDepthStencil || firstPP === this,
      generateStencilBuffer: (forceDepthStencil || firstPP === this) && this._engine.isStencilEnable,
      samplingMode: this.renderTargetSamplingMode,
      type: this._textureType,
      format: this._textureFormat,
      samples: this._samples,
      label: "PostProcessRTT-" + this.name
    };
    this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 0));
    if (this._reusable) {
      this._textures.push(this._createRenderTargetTexture(textureSize, textureOptions, 1));
    }
    this._texelSize.copyFromFloats(1 / this.width, 1 / this.height);
    this.onSizeChangedObservable.notifyObservers(this);
  }
  _getTarget() {
    let target;
    if (this._shareOutputWithPostProcess) {
      target = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      target = this._forcedOutputTexture;
      this.width = this._forcedOutputTexture.width;
      this.height = this._forcedOutputTexture.height;
    } else {
      target = this.inputTexture;
      let cache;
      for (let i = 0; i < this._textureCache.length; i++) {
        if (this._textureCache[i].texture === target) {
          cache = this._textureCache[i];
          break;
        }
      }
      if (cache) {
        cache.lastUsedRenderId = this._renderId;
      }
    }
    return target;
  }
  /**
   * Activates the post process by intializing the textures to be used when executed. Notifies onActivateObservable.
   * When this post process is used in a pipeline, this is call will bind the input texture of this post process to the output of the previous.
   * @param cameraOrScene The camera that will be used in the post process. This camera will be used when calling onActivateObservable. You can also pass the scene if no camera is available.
   * @param sourceTexture The source texture to be inspected to get the width and height if not specified in the post process constructor. (default: null)
   * @param forceDepthStencil If true, a depth and stencil buffer will be generated. (default: false)
   * @returns The render target wrapper that was bound to be written to.
   */
  activate(cameraOrScene, sourceTexture = null, forceDepthStencil) {
    var _a, _b;
    const camera = cameraOrScene === null || cameraOrScene.cameraRigMode !== void 0 ? cameraOrScene || this._camera : null;
    const scene = (camera == null ? void 0 : camera.getScene()) ?? cameraOrScene;
    const engine = scene.getEngine();
    const maxSize = engine.getCaps().maxTextureSize;
    const requiredWidth = (sourceTexture ? sourceTexture.width : this._engine.getRenderWidth(true)) * this._options | 0;
    const requiredHeight = (sourceTexture ? sourceTexture.height : this._engine.getRenderHeight(true)) * this._options | 0;
    let desiredWidth = this._options.width || requiredWidth;
    let desiredHeight = this._options.height || requiredHeight;
    const needMipMaps = this.renderTargetSamplingMode !== 7 && this.renderTargetSamplingMode !== 1 && this.renderTargetSamplingMode !== 2;
    let target = null;
    if (!this._shareOutputWithPostProcess && !this._forcedOutputTexture) {
      if (this.adaptScaleToCurrentViewport) {
        const currentViewport = engine.currentViewport;
        if (currentViewport) {
          desiredWidth *= currentViewport.width;
          desiredHeight *= currentViewport.height;
        }
      }
      if (needMipMaps || this.alwaysForcePOT) {
        if (!this._options.width) {
          desiredWidth = engine.needPOTTextures ? GetExponentOfTwo(desiredWidth, maxSize, this.scaleMode) : desiredWidth;
        }
        if (!this._options.height) {
          desiredHeight = engine.needPOTTextures ? GetExponentOfTwo(desiredHeight, maxSize, this.scaleMode) : desiredHeight;
        }
      }
      if (this.width !== desiredWidth || this.height !== desiredHeight || !(target = this._getTarget())) {
        this.resize(desiredWidth, desiredHeight, camera, needMipMaps, forceDepthStencil);
      }
      this._textures.forEach((texture) => {
        if (texture.samples !== this.samples) {
          this._engine.updateRenderTargetTextureSampleCount(texture, this.samples);
        }
      });
      this._flushTextureCache();
      this._renderId++;
    }
    if (!target) {
      target = this._getTarget();
    }
    if (this.enablePixelPerfectMode) {
      this._scaleRatio.copyFromFloats(requiredWidth / desiredWidth, requiredHeight / desiredHeight);
      this._engine.bindFramebuffer(target, 0, requiredWidth, requiredHeight, this.forceFullscreenViewport);
    } else {
      this._scaleRatio.copyFromFloats(1, 1);
      this._engine.bindFramebuffer(target, 0, void 0, void 0, this.forceFullscreenViewport);
    }
    (_b = (_a = this._engine)._debugInsertMarker) == null ? void 0 : _b.call(_a, `post process ${this.name} input`);
    this.onActivateObservable.notifyObservers(camera);
    if (this.autoClear && (this.alphaMode === 0 || this.forceAutoClearInAlphaMode)) {
      this._engine.clear(this.clearColor ? this.clearColor : scene.clearColor, scene._allowPostProcessClearColor, true, true);
    }
    if (this._reusable) {
      this._currentRenderTextureInd = (this._currentRenderTextureInd + 1) % 2;
    }
    return target;
  }
  /**
   * If the post process is supported.
   */
  get isSupported() {
    return this._effectWrapper.drawWrapper.effect.isSupported;
  }
  /**
   * The aspect ratio of the output texture.
   */
  get aspectRatio() {
    if (this._shareOutputWithPostProcess) {
      return this._shareOutputWithPostProcess.aspectRatio;
    }
    if (this._forcedOutputTexture) {
      return this._forcedOutputTexture.width / this._forcedOutputTexture.height;
    }
    return this.width / this.height;
  }
  /**
   * Get a value indicating if the post-process is ready to be used
   * @returns true if the post-process is ready (shader is compiled)
   */
  isReady() {
    return this._effectWrapper.isReady();
  }
  /**
   * Binds all textures and uniforms to the shader, this will be run on every pass.
   * @returns the effect corresponding to this post process. Null if not compiled or not ready.
   */
  apply() {
    if (!this._effectWrapper.isReady()) {
      return null;
    }
    this._engine.enableEffect(this._effectWrapper.drawWrapper);
    this._engine.setState(false);
    this._engine.setDepthBuffer(false);
    this._engine.setDepthWrite(false);
    if (this.alphaConstants) {
      this.getEngine().setAlphaConstants(this.alphaConstants.r, this.alphaConstants.g, this.alphaConstants.b, this.alphaConstants.a);
    }
    let source;
    if (this._shareOutputWithPostProcess) {
      source = this._shareOutputWithPostProcess.inputTexture;
    } else if (this._forcedOutputTexture) {
      source = this._forcedOutputTexture;
    } else {
      source = this.inputTexture;
    }
    if (!this.externalTextureSamplerBinding) {
      this._effectWrapper.drawWrapper.effect._bindTexture("textureSampler", source == null ? void 0 : source.texture);
    }
    this._effectWrapper.drawWrapper.effect.setVector2("scale", this._scaleRatio);
    this.onApplyObservable.notifyObservers(this._effectWrapper.drawWrapper.effect);
    this._effectWrapper.bind();
    return this._effectWrapper.drawWrapper.effect;
  }
  _disposeTextures() {
    if (this._shareOutputWithPostProcess || this._forcedOutputTexture) {
      this._disposeTextureCache();
      return;
    }
    this._disposeTextureCache();
    this._textures.dispose();
  }
  _disposeTextureCache() {
    for (let i = this._textureCache.length - 1; i >= 0; i--) {
      this._textureCache[i].texture.dispose();
    }
    this._textureCache.length = 0;
  }
  /**
   * Sets the required values to the prepass renderer.
   * @param prePassRenderer defines the prepass renderer to setup.
   * @returns true if the pre pass is needed.
   */
  setPrePassRenderer(prePassRenderer) {
    if (this._prePassEffectConfiguration) {
      this._prePassEffectConfiguration = prePassRenderer.addEffectConfiguration(this._prePassEffectConfiguration);
      this._prePassEffectConfiguration.enabled = true;
      return true;
    }
    return false;
  }
  /**
   * Disposes the post process.
   * @param camera The camera to dispose the post process on.
   */
  dispose(camera) {
    camera = camera || this._camera;
    if (!this._useExistingThinPostProcess) {
      this._effectWrapper.dispose();
    }
    this._disposeTextures();
    let index;
    if (this._scene) {
      index = this._scene.postProcesses.indexOf(this);
      if (index !== -1) {
        this._scene.postProcesses.splice(index, 1);
      }
    }
    if (this._parentContainer) {
      const index2 = this._parentContainer.postProcesses.indexOf(this);
      if (index2 > -1) {
        this._parentContainer.postProcesses.splice(index2, 1);
      }
      this._parentContainer = null;
    }
    index = this._engine.postProcesses.indexOf(this);
    if (index !== -1) {
      this._engine.postProcesses.splice(index, 1);
    }
    this.onDisposeObservable.notifyObservers();
    if (!camera) {
      return;
    }
    camera.detachPostProcess(this);
    index = camera._postProcesses.indexOf(this);
    if (index === 0 && camera._postProcesses.length > 0) {
      const firstPostProcess = this._camera._getFirstPostProcess();
      if (firstPostProcess) {
        firstPostProcess.markTextureDirty();
      }
    }
    this.onActivateObservable.clear();
    this.onAfterRenderObservable.clear();
    this.onApplyObservable.clear();
    this.onBeforeRenderObservable.clear();
    this.onSizeChangedObservable.clear();
    this.onEffectCreatedObservable.clear();
  }
  /**
   * Serializes the post process to a JSON object
   * @returns the JSON object
   */
  serialize() {
    const serializationObject = SerializationHelper.Serialize(this);
    const camera = this.getCamera() || this._scene && this._scene.activeCamera;
    serializationObject.customType = "BABYLON." + this.getClassName();
    serializationObject.cameraId = camera ? camera.id : null;
    serializationObject.reusable = this._reusable;
    serializationObject.textureType = this._textureType;
    serializationObject.fragmentUrl = this._fragmentUrl;
    serializationObject.parameters = this._parameters;
    serializationObject.samplers = this._samplers;
    serializationObject.uniformBuffers = this._uniformBuffers;
    serializationObject.options = this._options;
    serializationObject.defines = this._postProcessDefines;
    serializationObject.textureFormat = this._textureFormat;
    serializationObject.vertexUrl = this._vertexUrl;
    serializationObject.indexParameters = this._indexParameters;
    return serializationObject;
  }
  /**
   * Clones this post process
   * @returns a new post process similar to this one
   */
  clone() {
    const serializationObject = this.serialize();
    serializationObject._engine = this._engine;
    serializationObject.cameraId = null;
    const result = _PostProcess.Parse(serializationObject, this._scene, "");
    if (!result) {
      return null;
    }
    result.onActivateObservable = this.onActivateObservable.clone();
    result.onSizeChangedObservable = this.onSizeChangedObservable.clone();
    result.onApplyObservable = this.onApplyObservable.clone();
    result.onBeforeRenderObservable = this.onBeforeRenderObservable.clone();
    result.onAfterRenderObservable = this.onAfterRenderObservable.clone();
    result._prePassEffectConfiguration = this._prePassEffectConfiguration;
    return result;
  }
  /**
   * Creates a material from parsed material data
   * @param parsedPostProcess defines parsed post process data
   * @param scene defines the hosting scene
   * @param rootUrl defines the root URL to use to load textures
   * @returns a new post process
   */
  static Parse(parsedPostProcess, scene, rootUrl) {
    const postProcessType = GetClass(parsedPostProcess.customType);
    if (!postProcessType || !postProcessType._Parse) {
      return null;
    }
    const camera = scene ? scene.getCameraById(parsedPostProcess.cameraId) : null;
    return postProcessType._Parse(parsedPostProcess, camera, scene, rootUrl);
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PostProcess(parsedPostProcess.name, parsedPostProcess.fragmentUrl, parsedPostProcess.parameters, parsedPostProcess.samplers, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable, parsedPostProcess.defines, parsedPostProcess.textureType, parsedPostProcess.vertexUrl, parsedPostProcess.indexParameters, false, parsedPostProcess.textureFormat);
    }, parsedPostProcess, scene, rootUrl);
  }
};
__decorate([
  serialize()
], PostProcess.prototype, "uniqueId", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "name", null);
__decorate([
  serialize()
], PostProcess.prototype, "width", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "height", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "renderTargetSamplingMode", void 0);
__decorate([
  serializeAsColor4()
], PostProcess.prototype, "clearColor", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "autoClear", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceAutoClearInAlphaMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alphaMode", null);
__decorate([
  serialize()
], PostProcess.prototype, "alphaConstants", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "enablePixelPerfectMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "forceFullscreenViewport", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "scaleMode", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "alwaysForcePOT", void 0);
__decorate([
  serialize("samples")
], PostProcess.prototype, "_samples", void 0);
__decorate([
  serialize()
], PostProcess.prototype, "adaptScaleToCurrentViewport", void 0);
RegisterClass("BABYLON.PostProcess", PostProcess);

// node_modules/@babylonjs/core/Misc/performanceMonitor.js
var PerformanceMonitor = class {
  /**
   * constructor
   * @param frameSampleSize The number of samples required to saturate the sliding window
   */
  constructor(frameSampleSize = 30) {
    this._enabled = true;
    this._rollingFrameTime = new RollingAverage(frameSampleSize);
  }
  /**
   * Samples current frame
   * @param timeMs A timestamp in milliseconds of the current frame to compare with other frames
   */
  sampleFrame(timeMs = PrecisionDate.Now) {
    if (!this._enabled) {
      return;
    }
    if (this._lastFrameTimeMs != null) {
      const dt = timeMs - this._lastFrameTimeMs;
      this._rollingFrameTime.add(dt);
    }
    this._lastFrameTimeMs = timeMs;
  }
  /**
   * Returns the average frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
   */
  get averageFrameTime() {
    return this._rollingFrameTime.average;
  }
  /**
   * Returns the variance frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
   */
  get averageFrameTimeVariance() {
    return this._rollingFrameTime.variance;
  }
  /**
   * Returns the frame time of the most recent frame
   */
  get instantaneousFrameTime() {
    return this._rollingFrameTime.history(0);
  }
  /**
   * Returns the average framerate in frames per second over the sliding window (or the subset of frames sampled so far)
   */
  get averageFPS() {
    return 1e3 / this._rollingFrameTime.average;
  }
  /**
   * Returns the average framerate in frames per second using the most recent frame time
   */
  get instantaneousFPS() {
    const history = this._rollingFrameTime.history(0);
    if (history === 0) {
      return 0;
    }
    return 1e3 / history;
  }
  /**
   * Returns true if enough samples have been taken to completely fill the sliding window
   */
  get isSaturated() {
    return this._rollingFrameTime.isSaturated();
  }
  /**
   * Enables contributions to the sliding window sample set
   */
  enable() {
    this._enabled = true;
  }
  /**
   * Disables contributions to the sliding window sample set
   * Samples will not be interpolated over the disabled period
   */
  disable() {
    this._enabled = false;
    this._lastFrameTimeMs = null;
  }
  /**
   * Returns true if sampling is enabled
   */
  get isEnabled() {
    return this._enabled;
  }
  /**
   * Resets performance monitor
   */
  reset() {
    this._lastFrameTimeMs = null;
    this._rollingFrameTime.reset();
  }
};
var RollingAverage = class {
  /**
   * constructor
   * @param length The number of samples required to saturate the sliding window
   */
  constructor(length) {
    this._samples = new Array(length);
    this.reset();
  }
  /**
   * Adds a sample to the sample set
   * @param v The sample value
   */
  add(v) {
    let delta;
    if (this.isSaturated()) {
      const bottomValue = this._samples[this._pos];
      delta = bottomValue - this.average;
      this.average -= delta / (this._sampleCount - 1);
      this._m2 -= delta * (bottomValue - this.average);
    } else {
      this._sampleCount++;
    }
    delta = v - this.average;
    this.average += delta / this._sampleCount;
    this._m2 += delta * (v - this.average);
    this.variance = this._m2 / (this._sampleCount - 1);
    this._samples[this._pos] = v;
    this._pos++;
    this._pos %= this._samples.length;
  }
  /**
   * Returns previously added values or null if outside of history or outside the sliding window domain
   * @param i Index in history. For example, pass 0 for the most recent value and 1 for the value before that
   * @returns Value previously recorded with add() or null if outside of range
   */
  history(i) {
    if (i >= this._sampleCount || i >= this._samples.length) {
      return 0;
    }
    const i0 = this._wrapPosition(this._pos - 1);
    return this._samples[this._wrapPosition(i0 - i)];
  }
  /**
   * Returns true if enough samples have been taken to completely fill the sliding window
   * @returns true if sample-set saturated
   */
  isSaturated() {
    return this._sampleCount >= this._samples.length;
  }
  /**
   * Resets the rolling average (equivalent to 0 samples taken so far)
   */
  reset() {
    this.average = 0;
    this.variance = 0;
    this._sampleCount = 0;
    this._pos = 0;
    this._m2 = 0;
  }
  /**
   * Wraps a value around the sample range boundaries
   * @param i Position in sample range, for example if the sample length is 5, and i is -3, then 2 will be returned.
   * @returns Wrapped position in sample range
   */
  _wrapPosition(i) {
    const max = this._samples.length;
    return (i % max + max) % max;
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.readTexture.js
ThinEngine.prototype._readTexturePixelsSync = function(texture, width, height, faceIndex = -1, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0) {
  var _a, _b;
  const gl = this._gl;
  if (!gl) {
    throw new Error("Engine does not have gl rendering context.");
  }
  if (!this._dummyFramebuffer) {
    const dummy = gl.createFramebuffer();
    if (!dummy) {
      throw new Error("Unable to create dummy framebuffer");
    }
    this._dummyFramebuffer = dummy;
  }
  gl.bindFramebuffer(gl.FRAMEBUFFER, this._dummyFramebuffer);
  if (faceIndex > -1) {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, (_a = texture._hardwareTexture) == null ? void 0 : _a.underlyingResource, level);
  } else {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, (_b = texture._hardwareTexture) == null ? void 0 : _b.underlyingResource, level);
  }
  let readType = texture.type !== void 0 ? this._getWebGLTextureType(texture.type) : gl.UNSIGNED_BYTE;
  if (!noDataConversion) {
    switch (readType) {
      case gl.UNSIGNED_BYTE:
        if (!buffer) {
          buffer = new Uint8Array(4 * width * height);
        }
        readType = gl.UNSIGNED_BYTE;
        break;
      default:
        if (!buffer) {
          buffer = new Float32Array(4 * width * height);
        }
        readType = gl.FLOAT;
        break;
    }
  } else if (!buffer) {
    buffer = allocateAndCopyTypedBuffer(texture.type, 4 * width * height);
  }
  if (flushRenderer) {
    this.flushFramebuffer();
  }
  gl.readPixels(x, y, width, height, gl.RGBA, readType, buffer);
  gl.bindFramebuffer(gl.FRAMEBUFFER, this._currentFramebuffer);
  return buffer;
};
ThinEngine.prototype._readTexturePixels = function(texture, width, height, faceIndex = -1, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0) {
  return Promise.resolve(this._readTexturePixelsSync(texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion, x, y));
};

// node_modules/@babylonjs/core/Engines/renderTargetWrapper.js
var RenderTargetWrapper = class {
  /**
   * Gets the depth/stencil texture
   */
  get depthStencilTexture() {
    return this._depthStencilTexture;
  }
  /**
   * Sets the depth/stencil texture
   * @param texture The depth/stencil texture to set
   * @param disposeExisting True to dispose the existing depth/stencil texture (if any) before replacing it (default: true)
   */
  setDepthStencilTexture(texture, disposeExisting = true) {
    if (disposeExisting && this._depthStencilTexture) {
      this._depthStencilTexture.dispose();
    }
    this._depthStencilTexture = texture;
    this._generateDepthBuffer = this._generateStencilBuffer = this._depthStencilTextureWithStencil = false;
    if (texture) {
      this._generateDepthBuffer = true;
      this._generateStencilBuffer = this._depthStencilTextureWithStencil = HasStencilAspect(texture.format);
    }
  }
  /**
   * Indicates if the depth/stencil texture has a stencil aspect
   */
  get depthStencilTextureWithStencil() {
    return this._depthStencilTextureWithStencil;
  }
  /**
   * Defines if the render target wrapper is for a cube texture or if false a 2d texture
   */
  get isCube() {
    return this._isCube;
  }
  /**
   * Defines if the render target wrapper is for a single or multi target render wrapper
   */
  get isMulti() {
    return this._isMulti;
  }
  /**
   * Defines if the render target wrapper is for a single or an array of textures
   */
  get is2DArray() {
    return this.layers > 0;
  }
  /**
   * Defines if the render target wrapper is for a 3D texture
   */
  get is3D() {
    return this.depth > 0;
  }
  /**
   * Gets the size of the render target wrapper (used for cubes, as width=height in this case)
   */
  get size() {
    return this.width;
  }
  /**
   * Gets the width of the render target wrapper
   */
  get width() {
    return this._size.width ?? this._size;
  }
  /**
   * Gets the height of the render target wrapper
   */
  get height() {
    return this._size.height ?? this._size;
  }
  /**
   * Gets the number of layers of the render target wrapper (only used if is2DArray is true and wrapper is not a multi render target)
   */
  get layers() {
    return this._size.layers || 0;
  }
  /**
   * Gets the depth of the render target wrapper (only used if is3D is true and wrapper is not a multi render target)
   */
  get depth() {
    return this._size.depth || 0;
  }
  /**
   * Gets the render texture. If this is a multi render target, gets the first texture
   */
  get texture() {
    var _a;
    return ((_a = this._textures) == null ? void 0 : _a[0]) ?? null;
  }
  /**
   * Gets the list of render textures. If we are not in a multi render target, the list will be null (use the texture getter instead)
   */
  get textures() {
    return this._textures;
  }
  /**
   * Gets the face indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
   */
  get faceIndices() {
    return this._faceIndices;
  }
  /**
   * Gets the layer indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
   */
  get layerIndices() {
    return this._layerIndices;
  }
  /**
   * Gets the base array layer of a texture in the textures array
   * This is an number that is calculated based on the layer and face indices set for this texture at that index
   * @param index The index of the texture in the textures array to get the base array layer for
   * @returns the base array layer of the texture at the given index
   */
  getBaseArrayLayer(index) {
    var _a, _b;
    if (!this._textures) {
      return -1;
    }
    const texture = this._textures[index];
    const layerIndex = ((_a = this._layerIndices) == null ? void 0 : _a[index]) ?? 0;
    const faceIndex = ((_b = this._faceIndices) == null ? void 0 : _b[index]) ?? 0;
    return texture.isCube ? layerIndex * 6 + faceIndex : texture.is3D ? 0 : layerIndex;
  }
  /**
   * Gets the sample count of the render target
   */
  get samples() {
    return this._samples;
  }
  /**
   * Sets the sample count of the render target
   * @param value sample count
   * @param initializeBuffers If set to true, the engine will make an initializing call to drawBuffers (only used when isMulti=true).
   * @param force true to force calling the update sample count engine function even if the current sample count is equal to value
   * @returns the sample count that has been set
   */
  setSamples(value, initializeBuffers = true, force = false) {
    if (this.samples === value && !force) {
      return value;
    }
    const result = this._isMulti ? this._engine.updateMultipleRenderTargetTextureSampleCount(this, value, initializeBuffers) : this._engine.updateRenderTargetTextureSampleCount(this, value);
    this._samples = value;
    return result;
  }
  /**
   * Resolves the MSAA textures into their non-MSAA version.
   * Note that if samples equals 1 (no MSAA), no resolve is performed.
   */
  resolveMSAATextures() {
    if (this.isMulti) {
      this._engine.resolveMultiFramebuffer(this);
    } else {
      this._engine.resolveFramebuffer(this);
    }
  }
  /**
   * Generates mipmaps for each texture of the render target
   */
  generateMipMaps() {
    if (this._engine._currentRenderTarget === this) {
      this._engine.unBindFramebuffer(this, true);
    }
    if (this.isMulti) {
      this._engine.generateMipMapsMultiFramebuffer(this);
    } else {
      this._engine.generateMipMapsFramebuffer(this);
    }
  }
  /**
   * Initializes the render target wrapper
   * @param isMulti true if the wrapper is a multi render target
   * @param isCube true if the wrapper should render to a cube texture
   * @param size size of the render target (width/height/layers)
   * @param engine engine used to create the render target
   * @param label defines the label to use for the wrapper (for debugging purpose only)
   */
  constructor(isMulti, isCube, size, engine, label) {
    this._textures = null;
    this._faceIndices = null;
    this._layerIndices = null;
    this._samples = 1;
    this._attachments = null;
    this._generateStencilBuffer = false;
    this._generateDepthBuffer = false;
    this._depthStencilTextureWithStencil = false;
    this.disableAutomaticMSAAResolve = false;
    this.resolveMSAAColors = true;
    this.resolveMSAADepth = false;
    this.resolveMSAAStencil = false;
    this._isMulti = isMulti;
    this._isCube = isCube;
    this._size = size;
    this._engine = engine;
    this._depthStencilTexture = null;
    this.label = label;
  }
  /**
   * Sets the render target texture(s)
   * @param textures texture(s) to set
   */
  setTextures(textures) {
    if (Array.isArray(textures)) {
      this._textures = textures;
    } else if (textures) {
      this._textures = [textures];
    } else {
      this._textures = null;
    }
  }
  /**
   * Set a texture in the textures array
   * @param texture The texture to set
   * @param index The index in the textures array to set
   * @param disposePrevious If this function should dispose the previous texture
   */
  setTexture(texture, index = 0, disposePrevious = true) {
    if (!this._textures) {
      this._textures = [];
    }
    if (this._textures[index] === texture) {
      return;
    }
    if (this._textures[index] && disposePrevious) {
      this._textures[index].dispose();
    }
    this._textures[index] = texture;
  }
  /**
   * Sets the layer and face indices of every render target texture bound to each color attachment
   * @param layers The layers of each texture to be set
   * @param faces The faces of each texture to be set
   */
  setLayerAndFaceIndices(layers, faces) {
    this._layerIndices = layers;
    this._faceIndices = faces;
  }
  /**
   * Sets the layer and face indices of a texture in the textures array that should be bound to each color attachment
   * @param index The index of the texture in the textures array to modify
   * @param layer The layer of the texture to be set
   * @param face The face of the texture to be set
   */
  setLayerAndFaceIndex(index = 0, layer, face) {
    if (!this._layerIndices) {
      this._layerIndices = [];
    }
    if (!this._faceIndices) {
      this._faceIndices = [];
    }
    if (layer !== void 0 && layer >= 0) {
      this._layerIndices[index] = layer;
    }
    if (face !== void 0 && face >= 0) {
      this._faceIndices[index] = face;
    }
  }
  /**
   * Creates the depth/stencil texture
   * @param comparisonFunction Comparison function to use for the texture
   * @param bilinearFiltering true if bilinear filtering should be used when sampling the texture
   * @param generateStencil Not used anymore. "format" will be used to determine if stencil should be created
   * @param samples sample count to use when creating the texture (default: 1)
   * @param format format of the depth texture (default: 14)
   * @param label defines the label to use for the texture (for debugging purpose only)
   * @returns the depth/stencil created texture
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    var _a;
    (_a = this._depthStencilTexture) == null ? void 0 : _a.dispose();
    this._depthStencilTextureWithStencil = generateStencil;
    this._depthStencilTextureLabel = label;
    this._depthStencilTexture = this._engine.createDepthStencilTexture(this._size, {
      bilinearFiltering,
      comparisonFunction,
      generateStencil,
      isCube: this._isCube,
      samples,
      depthTextureFormat: format,
      label
    }, this);
    return this._depthStencilTexture;
  }
  /**
   * @deprecated Use shareDepth instead
   * @param renderTarget Destination renderTarget
   */
  _shareDepth(renderTarget) {
    this.shareDepth(renderTarget);
  }
  /**
   * Shares the depth buffer of this render target with another render target.
   * @param renderTarget Destination renderTarget
   */
  shareDepth(renderTarget) {
    if (this._depthStencilTexture) {
      if (renderTarget._depthStencilTexture) {
        renderTarget._depthStencilTexture.dispose();
      }
      renderTarget._depthStencilTexture = this._depthStencilTexture;
      renderTarget._depthStencilTextureWithStencil = this._depthStencilTextureWithStencil;
      this._depthStencilTexture.incrementReferences();
    }
  }
  /**
   * @internal
   */
  _swapAndDie(target) {
    if (this.texture) {
      this.texture._swapAndDie(target);
    }
    this._textures = null;
    this.dispose(true);
  }
  _cloneRenderTargetWrapper() {
    var _a, _b, _c, _d, _e;
    let rtw = null;
    if (this._isMulti) {
      const textureArray = this.textures;
      if (textureArray && textureArray.length > 0) {
        let generateDepthTexture = false;
        let textureCount = textureArray.length;
        let depthTextureFormat = -1;
        const lastTextureSource = textureArray[textureArray.length - 1]._source;
        if (lastTextureSource === 14 || lastTextureSource === 12) {
          generateDepthTexture = true;
          depthTextureFormat = textureArray[textureArray.length - 1].format;
          textureCount--;
        }
        const samplingModes = [];
        const types = [];
        const formats = [];
        const targetTypes = [];
        const faceIndex = [];
        const layerIndex = [];
        const layerCounts = [];
        const internalTexture2Index = {};
        for (let i = 0; i < textureCount; ++i) {
          const texture = textureArray[i];
          samplingModes.push(texture.samplingMode);
          types.push(texture.type);
          formats.push(texture.format);
          const index = internalTexture2Index[texture.uniqueId];
          if (index !== void 0) {
            targetTypes.push(-1);
            layerCounts.push(0);
          } else {
            internalTexture2Index[texture.uniqueId] = i;
            if (texture.is2DArray) {
              targetTypes.push(35866);
              layerCounts.push(texture.depth);
            } else if (texture.isCube) {
              targetTypes.push(34067);
              layerCounts.push(0);
            } else if (texture.is3D) {
              targetTypes.push(32879);
              layerCounts.push(texture.depth);
            } else {
              targetTypes.push(3553);
              layerCounts.push(0);
            }
          }
          if (this._faceIndices) {
            faceIndex.push(this._faceIndices[i] ?? 0);
          }
          if (this._layerIndices) {
            layerIndex.push(this._layerIndices[i] ?? 0);
          }
        }
        const optionsMRT = {
          samplingModes,
          generateMipMaps: textureArray[0].generateMipMaps,
          generateDepthBuffer: this._generateDepthBuffer,
          generateStencilBuffer: this._generateStencilBuffer,
          generateDepthTexture,
          depthTextureFormat,
          types,
          formats,
          textureCount,
          targetTypes,
          faceIndex,
          layerIndex,
          layerCounts,
          label: this.label
        };
        const size = {
          width: this.width,
          height: this.height,
          depth: this.depth
        };
        rtw = this._engine.createMultipleRenderTarget(size, optionsMRT);
        for (let i = 0; i < textureCount; ++i) {
          if (targetTypes[i] !== -1) {
            continue;
          }
          const index = internalTexture2Index[textureArray[i].uniqueId];
          rtw.setTexture(rtw.textures[index], i);
        }
      }
    } else {
      const options = {};
      options.generateDepthBuffer = this._generateDepthBuffer;
      options.generateMipMaps = ((_a = this.texture) == null ? void 0 : _a.generateMipMaps) ?? false;
      options.generateStencilBuffer = this._generateStencilBuffer;
      options.samplingMode = (_b = this.texture) == null ? void 0 : _b.samplingMode;
      options.type = (_c = this.texture) == null ? void 0 : _c.type;
      options.format = (_d = this.texture) == null ? void 0 : _d.format;
      options.noColorAttachment = !this._textures;
      options.label = this.label;
      if (this.isCube) {
        rtw = this._engine.createRenderTargetCubeTexture(this.width, options);
      } else {
        const size = {
          width: this.width,
          height: this.height,
          layers: this.is2DArray || this.is3D ? (_e = this.texture) == null ? void 0 : _e.depth : void 0
        };
        rtw = this._engine.createRenderTargetTexture(size, options);
      }
      if (rtw.texture) {
        rtw.texture.isReady = true;
      }
    }
    return rtw;
  }
  _swapRenderTargetWrapper(target) {
    if (this._textures && target._textures) {
      for (let i = 0; i < this._textures.length; ++i) {
        this._textures[i]._swapAndDie(target._textures[i], false);
        target._textures[i].isReady = true;
      }
    }
    if (this._depthStencilTexture && target._depthStencilTexture) {
      this._depthStencilTexture._swapAndDie(target._depthStencilTexture);
      target._depthStencilTexture.isReady = true;
    }
    this._textures = null;
    this._depthStencilTexture = null;
  }
  /** @internal */
  _rebuild() {
    const rtw = this._cloneRenderTargetWrapper();
    if (!rtw) {
      return;
    }
    if (this._depthStencilTexture) {
      const samplingMode = this._depthStencilTexture.samplingMode;
      const format = this._depthStencilTexture.format;
      const bilinear = samplingMode === 2 || samplingMode === 3 || samplingMode === 11;
      rtw.createDepthStencilTexture(this._depthStencilTexture._comparisonFunction, bilinear, this._depthStencilTextureWithStencil, this._depthStencilTexture.samples, format, this._depthStencilTextureLabel);
    }
    if (this.samples > 1) {
      rtw.setSamples(this.samples);
    }
    rtw._swapRenderTargetWrapper(this);
    rtw.dispose();
  }
  /**
   * Releases the internal render textures
   */
  releaseTextures() {
    if (this._textures) {
      for (let i = 0; i < this._textures.length; ++i) {
        this._textures[i].dispose();
      }
    }
    this._textures = null;
  }
  /**
   * Disposes the whole render target wrapper
   * @param disposeOnlyFramebuffers true if only the frame buffers should be released (used for the WebGL engine). If false, all the textures will also be released
   */
  dispose(disposeOnlyFramebuffers = false) {
    var _a;
    if (!disposeOnlyFramebuffers) {
      (_a = this._depthStencilTexture) == null ? void 0 : _a.dispose();
      this._depthStencilTexture = null;
      this.releaseTextures();
    }
    this._engine._releaseRenderTargetWrapper(this);
  }
};

// node_modules/@babylonjs/core/Engines/engine.common.js
function _DisableTouchAction(canvas) {
  if (!canvas || !canvas.setAttribute) {
    return;
  }
  canvas.setAttribute("touch-action", "none");
  canvas.style.touchAction = "none";
  canvas.style.webkitTapHighlightColor = "transparent";
}
function _CommonInit(commonEngine, canvas, creationOptions) {
  commonEngine._onCanvasFocus = () => {
    commonEngine.onCanvasFocusObservable.notifyObservers(commonEngine);
  };
  commonEngine._onCanvasBlur = () => {
    commonEngine.onCanvasBlurObservable.notifyObservers(commonEngine);
  };
  commonEngine._onCanvasContextMenu = (evt) => {
    if (commonEngine.disableContextMenu) {
      evt.preventDefault();
    }
  };
  canvas.addEventListener("focus", commonEngine._onCanvasFocus);
  canvas.addEventListener("blur", commonEngine._onCanvasBlur);
  canvas.addEventListener("contextmenu", commonEngine._onCanvasContextMenu);
  commonEngine._onBlur = () => {
    if (commonEngine.disablePerformanceMonitorInBackground) {
      commonEngine.performanceMonitor.disable();
    }
    commonEngine._windowIsBackground = true;
  };
  commonEngine._onFocus = () => {
    if (commonEngine.disablePerformanceMonitorInBackground) {
      commonEngine.performanceMonitor.enable();
    }
    commonEngine._windowIsBackground = false;
  };
  commonEngine._onCanvasPointerOut = (ev) => {
    if (document.elementFromPoint(ev.clientX, ev.clientY) !== canvas) {
      commonEngine.onCanvasPointerOutObservable.notifyObservers(ev);
    }
  };
  const hostWindow = commonEngine.getHostWindow();
  if (hostWindow && typeof hostWindow.addEventListener === "function") {
    hostWindow.addEventListener("blur", commonEngine._onBlur);
    hostWindow.addEventListener("focus", commonEngine._onFocus);
  }
  canvas.addEventListener("pointerout", commonEngine._onCanvasPointerOut);
  if (!creationOptions.doNotHandleTouchAction) {
    _DisableTouchAction(canvas);
  }
  if (!AbstractEngine.audioEngine && creationOptions.audioEngine && AbstractEngine.AudioEngineFactory) {
    AbstractEngine.audioEngine = AbstractEngine.AudioEngineFactory(commonEngine.getRenderingCanvas(), commonEngine.getAudioContext(), commonEngine.getAudioDestination());
  }
  if (IsDocumentAvailable()) {
    commonEngine._onFullscreenChange = () => {
      commonEngine.isFullscreen = !!document.fullscreenElement;
      if (commonEngine.isFullscreen && commonEngine._pointerLockRequested && canvas) {
        RequestPointerlock(canvas);
      }
    };
    document.addEventListener("fullscreenchange", commonEngine._onFullscreenChange, false);
    document.addEventListener("webkitfullscreenchange", commonEngine._onFullscreenChange, false);
    commonEngine._onPointerLockChange = () => {
      commonEngine.isPointerLock = document.pointerLockElement === canvas;
    };
    document.addEventListener("pointerlockchange", commonEngine._onPointerLockChange, false);
    document.addEventListener("webkitpointerlockchange", commonEngine._onPointerLockChange, false);
  }
  commonEngine.enableOfflineSupport = AbstractEngine.OfflineProviderFactory !== void 0;
  commonEngine._deterministicLockstep = !!creationOptions.deterministicLockstep;
  commonEngine._lockstepMaxSteps = creationOptions.lockstepMaxSteps || 0;
  commonEngine._timeStep = creationOptions.timeStep || 1 / 60;
}
function _CommonDispose(commonEngine, canvas) {
  if (EngineStore.Instances.length === 1 && AbstractEngine.audioEngine) {
    AbstractEngine.audioEngine.dispose();
    AbstractEngine.audioEngine = null;
  }
  const hostWindow = commonEngine.getHostWindow();
  if (hostWindow && typeof hostWindow.removeEventListener === "function") {
    hostWindow.removeEventListener("blur", commonEngine._onBlur);
    hostWindow.removeEventListener("focus", commonEngine._onFocus);
  }
  if (canvas) {
    canvas.removeEventListener("focus", commonEngine._onCanvasFocus);
    canvas.removeEventListener("blur", commonEngine._onCanvasBlur);
    canvas.removeEventListener("pointerout", commonEngine._onCanvasPointerOut);
    canvas.removeEventListener("contextmenu", commonEngine._onCanvasContextMenu);
  }
  if (IsDocumentAvailable()) {
    document.removeEventListener("fullscreenchange", commonEngine._onFullscreenChange);
    document.removeEventListener("mozfullscreenchange", commonEngine._onFullscreenChange);
    document.removeEventListener("webkitfullscreenchange", commonEngine._onFullscreenChange);
    document.removeEventListener("msfullscreenchange", commonEngine._onFullscreenChange);
    document.removeEventListener("pointerlockchange", commonEngine._onPointerLockChange);
    document.removeEventListener("mspointerlockchange", commonEngine._onPointerLockChange);
    document.removeEventListener("mozpointerlockchange", commonEngine._onPointerLockChange);
    document.removeEventListener("webkitpointerlockchange", commonEngine._onPointerLockChange);
  }
}
function GetFontOffset(font) {
  const text = document.createElement("span");
  text.textContent = "Hg";
  text.style.font = font;
  const block = document.createElement("div");
  block.style.display = "inline-block";
  block.style.width = "1px";
  block.style.height = "0px";
  block.style.verticalAlign = "bottom";
  const div = document.createElement("div");
  div.style.whiteSpace = "nowrap";
  div.appendChild(text);
  div.appendChild(block);
  document.body.appendChild(div);
  let fontAscent = 0;
  let fontHeight = 0;
  try {
    fontHeight = block.getBoundingClientRect().top - text.getBoundingClientRect().top;
    block.style.verticalAlign = "baseline";
    fontAscent = block.getBoundingClientRect().top - text.getBoundingClientRect().top;
  } finally {
    document.body.removeChild(div);
  }
  return { ascent: fontAscent, height: fontHeight, descent: fontHeight - fontAscent };
}
function CreateImageBitmapFromSource(engine, imageSource, options) {
  const promise = new Promise((resolve, reject) => {
    const image = new Image();
    image.onload = () => {
      image.decode().then(() => {
        engine.createImageBitmap(image, options).then((imageBitmap) => {
          resolve(imageBitmap);
        });
      });
    };
    image.onerror = () => {
      reject(`Error loading image ${image.src}`);
    };
    image.src = imageSource;
  });
  return promise;
}
function ResizeImageBitmap(engine, image, bufferWidth, bufferHeight) {
  const canvas = engine.createCanvas(bufferWidth, bufferHeight);
  const context = canvas.getContext("2d");
  if (!context) {
    throw new Error("Unable to get 2d context for resizeImageBitmap");
  }
  context.drawImage(image, 0, 0);
  const buffer = context.getImageData(0, 0, bufferWidth, bufferHeight).data;
  return buffer;
}
function RequestFullscreen(element) {
  const requestFunction = element.requestFullscreen || element.webkitRequestFullscreen;
  if (!requestFunction) {
    return;
  }
  requestFunction.call(element);
}
function ExitFullscreen() {
  const anyDoc = document;
  if (document.exitFullscreen) {
    document.exitFullscreen();
  } else if (anyDoc.webkitCancelFullScreen) {
    anyDoc.webkitCancelFullScreen();
  }
}
function RequestPointerlock(element) {
  if (element.requestPointerLock) {
    const promise = element.requestPointerLock();
    if (promise instanceof Promise)
      promise.then(() => {
        element.focus();
      }).catch(() => {
      });
    else
      element.focus();
  }
}
function ExitPointerlock() {
  if (document.exitPointerLock) {
    document.exitPointerLock();
  }
}

// node_modules/@babylonjs/core/Engines/Extensions/engine.alpha.js
ThinEngine.prototype.setAlphaMode = function(mode, noDepthWriteChange = false) {
  if (this._alphaMode === mode) {
    if (!noDepthWriteChange) {
      const depthMask = mode === 0;
      if (this.depthCullingState.depthMask !== depthMask) {
        this.depthCullingState.depthMask = depthMask;
      }
    }
    return;
  }
  switch (mode) {
    case 0:
      this._alphaState.alphaBlend = false;
      break;
    case 7:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 8:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 2:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 6:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 1:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 3:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ZERO, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 4:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.DST_COLOR, this._gl.ZERO, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 5:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 9:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.CONSTANT_COLOR, this._gl.ONE_MINUS_CONSTANT_COLOR, this._gl.CONSTANT_ALPHA, this._gl.ONE_MINUS_CONSTANT_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 10:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 11:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ONE, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 12:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.DST_ALPHA, this._gl.ONE, this._gl.ZERO, this._gl.ZERO);
      this._alphaState.alphaBlend = true;
      break;
    case 13:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE_MINUS_DST_COLOR, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ONE_MINUS_DST_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 14:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
    case 15:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE, this._gl.ONE, this._gl.ONE, this._gl.ZERO);
      this._alphaState.alphaBlend = true;
      break;
    case 16:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.ONE_MINUS_DST_COLOR, this._gl.ONE_MINUS_SRC_COLOR, this._gl.ZERO, this._gl.ONE);
      this._alphaState.alphaBlend = true;
      break;
    case 17:
      this._alphaState.setAlphaBlendFunctionParameters(this._gl.SRC_ALPHA, this._gl.ONE_MINUS_SRC_ALPHA, this._gl.ONE, this._gl.ONE_MINUS_SRC_ALPHA);
      this._alphaState.alphaBlend = true;
      break;
  }
  if (!noDepthWriteChange) {
    this.depthCullingState.depthMask = mode === 0;
  }
  this._alphaMode = mode;
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.rawTexture.js
ThinEngine.prototype.updateRawTexture = function(texture, data, format, invertY, compression = null, type = 0, useSRGBBuffer = false) {
  if (!texture) {
    return;
  }
  const internalSizedFomat = this._getRGBABufferInternalSizedFormat(type, format, useSRGBBuffer);
  const internalFormat = this._getInternalFormat(format);
  const textureType = this._getWebGLTextureType(type);
  this._bindTextureDirectly(this._gl.TEXTURE_2D, texture, true);
  this._unpackFlipY(invertY === void 0 ? true : invertY ? true : false);
  if (!this._doNotHandleContextLost) {
    texture._bufferView = data;
    texture.format = format;
    texture.type = type;
    texture.invertY = invertY;
    texture._compression = compression;
  }
  if (texture.width % 4 !== 0) {
    this._gl.pixelStorei(this._gl.UNPACK_ALIGNMENT, 1);
  }
  if (compression && data) {
    this._gl.compressedTexImage2D(this._gl.TEXTURE_2D, 0, this.getCaps().s3tc[compression], texture.width, texture.height, 0, data);
  } else {
    this._gl.texImage2D(this._gl.TEXTURE_2D, 0, internalSizedFomat, texture.width, texture.height, 0, internalFormat, textureType, data);
  }
  if (texture.generateMipMaps) {
    this._gl.generateMipmap(this._gl.TEXTURE_2D);
  }
  this._bindTextureDirectly(this._gl.TEXTURE_2D, null);
  texture.isReady = true;
};
ThinEngine.prototype.createRawTexture = function(data, width, height, format, generateMipMaps, invertY, samplingMode, compression = null, type = 0, creationFlags = 0, useSRGBBuffer = false) {
  const texture = new InternalTexture(
    this,
    3
    /* InternalTextureSource.Raw */
  );
  texture.baseWidth = width;
  texture.baseHeight = height;
  texture.width = width;
  texture.height = height;
  texture.format = format;
  texture.generateMipMaps = generateMipMaps;
  texture.samplingMode = samplingMode;
  texture.invertY = invertY;
  texture._compression = compression;
  texture.type = type;
  texture._useSRGBBuffer = this._getUseSRGBBuffer(useSRGBBuffer, !generateMipMaps);
  if (!this._doNotHandleContextLost) {
    texture._bufferView = data;
  }
  this.updateRawTexture(texture, data, format, invertY, compression, type, texture._useSRGBBuffer);
  this._bindTextureDirectly(this._gl.TEXTURE_2D, texture, true);
  const filters = this._getSamplingParameters(samplingMode, generateMipMaps);
  this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MAG_FILTER, filters.mag);
  this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MIN_FILTER, filters.min);
  if (generateMipMaps) {
    this._gl.generateMipmap(this._gl.TEXTURE_2D);
  }
  this._bindTextureDirectly(this._gl.TEXTURE_2D, null);
  this._internalTexturesCache.push(texture);
  return texture;
};
ThinEngine.prototype.createRawCubeTexture = function(data, size, format, type, generateMipMaps, invertY, samplingMode, compression = null) {
  const gl = this._gl;
  const texture = new InternalTexture(
    this,
    8
    /* InternalTextureSource.CubeRaw */
  );
  texture.isCube = true;
  texture.format = format;
  texture.type = type;
  if (!this._doNotHandleContextLost) {
    texture._bufferViewArray = data;
  }
  const textureType = this._getWebGLTextureType(type);
  let internalFormat = this._getInternalFormat(format);
  if (internalFormat === gl.RGB) {
    internalFormat = gl.RGBA;
  }
  if (textureType === gl.FLOAT && !this._caps.textureFloatLinearFiltering) {
    generateMipMaps = false;
    samplingMode = 1;
    Logger.Warn("Float texture filtering is not supported. Mipmap generation and sampling mode are forced to false and TEXTURE_NEAREST_SAMPLINGMODE, respectively.");
  } else if (textureType === this._gl.HALF_FLOAT_OES && !this._caps.textureHalfFloatLinearFiltering) {
    generateMipMaps = false;
    samplingMode = 1;
    Logger.Warn("Half float texture filtering is not supported. Mipmap generation and sampling mode are forced to false and TEXTURE_NEAREST_SAMPLINGMODE, respectively.");
  } else if (textureType === gl.FLOAT && !this._caps.textureFloatRender) {
    generateMipMaps = false;
    Logger.Warn("Render to float textures is not supported. Mipmap generation forced to false.");
  } else if (textureType === gl.HALF_FLOAT && !this._caps.colorBufferFloat) {
    generateMipMaps = false;
    Logger.Warn("Render to half float textures is not supported. Mipmap generation forced to false.");
  }
  const width = size;
  const height = width;
  texture.width = width;
  texture.height = height;
  texture.invertY = invertY;
  texture._compression = compression;
  const isPot = !this.needPOTTextures || IsExponentOfTwo(texture.width) && IsExponentOfTwo(texture.height);
  if (!isPot) {
    generateMipMaps = false;
  }
  if (data) {
    this.updateRawCubeTexture(texture, data, format, type, invertY, compression);
  } else {
    const internalSizedFomat = this._getRGBABufferInternalSizedFormat(type);
    const level = 0;
    this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
    for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
      if (compression) {
        gl.compressedTexImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, level, this.getCaps().s3tc[compression], texture.width, texture.height, 0, void 0);
      } else {
        gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, level, internalSizedFomat, texture.width, texture.height, 0, internalFormat, textureType, null);
      }
    }
    this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, null);
  }
  this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, texture, true);
  if (data && generateMipMaps) {
    this._gl.generateMipmap(this._gl.TEXTURE_CUBE_MAP);
  }
  const filters = this._getSamplingParameters(samplingMode, generateMipMaps);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, filters.mag);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, filters.min);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
  texture.generateMipMaps = generateMipMaps;
  texture.samplingMode = samplingMode;
  texture.isReady = true;
  return texture;
};
ThinEngine.prototype.updateRawCubeTexture = function(texture, data, format, type, invertY, compression = null, level = 0) {
  texture._bufferViewArray = data;
  texture.format = format;
  texture.type = type;
  texture.invertY = invertY;
  texture._compression = compression;
  const gl = this._gl;
  const textureType = this._getWebGLTextureType(type);
  let internalFormat = this._getInternalFormat(format);
  const internalSizedFomat = this._getRGBABufferInternalSizedFormat(type);
  let needConversion = false;
  if (internalFormat === gl.RGB) {
    internalFormat = gl.RGBA;
    needConversion = true;
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
  this._unpackFlipY(invertY === void 0 ? true : invertY ? true : false);
  if (texture.width % 4 !== 0) {
    gl.pixelStorei(gl.UNPACK_ALIGNMENT, 1);
  }
  for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
    let faceData = data[faceIndex];
    if (compression) {
      gl.compressedTexImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, level, this.getCaps().s3tc[compression], texture.width, texture.height, 0, faceData);
    } else {
      if (needConversion) {
        faceData = _convertRGBtoRGBATextureData(faceData, texture.width, texture.height, type);
      }
      gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex, level, internalSizedFomat, texture.width, texture.height, 0, internalFormat, textureType, faceData);
    }
  }
  const isPot = !this.needPOTTextures || IsExponentOfTwo(texture.width) && IsExponentOfTwo(texture.height);
  if (isPot && texture.generateMipMaps && level === 0) {
    this._gl.generateMipmap(this._gl.TEXTURE_CUBE_MAP);
  }
  this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, null);
  texture.isReady = true;
};
ThinEngine.prototype.createRawCubeTextureFromUrl = function(url, scene, size, format, type, noMipmap, callback, mipmapGenerator, onLoad = null, onError = null, samplingMode = 3, invertY = false) {
  const gl = this._gl;
  const texture = this.createRawCubeTexture(null, size, format, type, !noMipmap, invertY, samplingMode, null);
  scene == null ? void 0 : scene.addPendingData(texture);
  texture.url = url;
  texture.isReady = false;
  this._internalTexturesCache.push(texture);
  const onerror = (request, exception) => {
    scene == null ? void 0 : scene.removePendingData(texture);
    if (onError && request) {
      onError(request.status + " " + request.statusText, exception);
    }
  };
  const internalCallback = (data) => {
    if (!texture._hardwareTexture) {
      return;
    }
    const width = texture.width;
    const faceDataArrays = callback(data);
    if (!faceDataArrays) {
      return;
    }
    if (mipmapGenerator) {
      const textureType = this._getWebGLTextureType(type);
      let internalFormat = this._getInternalFormat(format);
      const internalSizedFomat = this._getRGBABufferInternalSizedFormat(type);
      let needConversion = false;
      if (internalFormat === gl.RGB) {
        internalFormat = gl.RGBA;
        needConversion = true;
      }
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
      this._unpackFlipY(false);
      const mipData = mipmapGenerator(faceDataArrays);
      for (let level = 0; level < mipData.length; level++) {
        const mipSize = width >> level;
        for (let faceIndex = 0; faceIndex < 6; faceIndex++) {
          let mipFaceData = mipData[level][faceIndex];
          if (needConversion) {
            mipFaceData = _convertRGBtoRGBATextureData(mipFaceData, mipSize, mipSize, type);
          }
          gl.texImage2D(faceIndex, level, internalSizedFomat, mipSize, mipSize, 0, internalFormat, textureType, mipFaceData);
        }
      }
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
    } else {
      this.updateRawCubeTexture(texture, faceDataArrays, format, type, invertY);
    }
    texture.isReady = true;
    scene == null ? void 0 : scene.removePendingData(texture);
    texture.onLoadedObservable.notifyObservers(texture);
    texture.onLoadedObservable.clear();
    if (onLoad) {
      onLoad();
    }
  };
  this._loadFile(url, (data) => {
    internalCallback(data);
  }, void 0, scene == null ? void 0 : scene.offlineProvider, true, onerror);
  return texture;
};
function _convertRGBtoRGBATextureData(rgbData, width, height, textureType) {
  let rgbaData;
  let val1 = 1;
  if (textureType === 1) {
    rgbaData = new Float32Array(width * height * 4);
  } else if (textureType === 2) {
    rgbaData = new Uint16Array(width * height * 4);
    val1 = 15360;
  } else if (textureType === 7) {
    rgbaData = new Uint32Array(width * height * 4);
  } else {
    rgbaData = new Uint8Array(width * height * 4);
  }
  for (let x = 0; x < width; x++) {
    for (let y = 0; y < height; y++) {
      const index = (y * width + x) * 3;
      const newIndex = (y * width + x) * 4;
      rgbaData[newIndex + 0] = rgbData[index + 0];
      rgbaData[newIndex + 1] = rgbData[index + 1];
      rgbaData[newIndex + 2] = rgbData[index + 2];
      rgbaData[newIndex + 3] = val1;
    }
  }
  return rgbaData;
}
function _makeCreateRawTextureFunction(is3D) {
  return function(data, width, height, depth, format, generateMipMaps, invertY, samplingMode, compression = null, textureType = 0) {
    const target = is3D ? this._gl.TEXTURE_3D : this._gl.TEXTURE_2D_ARRAY;
    const source = is3D ? 10 : 11;
    const texture = new InternalTexture(this, source);
    texture.baseWidth = width;
    texture.baseHeight = height;
    texture.baseDepth = depth;
    texture.width = width;
    texture.height = height;
    texture.depth = depth;
    texture.format = format;
    texture.type = textureType;
    texture.generateMipMaps = generateMipMaps;
    texture.samplingMode = samplingMode;
    if (is3D) {
      texture.is3D = true;
    } else {
      texture.is2DArray = true;
    }
    if (!this._doNotHandleContextLost) {
      texture._bufferView = data;
    }
    if (is3D) {
      this.updateRawTexture3D(texture, data, format, invertY, compression, textureType);
    } else {
      this.updateRawTexture2DArray(texture, data, format, invertY, compression, textureType);
    }
    this._bindTextureDirectly(target, texture, true);
    const filters = this._getSamplingParameters(samplingMode, generateMipMaps);
    this._gl.texParameteri(target, this._gl.TEXTURE_MAG_FILTER, filters.mag);
    this._gl.texParameteri(target, this._gl.TEXTURE_MIN_FILTER, filters.min);
    if (generateMipMaps) {
      this._gl.generateMipmap(target);
    }
    this._bindTextureDirectly(target, null);
    this._internalTexturesCache.push(texture);
    return texture;
  };
}
ThinEngine.prototype.createRawTexture2DArray = _makeCreateRawTextureFunction(false);
ThinEngine.prototype.createRawTexture3D = _makeCreateRawTextureFunction(true);
function _makeUpdateRawTextureFunction(is3D) {
  return function(texture, data, format, invertY, compression = null, textureType = 0) {
    const target = is3D ? this._gl.TEXTURE_3D : this._gl.TEXTURE_2D_ARRAY;
    const internalType = this._getWebGLTextureType(textureType);
    const internalFormat = this._getInternalFormat(format);
    const internalSizedFomat = this._getRGBABufferInternalSizedFormat(textureType, format);
    this._bindTextureDirectly(target, texture, true);
    this._unpackFlipY(invertY === void 0 ? true : invertY ? true : false);
    if (!this._doNotHandleContextLost) {
      texture._bufferView = data;
      texture.format = format;
      texture.invertY = invertY;
      texture._compression = compression;
    }
    if (texture.width % 4 !== 0) {
      this._gl.pixelStorei(this._gl.UNPACK_ALIGNMENT, 1);
    }
    if (compression && data) {
      this._gl.compressedTexImage3D(target, 0, this.getCaps().s3tc[compression], texture.width, texture.height, texture.depth, 0, data);
    } else {
      this._gl.texImage3D(target, 0, internalSizedFomat, texture.width, texture.height, texture.depth, 0, internalFormat, internalType, data);
    }
    if (texture.generateMipMaps) {
      this._gl.generateMipmap(target);
    }
    this._bindTextureDirectly(target, null);
    texture.isReady = true;
  };
}
ThinEngine.prototype.updateRawTexture2DArray = _makeUpdateRawTextureFunction(false);
ThinEngine.prototype.updateRawTexture3D = _makeUpdateRawTextureFunction(true);

// node_modules/@babylonjs/core/Engines/Extensions/engine.dynamicBuffer.js
ThinEngine.prototype.updateDynamicIndexBuffer = function(indexBuffer, indices, offset = 0) {
  this._currentBoundBuffer[this._gl.ELEMENT_ARRAY_BUFFER] = null;
  this.bindIndexBuffer(indexBuffer);
  let view;
  if (indexBuffer.is32Bits) {
    view = indices instanceof Uint32Array ? indices : new Uint32Array(indices);
  } else {
    view = indices instanceof Uint16Array ? indices : new Uint16Array(indices);
  }
  this._gl.bufferData(this._gl.ELEMENT_ARRAY_BUFFER, view, this._gl.DYNAMIC_DRAW);
  this._resetIndexBufferBinding();
};
ThinEngine.prototype.updateDynamicVertexBuffer = function(vertexBuffer, data, byteOffset, byteLength) {
  this.bindArrayBuffer(vertexBuffer);
  if (byteOffset === void 0) {
    byteOffset = 0;
  }
  const dataLength = data.byteLength || data.length;
  if (byteLength === void 0 || byteLength >= dataLength && byteOffset === 0) {
    if (data instanceof Array) {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, new Float32Array(data));
    } else {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, data);
    }
  } else {
    if (data instanceof Array) {
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, new Float32Array(data).subarray(0, byteLength / 4));
    } else {
      if (data instanceof ArrayBuffer) {
        data = new Uint8Array(data, 0, byteLength);
      } else {
        data = new Uint8Array(data.buffer, data.byteOffset, byteLength);
      }
      this._gl.bufferSubData(this._gl.ARRAY_BUFFER, byteOffset, data);
    }
  }
  this._resetVertexBufferBinding();
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.cubeTexture.js
ThinEngine.prototype._createDepthStencilCubeTexture = function(size, options) {
  const internalTexture = new InternalTexture(
    this,
    12
    /* InternalTextureSource.DepthStencil */
  );
  internalTexture.isCube = true;
  if (this.webGLVersion === 1) {
    Logger.Error("Depth cube texture is not supported by WebGL 1.");
    return internalTexture;
  }
  const internalOptions = {
    bilinearFiltering: false,
    comparisonFunction: 0,
    generateStencil: false,
    ...options
  };
  const gl = this._gl;
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, internalTexture, true);
  this._setupDepthStencilTexture(internalTexture, size, internalOptions.bilinearFiltering, internalOptions.comparisonFunction);
  for (let face = 0; face < 6; face++) {
    if (internalOptions.generateStencil) {
      gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, gl.DEPTH24_STENCIL8, size, size, 0, gl.DEPTH_STENCIL, gl.UNSIGNED_INT_24_8, null);
    } else {
      gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, gl.DEPTH_COMPONENT24, size, size, 0, gl.DEPTH_COMPONENT, gl.UNSIGNED_INT, null);
    }
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
  this._internalTexturesCache.push(internalTexture);
  return internalTexture;
};
ThinEngine.prototype._setCubeMapTextureParams = function(texture, loadMipmap, maxLevel) {
  const gl = this._gl;
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, loadMipmap ? gl.LINEAR_MIPMAP_LINEAR : gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  texture.samplingMode = loadMipmap ? 3 : 2;
  if (loadMipmap && this.getCaps().textureMaxLevel && maxLevel !== void 0 && maxLevel > 0) {
    gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAX_LEVEL, maxLevel);
    texture._maxLodLevel = maxLevel;
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
};
ThinEngine.prototype.createCubeTexture = function(rootUrl, scene, files, noMipmap, onLoad = null, onError = null, format, forcedExtension = null, createPolynomials = false, lodScale = 0, lodOffset = 0, fallback = null, loaderOptions, useSRGBBuffer = false, buffer = null) {
  const gl = this._gl;
  return this.createCubeTextureBase(rootUrl, scene, files, !!noMipmap, onLoad, onError, format, forcedExtension, createPolynomials, lodScale, lodOffset, fallback, (texture) => this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true), (texture, imgs) => {
    const width = this.needPOTTextures ? GetExponentOfTwo(imgs[0].width, this._caps.maxCubemapTextureSize) : imgs[0].width;
    const height = width;
    const faces = [
      gl.TEXTURE_CUBE_MAP_POSITIVE_X,
      gl.TEXTURE_CUBE_MAP_POSITIVE_Y,
      gl.TEXTURE_CUBE_MAP_POSITIVE_Z,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_X,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_Y,
      gl.TEXTURE_CUBE_MAP_NEGATIVE_Z
    ];
    this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
    this._unpackFlipY(false);
    const internalFormat = format ? this._getInternalFormat(format, texture._useSRGBBuffer) : texture._useSRGBBuffer ? this._glSRGBExtensionValues.SRGB8_ALPHA8 : gl.RGBA;
    let texelFormat = format ? this._getInternalFormat(format) : gl.RGBA;
    if (texture._useSRGBBuffer && this.webGLVersion === 1) {
      texelFormat = internalFormat;
    }
    for (let index = 0; index < faces.length; index++) {
      if (imgs[index].width !== width || imgs[index].height !== height) {
        this._prepareWorkingCanvas();
        if (!this._workingCanvas || !this._workingContext) {
          Logger.Warn("Cannot create canvas to resize texture.");
          return;
        }
        this._workingCanvas.width = width;
        this._workingCanvas.height = height;
        this._workingContext.drawImage(imgs[index], 0, 0, imgs[index].width, imgs[index].height, 0, 0, width, height);
        gl.texImage2D(faces[index], 0, internalFormat, texelFormat, gl.UNSIGNED_BYTE, this._workingCanvas);
      } else {
        gl.texImage2D(faces[index], 0, internalFormat, texelFormat, gl.UNSIGNED_BYTE, imgs[index]);
      }
    }
    if (!noMipmap) {
      gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
    }
    this._setCubeMapTextureParams(texture, !noMipmap);
    texture.width = width;
    texture.height = height;
    texture.isReady = true;
    if (format) {
      texture.format = format;
    }
    texture.onLoadedObservable.notifyObservers(texture);
    texture.onLoadedObservable.clear();
    if (onLoad) {
      onLoad();
    }
  }, !!useSRGBBuffer, buffer);
};
ThinEngine.prototype.generateMipMapsForCubemap = function(texture, unbind = true) {
  if (texture.generateMipMaps) {
    const gl = this._gl;
    this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
    gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
    if (unbind) {
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
    }
  }
};

// node_modules/@babylonjs/core/Engines/WebGL/webGLRenderTargetWrapper.js
var WebGLRenderTargetWrapper = class extends RenderTargetWrapper {
  setDepthStencilTexture(texture, disposeExisting = true) {
    super.setDepthStencilTexture(texture, disposeExisting);
    if (!texture) {
      return;
    }
    const engine = this._engine;
    const gl = this._context;
    const hardwareTexture = texture._hardwareTexture;
    if (hardwareTexture && texture._autoMSAAManagement && this._MSAAFramebuffer) {
      const currentFB = engine._currentFramebuffer;
      engine._bindUnboundFramebuffer(this._MSAAFramebuffer);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, HasStencilAspect(texture.format) ? gl.DEPTH_STENCIL_ATTACHMENT : gl.DEPTH_ATTACHMENT, gl.RENDERBUFFER, hardwareTexture.getMSAARenderBuffer());
      engine._bindUnboundFramebuffer(currentFB);
    }
  }
  constructor(isMulti, isCube, size, engine, context) {
    super(isMulti, isCube, size, engine);
    this._framebuffer = null;
    this._depthStencilBuffer = null;
    this._MSAAFramebuffer = null;
    this._colorTextureArray = null;
    this._depthStencilTextureArray = null;
    this._disposeOnlyFramebuffers = false;
    this._currentLOD = 0;
    this._context = context;
  }
  _cloneRenderTargetWrapper() {
    let rtw = null;
    if (this._colorTextureArray && this._depthStencilTextureArray) {
      rtw = this._engine.createMultiviewRenderTargetTexture(this.width, this.height);
      rtw.texture.isReady = true;
    } else {
      rtw = super._cloneRenderTargetWrapper();
    }
    return rtw;
  }
  _swapRenderTargetWrapper(target) {
    super._swapRenderTargetWrapper(target);
    target._framebuffer = this._framebuffer;
    target._depthStencilBuffer = this._depthStencilBuffer;
    target._MSAAFramebuffer = this._MSAAFramebuffer;
    target._colorTextureArray = this._colorTextureArray;
    target._depthStencilTextureArray = this._depthStencilTextureArray;
    this._framebuffer = this._depthStencilBuffer = this._MSAAFramebuffer = this._colorTextureArray = this._depthStencilTextureArray = null;
  }
  /**
   * Creates the depth/stencil texture
   * @param comparisonFunction Comparison function to use for the texture
   * @param bilinearFiltering true if bilinear filtering should be used when sampling the texture
   * @param generateStencil true if the stencil aspect should also be created
   * @param samples sample count to use when creating the texture
   * @param format format of the depth texture
   * @param label defines the label to use for the texture (for debugging purpose only)
   * @returns the depth/stencil created texture
   */
  createDepthStencilTexture(comparisonFunction = 0, bilinearFiltering = true, generateStencil = false, samples = 1, format = 14, label) {
    if (this._depthStencilBuffer) {
      const engine = this._engine;
      const currentFrameBuffer = engine._currentFramebuffer;
      const gl = this._context;
      engine._bindUnboundFramebuffer(this._framebuffer);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_STENCIL_ATTACHMENT, gl.RENDERBUFFER, null);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.RENDERBUFFER, null);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.STENCIL_ATTACHMENT, gl.RENDERBUFFER, null);
      engine._bindUnboundFramebuffer(currentFrameBuffer);
      gl.deleteRenderbuffer(this._depthStencilBuffer);
      this._depthStencilBuffer = null;
    }
    return super.createDepthStencilTexture(comparisonFunction, bilinearFiltering, generateStencil, samples, format, label);
  }
  /**
   * Shares the depth buffer of this render target with another render target.
   * @param renderTarget Destination renderTarget
   */
  shareDepth(renderTarget) {
    super.shareDepth(renderTarget);
    const gl = this._context;
    const depthbuffer = this._depthStencilBuffer;
    const framebuffer = renderTarget._MSAAFramebuffer || renderTarget._framebuffer;
    const engine = this._engine;
    if (renderTarget._depthStencilBuffer && renderTarget._depthStencilBuffer !== depthbuffer) {
      gl.deleteRenderbuffer(renderTarget._depthStencilBuffer);
    }
    renderTarget._depthStencilBuffer = depthbuffer;
    const attachment = renderTarget._generateStencilBuffer ? gl.DEPTH_STENCIL_ATTACHMENT : gl.DEPTH_ATTACHMENT;
    engine._bindUnboundFramebuffer(framebuffer);
    gl.framebufferRenderbuffer(gl.FRAMEBUFFER, attachment, gl.RENDERBUFFER, depthbuffer);
    engine._bindUnboundFramebuffer(null);
  }
  /**
   * Binds a texture to this render target on a specific attachment
   * @param texture The texture to bind to the framebuffer
   * @param attachmentIndex Index of the attachment
   * @param faceIndexOrLayer The face or layer of the texture to render to in case of cube texture or array texture
   * @param lodLevel defines the lod level to bind to the frame buffer
   */
  _bindTextureRenderTarget(texture, attachmentIndex = 0, faceIndexOrLayer, lodLevel = 0) {
    var _a, _b;
    const hardwareTexture = texture._hardwareTexture;
    if (!hardwareTexture) {
      return;
    }
    const framebuffer = this._framebuffer;
    const engine = this._engine;
    const currentFB = engine._currentFramebuffer;
    engine._bindUnboundFramebuffer(framebuffer);
    let attachment;
    if (engine.webGLVersion > 1) {
      const gl = this._context;
      attachment = gl["COLOR_ATTACHMENT" + attachmentIndex];
      if (texture.is2DArray || texture.is3D) {
        faceIndexOrLayer = faceIndexOrLayer ?? ((_a = this.layerIndices) == null ? void 0 : _a[attachmentIndex]) ?? 0;
        gl.framebufferTextureLayer(gl.FRAMEBUFFER, attachment, hardwareTexture.underlyingResource, lodLevel, faceIndexOrLayer);
      } else if (texture.isCube) {
        faceIndexOrLayer = faceIndexOrLayer ?? ((_b = this.faceIndices) == null ? void 0 : _b[attachmentIndex]) ?? 0;
        gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndexOrLayer, hardwareTexture.underlyingResource, lodLevel);
      } else {
        gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, gl.TEXTURE_2D, hardwareTexture.underlyingResource, lodLevel);
      }
    } else {
      const gl = this._context;
      attachment = gl["COLOR_ATTACHMENT" + attachmentIndex + "_WEBGL"];
      const target = faceIndexOrLayer !== void 0 ? gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndexOrLayer : gl.TEXTURE_2D;
      gl.framebufferTexture2D(gl.FRAMEBUFFER, attachment, target, hardwareTexture.underlyingResource, lodLevel);
    }
    if (texture._autoMSAAManagement && this._MSAAFramebuffer) {
      const gl = this._context;
      engine._bindUnboundFramebuffer(this._MSAAFramebuffer);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, attachment, gl.RENDERBUFFER, hardwareTexture.getMSAARenderBuffer());
    }
    engine._bindUnboundFramebuffer(currentFB);
  }
  /**
   * Set a texture in the textures array
   * @param texture the texture to set
   * @param index the index in the textures array to set
   * @param disposePrevious If this function should dispose the previous texture
   */
  setTexture(texture, index = 0, disposePrevious = true) {
    super.setTexture(texture, index, disposePrevious);
    this._bindTextureRenderTarget(texture, index);
  }
  /**
   * Sets the layer and face indices of every render target texture
   * @param layers The layer of the texture to be set (make negative to not modify)
   * @param faces The face of the texture to be set (make negative to not modify)
   */
  setLayerAndFaceIndices(layers, faces) {
    var _a;
    super.setLayerAndFaceIndices(layers, faces);
    if (!this.textures || !this.layerIndices || !this.faceIndices) {
      return;
    }
    const textureCount = ((_a = this._attachments) == null ? void 0 : _a.length) ?? this.textures.length;
    for (let index = 0; index < textureCount; index++) {
      const texture = this.textures[index];
      if (!texture) {
        continue;
      }
      if (texture.is2DArray || texture.is3D) {
        this._bindTextureRenderTarget(texture, index, this.layerIndices[index]);
      } else if (texture.isCube) {
        this._bindTextureRenderTarget(texture, index, this.faceIndices[index]);
      } else {
        this._bindTextureRenderTarget(texture, index);
      }
    }
  }
  /**
   * Set the face and layer indices of a texture in the textures array
   * @param index The index of the texture in the textures array to modify
   * @param layer The layer of the texture to be set
   * @param face The face of the texture to be set
   */
  setLayerAndFaceIndex(index = 0, layer, face) {
    super.setLayerAndFaceIndex(index, layer, face);
    if (!this.textures || !this.layerIndices || !this.faceIndices) {
      return;
    }
    const texture = this.textures[index];
    if (texture.is2DArray || texture.is3D) {
      this._bindTextureRenderTarget(this.textures[index], index, this.layerIndices[index]);
    } else if (texture.isCube) {
      this._bindTextureRenderTarget(this.textures[index], index, this.faceIndices[index]);
    }
  }
  resolveMSAATextures() {
    const engine = this._engine;
    const currentFramebuffer = engine._currentFramebuffer;
    engine._bindUnboundFramebuffer(this._MSAAFramebuffer);
    super.resolveMSAATextures();
    engine._bindUnboundFramebuffer(currentFramebuffer);
  }
  dispose(disposeOnlyFramebuffers = this._disposeOnlyFramebuffers) {
    const gl = this._context;
    if (!disposeOnlyFramebuffers) {
      if (this._colorTextureArray) {
        this._context.deleteTexture(this._colorTextureArray);
        this._colorTextureArray = null;
      }
      if (this._depthStencilTextureArray) {
        this._context.deleteTexture(this._depthStencilTextureArray);
        this._depthStencilTextureArray = null;
      }
    }
    if (this._framebuffer) {
      gl.deleteFramebuffer(this._framebuffer);
      this._framebuffer = null;
    }
    if (this._depthStencilBuffer) {
      gl.deleteRenderbuffer(this._depthStencilBuffer);
      this._depthStencilBuffer = null;
    }
    if (this._MSAAFramebuffer) {
      gl.deleteFramebuffer(this._MSAAFramebuffer);
      this._MSAAFramebuffer = null;
    }
    super.dispose(disposeOnlyFramebuffers);
  }
};

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.texture.js
AbstractEngine.prototype.createDepthStencilTexture = function(size, options, rtWrapper) {
  if (options.isCube) {
    const width = size.width || size;
    return this._createDepthStencilCubeTexture(width, options);
  } else {
    return this._createDepthStencilTexture(size, options, rtWrapper);
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.renderTarget.js
ThinEngine.prototype._createHardwareRenderTargetWrapper = function(isMulti, isCube, size) {
  const rtWrapper = new WebGLRenderTargetWrapper(isMulti, isCube, size, this, this._gl);
  this._renderTargetWrapperCache.push(rtWrapper);
  return rtWrapper;
};
ThinEngine.prototype.createRenderTargetTexture = function(size, options) {
  const rtWrapper = this._createHardwareRenderTargetWrapper(false, false, size);
  let generateDepthBuffer = true;
  let generateStencilBuffer = false;
  let noColorAttachment = false;
  let colorAttachment = void 0;
  let samples = 1;
  let label = void 0;
  if (options !== void 0 && typeof options === "object") {
    generateDepthBuffer = options.generateDepthBuffer ?? true;
    generateStencilBuffer = !!options.generateStencilBuffer;
    noColorAttachment = !!options.noColorAttachment;
    colorAttachment = options.colorAttachment;
    samples = options.samples ?? 1;
    label = options.label;
  }
  const texture = colorAttachment || (noColorAttachment ? null : this._createInternalTexture(
    size,
    options,
    true,
    5
    /* InternalTextureSource.RenderTarget */
  ));
  const width = size.width || size;
  const height = size.height || size;
  const currentFrameBuffer = this._currentFramebuffer;
  const gl = this._gl;
  const framebuffer = gl.createFramebuffer();
  this._bindUnboundFramebuffer(framebuffer);
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(generateStencilBuffer, generateDepthBuffer, width, height);
  if (texture && !texture.is2DArray && !texture.is3D) {
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture._hardwareTexture.underlyingResource, 0);
  }
  this._bindUnboundFramebuffer(currentFrameBuffer);
  rtWrapper.label = label ?? "RenderTargetWrapper";
  rtWrapper._framebuffer = framebuffer;
  rtWrapper._generateDepthBuffer = generateDepthBuffer;
  rtWrapper._generateStencilBuffer = generateStencilBuffer;
  rtWrapper.setTextures(texture);
  if (!colorAttachment) {
    this.updateRenderTargetTextureSampleCount(rtWrapper, samples);
  } else {
    rtWrapper._samples = colorAttachment.samples;
    if (colorAttachment.samples > 1) {
      const msaaRenderBuffer = colorAttachment._hardwareTexture.getMSAARenderBuffer(0);
      rtWrapper._MSAAFramebuffer = gl.createFramebuffer();
      this._bindUnboundFramebuffer(rtWrapper._MSAAFramebuffer);
      gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.RENDERBUFFER, msaaRenderBuffer);
      this._bindUnboundFramebuffer(null);
    }
  }
  return rtWrapper;
};
ThinEngine.prototype._createDepthStencilTexture = function(size, options, rtWrapper) {
  const gl = this._gl;
  const layers = size.layers || 0;
  const depth = size.depth || 0;
  let target = gl.TEXTURE_2D;
  if (layers !== 0) {
    target = gl.TEXTURE_2D_ARRAY;
  } else if (depth !== 0) {
    target = gl.TEXTURE_3D;
  }
  const internalTexture = new InternalTexture(
    this,
    12
    /* InternalTextureSource.DepthStencil */
  );
  internalTexture.label = options.label;
  if (!this._caps.depthTextureExtension) {
    Logger.Error("Depth texture is not supported by your browser or hardware.");
    return internalTexture;
  }
  const internalOptions = {
    bilinearFiltering: false,
    comparisonFunction: 0,
    generateStencil: false,
    ...options
  };
  this._bindTextureDirectly(target, internalTexture, true);
  this._setupDepthStencilTexture(internalTexture, size, internalOptions.comparisonFunction === 0 ? false : internalOptions.bilinearFiltering, internalOptions.comparisonFunction, internalOptions.samples);
  if (internalOptions.depthTextureFormat !== void 0) {
    if (internalOptions.depthTextureFormat !== 15 && internalOptions.depthTextureFormat !== 16 && internalOptions.depthTextureFormat !== 17 && internalOptions.depthTextureFormat !== 13 && internalOptions.depthTextureFormat !== 14 && internalOptions.depthTextureFormat !== 18) {
      Logger.Error(`Depth texture ${internalOptions.depthTextureFormat} format is not supported.`);
      return internalTexture;
    }
    internalTexture.format = internalOptions.depthTextureFormat;
  } else {
    internalTexture.format = internalOptions.generateStencil ? 13 : 16;
  }
  const hasStencil = HasStencilAspect(internalTexture.format);
  const type = this._getWebGLTextureTypeFromDepthTextureFormat(internalTexture.format);
  const format = hasStencil ? gl.DEPTH_STENCIL : gl.DEPTH_COMPONENT;
  const internalFormat = this._getInternalFormatFromDepthTextureFormat(internalTexture.format, true, hasStencil);
  if (internalTexture.is2DArray) {
    gl.texImage3D(target, 0, internalFormat, internalTexture.width, internalTexture.height, layers, 0, format, type, null);
  } else if (internalTexture.is3D) {
    gl.texImage3D(target, 0, internalFormat, internalTexture.width, internalTexture.height, depth, 0, format, type, null);
  } else {
    gl.texImage2D(target, 0, internalFormat, internalTexture.width, internalTexture.height, 0, format, type, null);
  }
  this._bindTextureDirectly(target, null);
  this._internalTexturesCache.push(internalTexture);
  if (rtWrapper._depthStencilBuffer) {
    gl.deleteRenderbuffer(rtWrapper._depthStencilBuffer);
    rtWrapper._depthStencilBuffer = null;
  }
  this._bindUnboundFramebuffer(rtWrapper._MSAAFramebuffer ?? rtWrapper._framebuffer);
  rtWrapper._generateStencilBuffer = hasStencil;
  rtWrapper._depthStencilTextureWithStencil = hasStencil;
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(rtWrapper._generateStencilBuffer, rtWrapper._generateDepthBuffer, rtWrapper.width, rtWrapper.height, rtWrapper.samples, internalTexture.format);
  this._bindUnboundFramebuffer(null);
  return internalTexture;
};
ThinEngine.prototype.updateRenderTargetTextureSampleCount = function(rtWrapper, samples) {
  var _a;
  if (this.webGLVersion < 2 || !rtWrapper) {
    return 1;
  }
  if (rtWrapper.samples === samples) {
    return samples;
  }
  const gl = this._gl;
  samples = Math.min(samples, this.getCaps().maxMSAASamples);
  if (rtWrapper._depthStencilBuffer) {
    gl.deleteRenderbuffer(rtWrapper._depthStencilBuffer);
    rtWrapper._depthStencilBuffer = null;
  }
  if (rtWrapper._MSAAFramebuffer) {
    gl.deleteFramebuffer(rtWrapper._MSAAFramebuffer);
    rtWrapper._MSAAFramebuffer = null;
  }
  const hardwareTexture = (_a = rtWrapper.texture) == null ? void 0 : _a._hardwareTexture;
  hardwareTexture == null ? void 0 : hardwareTexture.releaseMSAARenderBuffers();
  if (rtWrapper.texture && samples > 1 && typeof gl.renderbufferStorageMultisample === "function") {
    const framebuffer = gl.createFramebuffer();
    if (!framebuffer) {
      throw new Error("Unable to create multi sampled framebuffer");
    }
    rtWrapper._MSAAFramebuffer = framebuffer;
    this._bindUnboundFramebuffer(rtWrapper._MSAAFramebuffer);
    const colorRenderbuffer = this._createRenderBuffer(rtWrapper.texture.width, rtWrapper.texture.height, samples, -1, this._getRGBABufferInternalSizedFormat(rtWrapper.texture.type, rtWrapper.texture.format, rtWrapper.texture._useSRGBBuffer), gl.COLOR_ATTACHMENT0, false);
    if (!colorRenderbuffer) {
      throw new Error("Unable to create multi sampled framebuffer");
    }
    hardwareTexture == null ? void 0 : hardwareTexture.addMSAARenderBuffer(colorRenderbuffer);
  }
  this._bindUnboundFramebuffer(rtWrapper._MSAAFramebuffer ?? rtWrapper._framebuffer);
  if (rtWrapper.texture) {
    rtWrapper.texture.samples = samples;
  }
  rtWrapper._samples = samples;
  const depthFormat = rtWrapper._depthStencilTexture ? rtWrapper._depthStencilTexture.format : void 0;
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(rtWrapper._generateStencilBuffer, rtWrapper._generateDepthBuffer, rtWrapper.width, rtWrapper.height, samples, depthFormat);
  this._bindUnboundFramebuffer(null);
  return samples;
};
ThinEngine.prototype._setupDepthStencilTexture = function(internalTexture, size, bilinearFiltering, comparisonFunction, samples = 1) {
  const width = size.width ?? size;
  const height = size.height ?? size;
  const layers = size.layers || 0;
  const depth = size.depth || 0;
  internalTexture.baseWidth = width;
  internalTexture.baseHeight = height;
  internalTexture.width = width;
  internalTexture.height = height;
  internalTexture.is2DArray = layers > 0;
  internalTexture.depth = layers || depth;
  internalTexture.isReady = true;
  internalTexture.samples = samples;
  internalTexture.generateMipMaps = false;
  internalTexture.samplingMode = bilinearFiltering ? 2 : 1;
  internalTexture.type = 0;
  internalTexture._comparisonFunction = comparisonFunction;
  const gl = this._gl;
  const target = this._getTextureTarget(internalTexture);
  const samplingParameters = this._getSamplingParameters(internalTexture.samplingMode, false);
  gl.texParameteri(target, gl.TEXTURE_MAG_FILTER, samplingParameters.mag);
  gl.texParameteri(target, gl.TEXTURE_MIN_FILTER, samplingParameters.min);
  gl.texParameteri(target, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(target, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  if (this.webGLVersion > 1) {
    if (comparisonFunction === 0) {
      gl.texParameteri(target, gl.TEXTURE_COMPARE_FUNC, 515);
      gl.texParameteri(target, gl.TEXTURE_COMPARE_MODE, gl.NONE);
    } else {
      gl.texParameteri(target, gl.TEXTURE_COMPARE_FUNC, comparisonFunction);
      gl.texParameteri(target, gl.TEXTURE_COMPARE_MODE, gl.COMPARE_REF_TO_TEXTURE);
    }
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.renderTargetTexture.js
ThinEngine.prototype.setDepthStencilTexture = function(channel, uniform, texture, name) {
  if (channel === void 0) {
    return;
  }
  if (uniform) {
    this._boundUniforms[channel] = uniform;
  }
  if (!texture || !texture.depthStencilTexture) {
    this._setTexture(channel, null, void 0, void 0, name);
  } else {
    this._setTexture(channel, texture, false, true, name);
  }
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.renderTargetCube.js
ThinEngine.prototype.createRenderTargetCubeTexture = function(size, options) {
  const rtWrapper = this._createHardwareRenderTargetWrapper(false, true, size);
  const fullOptions = {
    generateMipMaps: true,
    generateDepthBuffer: true,
    generateStencilBuffer: false,
    type: 0,
    samplingMode: 3,
    format: 5,
    ...options
  };
  fullOptions.generateStencilBuffer = fullOptions.generateDepthBuffer && fullOptions.generateStencilBuffer;
  if (fullOptions.type === 1 && !this._caps.textureFloatLinearFiltering) {
    fullOptions.samplingMode = 1;
  } else if (fullOptions.type === 2 && !this._caps.textureHalfFloatLinearFiltering) {
    fullOptions.samplingMode = 1;
  }
  const gl = this._gl;
  const texture = new InternalTexture(
    this,
    5
    /* InternalTextureSource.RenderTarget */
  );
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, texture, true);
  const filters = this._getSamplingParameters(fullOptions.samplingMode, fullOptions.generateMipMaps);
  if (fullOptions.type === 1 && !this._caps.textureFloat) {
    fullOptions.type = 0;
    Logger.Warn("Float textures are not supported. Cube render target forced to TEXTURETYPE_UNESIGNED_BYTE type");
  }
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, filters.mag);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, filters.min);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  for (let face = 0; face < 6; face++) {
    gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + face, 0, this._getRGBABufferInternalSizedFormat(fullOptions.type, fullOptions.format), size, size, 0, this._getInternalFormat(fullOptions.format), this._getWebGLTextureType(fullOptions.type), null);
  }
  const framebuffer = gl.createFramebuffer();
  this._bindUnboundFramebuffer(framebuffer);
  rtWrapper._depthStencilBuffer = this._setupFramebufferDepthAttachments(fullOptions.generateStencilBuffer, fullOptions.generateDepthBuffer, size, size);
  if (fullOptions.generateMipMaps) {
    gl.generateMipmap(gl.TEXTURE_CUBE_MAP);
  }
  this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
  this._bindUnboundFramebuffer(null);
  rtWrapper._framebuffer = framebuffer;
  rtWrapper._generateDepthBuffer = fullOptions.generateDepthBuffer;
  rtWrapper._generateStencilBuffer = fullOptions.generateStencilBuffer;
  texture.width = size;
  texture.height = size;
  texture.isReady = true;
  texture.isCube = true;
  texture.samples = 1;
  texture.generateMipMaps = fullOptions.generateMipMaps;
  texture.samplingMode = fullOptions.samplingMode;
  texture.type = fullOptions.type;
  texture.format = fullOptions.format;
  this._internalTexturesCache.push(texture);
  rtWrapper.setTextures(texture);
  return rtWrapper;
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.prefilteredCubeTexture.js
ThinEngine.prototype.createPrefilteredCubeTexture = function(rootUrl, scene, lodScale, lodOffset, onLoad = null, onError = null, format, forcedExtension = null, createPolynomials = true) {
  const callback = async (loadData) => {
    if (!loadData) {
      if (onLoad) {
        onLoad(null);
      }
      return;
    }
    const texture = loadData.texture;
    if (!createPolynomials) {
      texture._sphericalPolynomial = new SphericalPolynomial();
    } else if (loadData.info.sphericalPolynomial) {
      texture._sphericalPolynomial = loadData.info.sphericalPolynomial;
    }
    texture._source = 9;
    if (this.getCaps().textureLOD) {
      if (onLoad) {
        onLoad(texture);
      }
      return;
    }
    const mipSlices = 3;
    const gl = this._gl;
    const width = loadData.width;
    if (!width) {
      return;
    }
    const { DDSTools } = await import("./dds-EQ4Q3SPB.js");
    const textures = [];
    for (let i = 0; i < mipSlices; i++) {
      const smoothness = i / (mipSlices - 1);
      const roughness = 1 - smoothness;
      const minLODIndex = lodOffset;
      const maxLODIndex = Math.log2(width) * lodScale + lodOffset;
      const lodIndex = minLODIndex + (maxLODIndex - minLODIndex) * roughness;
      const mipmapIndex = Math.round(Math.min(Math.max(lodIndex, 0), maxLODIndex));
      const glTextureFromLod = new InternalTexture(
        this,
        2
        /* InternalTextureSource.Temp */
      );
      glTextureFromLod.type = texture.type;
      glTextureFromLod.format = texture.format;
      glTextureFromLod.width = Math.pow(2, Math.max(Math.log2(width) - mipmapIndex, 0));
      glTextureFromLod.height = glTextureFromLod.width;
      glTextureFromLod.isCube = true;
      glTextureFromLod._cachedWrapU = 0;
      glTextureFromLod._cachedWrapV = 0;
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, glTextureFromLod, true);
      glTextureFromLod.samplingMode = 2;
      gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      if (loadData.isDDS) {
        const info = loadData.info;
        const data = loadData.data;
        this._unpackFlipY(info.isCompressed);
        DDSTools.UploadDDSLevels(this, glTextureFromLod, data, info, true, 6, mipmapIndex);
      } else {
        Logger.Warn("DDS is the only prefiltered cube map supported so far.");
      }
      this._bindTextureDirectly(gl.TEXTURE_CUBE_MAP, null);
      const lodTexture = new BaseTexture(scene);
      lodTexture._isCube = true;
      lodTexture._texture = glTextureFromLod;
      glTextureFromLod.isReady = true;
      textures.push(lodTexture);
    }
    texture._lodTextureHigh = textures[2];
    texture._lodTextureMid = textures[1];
    texture._lodTextureLow = textures[0];
    if (onLoad) {
      onLoad(texture);
    }
  };
  return this.createCubeTexture(rootUrl, scene, null, false, callback, onError, format, forcedExtension, createPolynomials, lodScale, lodOffset);
};

// node_modules/@babylonjs/core/Engines/Extensions/engine.uniformBuffer.js
ThinEngine.prototype.createUniformBuffer = function(elements, _label) {
  const ubo = this._gl.createBuffer();
  if (!ubo) {
    throw new Error("Unable to create uniform buffer");
  }
  const result = new WebGLDataBuffer(ubo);
  this.bindUniformBuffer(result);
  if (elements instanceof Float32Array) {
    this._gl.bufferData(this._gl.UNIFORM_BUFFER, elements, this._gl.STATIC_DRAW);
  } else {
    this._gl.bufferData(this._gl.UNIFORM_BUFFER, new Float32Array(elements), this._gl.STATIC_DRAW);
  }
  this.bindUniformBuffer(null);
  result.references = 1;
  return result;
};
ThinEngine.prototype.createDynamicUniformBuffer = function(elements, _label) {
  const ubo = this._gl.createBuffer();
  if (!ubo) {
    throw new Error("Unable to create dynamic uniform buffer");
  }
  const result = new WebGLDataBuffer(ubo);
  this.bindUniformBuffer(result);
  if (elements instanceof Float32Array) {
    this._gl.bufferData(this._gl.UNIFORM_BUFFER, elements, this._gl.DYNAMIC_DRAW);
  } else {
    this._gl.bufferData(this._gl.UNIFORM_BUFFER, new Float32Array(elements), this._gl.DYNAMIC_DRAW);
  }
  this.bindUniformBuffer(null);
  result.references = 1;
  return result;
};
ThinEngine.prototype.updateUniformBuffer = function(uniformBuffer, elements, offset, count) {
  this.bindUniformBuffer(uniformBuffer);
  if (offset === void 0) {
    offset = 0;
  }
  if (count === void 0) {
    if (elements instanceof Float32Array) {
      this._gl.bufferSubData(this._gl.UNIFORM_BUFFER, offset, elements);
    } else {
      this._gl.bufferSubData(this._gl.UNIFORM_BUFFER, offset, new Float32Array(elements));
    }
  } else {
    if (elements instanceof Float32Array) {
      this._gl.bufferSubData(this._gl.UNIFORM_BUFFER, 0, elements.subarray(offset, offset + count));
    } else {
      this._gl.bufferSubData(this._gl.UNIFORM_BUFFER, 0, new Float32Array(elements).subarray(offset, offset + count));
    }
  }
  this.bindUniformBuffer(null);
};
ThinEngine.prototype.bindUniformBuffer = function(buffer) {
  this._gl.bindBuffer(this._gl.UNIFORM_BUFFER, buffer ? buffer.underlyingResource : null);
};
ThinEngine.prototype.bindUniformBufferBase = function(buffer, location, name) {
  this._gl.bindBufferBase(this._gl.UNIFORM_BUFFER, location, buffer ? buffer.underlyingResource : null);
};
ThinEngine.prototype.bindUniformBlock = function(pipelineContext, blockName, index) {
  const program = pipelineContext.program;
  const uniformLocation = this._gl.getUniformBlockIndex(program, blockName);
  if (uniformLocation !== 4294967295) {
    this._gl.uniformBlockBinding(program, uniformLocation, index);
  }
};

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.loadingScreen.js
AbstractEngine.prototype.displayLoadingUI = function() {
  if (!IsWindowObjectExist()) {
    return;
  }
  const loadingScreen = this.loadingScreen;
  if (loadingScreen) {
    loadingScreen.displayLoadingUI();
  }
};
AbstractEngine.prototype.hideLoadingUI = function() {
  if (!IsWindowObjectExist()) {
    return;
  }
  const loadingScreen = this._loadingScreen;
  if (loadingScreen) {
    loadingScreen.hideLoadingUI();
  }
};
Object.defineProperty(AbstractEngine.prototype, "loadingScreen", {
  get: function() {
    if (!this._loadingScreen && this._renderingCanvas) {
      this._loadingScreen = AbstractEngine.DefaultLoadingScreenFactory(this._renderingCanvas);
    }
    return this._loadingScreen;
  },
  set: function(value) {
    this._loadingScreen = value;
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(AbstractEngine.prototype, "loadingUIText", {
  set: function(value) {
    this.loadingScreen.loadingUIText = value;
  },
  enumerable: true,
  configurable: true
});
Object.defineProperty(AbstractEngine.prototype, "loadingUIBackgroundColor", {
  set: function(value) {
    this.loadingScreen.loadingUIBackgroundColor = value;
  },
  enumerable: true,
  configurable: true
});

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.dom.js
AbstractEngine.prototype.getInputElement = function() {
  return this._renderingCanvas;
};
AbstractEngine.prototype.getRenderingCanvasClientRect = function() {
  if (!this._renderingCanvas) {
    return null;
  }
  return this._renderingCanvas.getBoundingClientRect();
};
AbstractEngine.prototype.getInputElementClientRect = function() {
  if (!this._renderingCanvas) {
    return null;
  }
  return this.getInputElement().getBoundingClientRect();
};
AbstractEngine.prototype.getAspectRatio = function(viewportOwner, useScreen = false) {
  const viewport = viewportOwner.viewport;
  return this.getRenderWidth(useScreen) * viewport.width / (this.getRenderHeight(useScreen) * viewport.height);
};
AbstractEngine.prototype.getScreenAspectRatio = function() {
  return this.getRenderWidth(true) / this.getRenderHeight(true);
};
AbstractEngine.prototype._verifyPointerLock = function() {
  var _a;
  (_a = this._onPointerLockChange) == null ? void 0 : _a.call(this);
};

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.alpha.js
AbstractEngine.prototype.setAlphaEquation = function(equation) {
  if (this._alphaEquation === equation) {
    return;
  }
  switch (equation) {
    case 0:
      this._alphaState.setAlphaEquationParameters(32774, 32774);
      break;
    case 1:
      this._alphaState.setAlphaEquationParameters(32778, 32778);
      break;
    case 2:
      this._alphaState.setAlphaEquationParameters(32779, 32779);
      break;
    case 3:
      this._alphaState.setAlphaEquationParameters(32776, 32776);
      break;
    case 4:
      this._alphaState.setAlphaEquationParameters(32775, 32775);
      break;
    case 5:
      this._alphaState.setAlphaEquationParameters(32775, 32774);
      break;
  }
  this._alphaEquation = equation;
};

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.states.js
AbstractEngine.prototype.getInputElement = function() {
  return this._renderingCanvas;
};
AbstractEngine.prototype.getDepthFunction = function() {
  return this._depthCullingState.depthFunc;
};
AbstractEngine.prototype.setDepthFunction = function(depthFunc) {
  this._depthCullingState.depthFunc = depthFunc;
};
AbstractEngine.prototype.setDepthFunctionToGreater = function() {
  this.setDepthFunction(516);
};
AbstractEngine.prototype.setDepthFunctionToGreaterOrEqual = function() {
  this.setDepthFunction(518);
};
AbstractEngine.prototype.setDepthFunctionToLess = function() {
  this.setDepthFunction(513);
};
AbstractEngine.prototype.setDepthFunctionToLessOrEqual = function() {
  this.setDepthFunction(515);
};
AbstractEngine.prototype.getDepthWrite = function() {
  return this._depthCullingState.depthMask;
};
AbstractEngine.prototype.setDepthWrite = function(enable) {
  this._depthCullingState.depthMask = enable;
};
AbstractEngine.prototype.getStencilBuffer = function() {
  return this._stencilState.stencilTest;
};
AbstractEngine.prototype.setStencilBuffer = function(enable) {
  this._stencilState.stencilTest = enable;
};
AbstractEngine.prototype.getStencilMask = function() {
  return this._stencilState.stencilMask;
};
AbstractEngine.prototype.setStencilMask = function(mask) {
  this._stencilState.stencilMask = mask;
};
AbstractEngine.prototype.getStencilFunction = function() {
  return this._stencilState.stencilFunc;
};
AbstractEngine.prototype.getStencilFunctionReference = function() {
  return this._stencilState.stencilFuncRef;
};
AbstractEngine.prototype.getStencilFunctionMask = function() {
  return this._stencilState.stencilFuncMask;
};
AbstractEngine.prototype.setStencilFunction = function(stencilFunc) {
  this._stencilState.stencilFunc = stencilFunc;
};
AbstractEngine.prototype.setStencilFunctionReference = function(reference) {
  this._stencilState.stencilFuncRef = reference;
};
AbstractEngine.prototype.setStencilFunctionMask = function(mask) {
  this._stencilState.stencilFuncMask = mask;
};
AbstractEngine.prototype.getStencilOperationFail = function() {
  return this._stencilState.stencilOpStencilFail;
};
AbstractEngine.prototype.getStencilOperationDepthFail = function() {
  return this._stencilState.stencilOpDepthFail;
};
AbstractEngine.prototype.getStencilOperationPass = function() {
  return this._stencilState.stencilOpStencilDepthPass;
};
AbstractEngine.prototype.setStencilOperationFail = function(operation) {
  this._stencilState.stencilOpStencilFail = operation;
};
AbstractEngine.prototype.setStencilOperationDepthFail = function(operation) {
  this._stencilState.stencilOpDepthFail = operation;
};
AbstractEngine.prototype.setStencilOperationPass = function(operation) {
  this._stencilState.stencilOpStencilDepthPass = operation;
};
AbstractEngine.prototype.cacheStencilState = function() {
  this._cachedStencilBuffer = this.getStencilBuffer();
  this._cachedStencilFunction = this.getStencilFunction();
  this._cachedStencilMask = this.getStencilMask();
  this._cachedStencilOperationPass = this.getStencilOperationPass();
  this._cachedStencilOperationFail = this.getStencilOperationFail();
  this._cachedStencilOperationDepthFail = this.getStencilOperationDepthFail();
  this._cachedStencilReference = this.getStencilFunctionReference();
};
AbstractEngine.prototype.restoreStencilState = function() {
  this.setStencilFunction(this._cachedStencilFunction);
  this.setStencilMask(this._cachedStencilMask);
  this.setStencilBuffer(this._cachedStencilBuffer);
  this.setStencilOperationPass(this._cachedStencilOperationPass);
  this.setStencilOperationFail(this._cachedStencilOperationFail);
  this.setStencilOperationDepthFail(this._cachedStencilOperationDepthFail);
  this.setStencilFunctionReference(this._cachedStencilReference);
};
AbstractEngine.prototype.setAlphaConstants = function(r, g, b, a) {
  this._alphaState.setAlphaBlendConstants(r, g, b, a);
};
AbstractEngine.prototype.getAlphaMode = function() {
  return this._alphaMode;
};
AbstractEngine.prototype.getAlphaEquation = function() {
  return this._alphaEquation;
};

// node_modules/@babylonjs/core/Engines/AbstractEngine/abstractEngine.renderPass.js
AbstractEngine.prototype.getRenderPassNames = function() {
  return this._renderPassNames;
};
AbstractEngine.prototype.getCurrentRenderPassName = function() {
  return this._renderPassNames[this.currentRenderPassId];
};
AbstractEngine.prototype.createRenderPassId = function(name) {
  const id = ++AbstractEngine._RenderPassIdCounter;
  this._renderPassNames[id] = name ?? "NONAME";
  return id;
};
AbstractEngine.prototype.releaseRenderPassId = function(id) {
  this._renderPassNames[id] = void 0;
  for (let s = 0; s < this.scenes.length; ++s) {
    const scene = this.scenes[s];
    for (let m = 0; m < scene.meshes.length; ++m) {
      const mesh = scene.meshes[m];
      if (mesh.subMeshes) {
        for (let b = 0; b < mesh.subMeshes.length; ++b) {
          const subMesh = mesh.subMeshes[b];
          subMesh._removeDrawWrapper(id);
        }
      }
    }
  }
};

// node_modules/@babylonjs/core/Engines/engine.js
var Engine = class _Engine extends ThinEngine {
  /**
   * Returns the current npm package of the sdk
   */
  // Not mixed with Version for tooling purpose.
  static get NpmPackage() {
    return AbstractEngine.NpmPackage;
  }
  /**
   * Returns the current version of the framework
   */
  static get Version() {
    return AbstractEngine.Version;
  }
  /** Gets the list of created engines */
  static get Instances() {
    return EngineStore.Instances;
  }
  /**
   * Gets the latest created engine
   */
  static get LastCreatedEngine() {
    return EngineStore.LastCreatedEngine;
  }
  /**
   * Gets the latest created scene
   */
  static get LastCreatedScene() {
    return EngineStore.LastCreatedScene;
  }
  /** @internal */
  // eslint-disable-next-line jsdoc/require-returns-check
  /**
   * Method called to create the default loading screen.
   * This can be overridden in your own app.
   * @param canvas The rendering canvas element
   * @returns The loading screen
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  static DefaultLoadingScreenFactory(canvas) {
    return AbstractEngine.DefaultLoadingScreenFactory(canvas);
  }
  get _supportsHardwareTextureRescaling() {
    return !!_Engine._RescalePostProcessFactory;
  }
  _measureFps() {
    this._performanceMonitor.sampleFrame();
    this._fps = this._performanceMonitor.averageFPS;
    this._deltaTime = this._performanceMonitor.instantaneousFrameTime || 0;
  }
  /**
   * Gets the performance monitor attached to this engine
   * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
   */
  get performanceMonitor() {
    return this._performanceMonitor;
  }
  // Events
  /**
   * Creates a new engine
   * @param canvasOrContext defines the canvas or WebGL context to use for rendering. If you provide a WebGL context, Babylon.js will not hook events on the canvas (like pointers, keyboards, etc...) so no event observables will be available. This is mostly used when Babylon.js is used as a plugin on a system which already used the WebGL context
   * @param antialias defines enable antialiasing (default: false)
   * @param options defines further options to be sent to the getContext() function
   * @param adaptToDeviceRatio defines whether to adapt to the device's viewport characteristics (default: false)
   */
  constructor(canvasOrContext, antialias, options, adaptToDeviceRatio = false) {
    super(canvasOrContext, antialias, options, adaptToDeviceRatio);
    this.customAnimationFrameRequester = null;
    this._performanceMonitor = new PerformanceMonitor();
    this._drawCalls = new PerfCounter();
    if (!canvasOrContext) {
      return;
    }
    this._features.supportRenderPasses = true;
    options = this._creationOptions;
  }
  _initGLContext() {
    super._initGLContext();
    this._rescalePostProcess = null;
  }
  /**
   * Shared initialization across engines types.
   * @param canvas The canvas associated with this instance of the engine.
   */
  _sharedInit(canvas) {
    super._sharedInit(canvas);
    _CommonInit(this, canvas, this._creationOptions);
  }
  /**
   * Resize an image and returns the image data as an uint8array
   * @param image image to resize
   * @param bufferWidth destination buffer width
   * @param bufferHeight destination buffer height
   * @returns an uint8array containing RGBA values of bufferWidth * bufferHeight size
   */
  resizeImageBitmap(image, bufferWidth, bufferHeight) {
    return ResizeImageBitmap(this, image, bufferWidth, bufferHeight);
  }
  /**
   * Engine abstraction for loading and creating an image bitmap from a given source string.
   * @param imageSource source to load the image from.
   * @param options An object that sets options for the image's extraction.
   * @returns ImageBitmap
   */
  _createImageBitmapFromSource(imageSource, options) {
    return CreateImageBitmapFromSource(this, imageSource, options);
  }
  /**
   * Toggle full screen mode
   * @param requestPointerLock defines if a pointer lock should be requested from the user
   */
  switchFullscreen(requestPointerLock) {
    if (this.isFullscreen) {
      this.exitFullscreen();
    } else {
      this.enterFullscreen(requestPointerLock);
    }
  }
  /**
   * Enters full screen mode
   * @param requestPointerLock defines if a pointer lock should be requested from the user
   */
  enterFullscreen(requestPointerLock) {
    if (!this.isFullscreen) {
      this._pointerLockRequested = requestPointerLock;
      if (this._renderingCanvas) {
        RequestFullscreen(this._renderingCanvas);
      }
    }
  }
  /**
   * Exits full screen mode
   */
  exitFullscreen() {
    if (this.isFullscreen) {
      ExitFullscreen();
    }
  }
  /** States */
  /**
   * Sets a boolean indicating if the dithering state is enabled or disabled
   * @param value defines the dithering state
   */
  setDitheringState(value) {
    if (value) {
      this._gl.enable(this._gl.DITHER);
    } else {
      this._gl.disable(this._gl.DITHER);
    }
  }
  /**
   * Sets a boolean indicating if the rasterizer state is enabled or disabled
   * @param value defines the rasterizer state
   */
  setRasterizerState(value) {
    if (value) {
      this._gl.disable(this._gl.RASTERIZER_DISCARD);
    } else {
      this._gl.enable(this._gl.RASTERIZER_DISCARD);
    }
  }
  /**
   * Directly set the WebGL Viewport
   * @param x defines the x coordinate of the viewport (in screen space)
   * @param y defines the y coordinate of the viewport (in screen space)
   * @param width defines the width of the viewport (in screen space)
   * @param height defines the height of the viewport (in screen space)
   * @returns the current viewport Object (if any) that is being replaced by this call. You can restore this viewport later on to go back to the original state
   */
  setDirectViewport(x, y, width, height) {
    const currentViewport = this._cachedViewport;
    this._cachedViewport = null;
    this._viewport(x, y, width, height);
    return currentViewport;
  }
  /**
   * Executes a scissor clear (ie. a clear on a specific portion of the screen)
   * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
   * @param y defines the y-coordinate of the corner of the clear rectangle
   * @param width defines the width of the clear rectangle
   * @param height defines the height of the clear rectangle
   * @param clearColor defines the clear color
   */
  scissorClear(x, y, width, height, clearColor) {
    this.enableScissor(x, y, width, height);
    this.clear(clearColor, true, true, true);
    this.disableScissor();
  }
  /**
   * Enable scissor test on a specific rectangle (ie. render will only be executed on a specific portion of the screen)
   * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
   * @param y defines the y-coordinate of the corner of the clear rectangle
   * @param width defines the width of the clear rectangle
   * @param height defines the height of the clear rectangle
   */
  enableScissor(x, y, width, height) {
    const gl = this._gl;
    gl.enable(gl.SCISSOR_TEST);
    gl.scissor(x, y, width, height);
  }
  /**
   * Disable previously set scissor test rectangle
   */
  disableScissor() {
    const gl = this._gl;
    gl.disable(gl.SCISSOR_TEST);
  }
  /**
   * @internal
   */
  _loadFileAsync(url, offlineProvider, useArrayBuffer) {
    return new Promise((resolve, reject) => {
      this._loadFile(url, (data) => {
        resolve(data);
      }, void 0, offlineProvider, useArrayBuffer, (request, exception) => {
        reject(exception);
      });
    });
  }
  /**
   * Gets the source code of the vertex shader associated with a specific webGL program
   * @param program defines the program to use
   * @returns a string containing the source code of the vertex shader associated with the program
   */
  getVertexShaderSource(program) {
    const shaders = this._gl.getAttachedShaders(program);
    if (!shaders) {
      return null;
    }
    return this._gl.getShaderSource(shaders[0]);
  }
  /**
   * Gets the source code of the fragment shader associated with a specific webGL program
   * @param program defines the program to use
   * @returns a string containing the source code of the fragment shader associated with the program
   */
  getFragmentShaderSource(program) {
    const shaders = this._gl.getAttachedShaders(program);
    if (!shaders) {
      return null;
    }
    return this._gl.getShaderSource(shaders[1]);
  }
  /**
   * sets the object from which width and height will be taken from when getting render width and height
   * Will fallback to the gl object
   * @param dimensions the framebuffer width and height that will be used.
   */
  set framebufferDimensionsObject(dimensions) {
    this._framebufferDimensionsObject = dimensions;
    if (this._framebufferDimensionsObject) {
      this.onResizeObservable.notifyObservers(this);
    }
  }
  _rebuildBuffers() {
    for (const scene of this.scenes) {
      scene.resetCachedMaterial();
      scene._rebuildGeometries();
    }
    for (const scene of this._virtualScenes) {
      scene.resetCachedMaterial();
      scene._rebuildGeometries();
    }
    super._rebuildBuffers();
  }
  /**
   * Get Font size information
   * @param font font name
   * @returns an object containing ascent, height and descent
   */
  getFontOffset(font) {
    return GetFontOffset(font);
  }
  _cancelFrame() {
    if (this.customAnimationFrameRequester) {
      if (this._frameHandler !== 0) {
        this._frameHandler = 0;
        const { cancelAnimationFrame } = this.customAnimationFrameRequester;
        if (cancelAnimationFrame) {
          cancelAnimationFrame(this.customAnimationFrameRequester.requestID);
        }
      }
    } else {
      super._cancelFrame();
    }
  }
  _renderLoop(timestamp) {
    this._processFrame(timestamp);
    if (this._activeRenderLoops.length > 0 && this._frameHandler === 0) {
      if (this.customAnimationFrameRequester) {
        this.customAnimationFrameRequester.requestID = this._queueNewFrame(this.customAnimationFrameRequester.renderFunction || this._boundRenderFunction, this.customAnimationFrameRequester);
        this._frameHandler = this.customAnimationFrameRequester.requestID;
      } else {
        this._frameHandler = this._queueNewFrame(this._boundRenderFunction, this.getHostWindow());
      }
    }
  }
  /**
   * Enters Pointerlock mode
   */
  enterPointerlock() {
    if (this._renderingCanvas) {
      RequestPointerlock(this._renderingCanvas);
    }
  }
  /**
   * Exits Pointerlock mode
   */
  exitPointerlock() {
    ExitPointerlock();
  }
  /**
   * Begin a new frame
   */
  beginFrame() {
    this._measureFps();
    super.beginFrame();
  }
  _deletePipelineContext(pipelineContext) {
    const webGLPipelineContext = pipelineContext;
    if (webGLPipelineContext && webGLPipelineContext.program) {
      if (webGLPipelineContext.transformFeedback) {
        this.deleteTransformFeedback(webGLPipelineContext.transformFeedback);
        webGLPipelineContext.transformFeedback = null;
      }
    }
    super._deletePipelineContext(pipelineContext);
  }
  createShaderProgram(pipelineContext, vertexCode, fragmentCode, defines, context, transformFeedbackVaryings = null) {
    context = context || this._gl;
    this.onBeforeShaderCompilationObservable.notifyObservers(this);
    const program = super.createShaderProgram(pipelineContext, vertexCode, fragmentCode, defines, context, transformFeedbackVaryings);
    this.onAfterShaderCompilationObservable.notifyObservers(this);
    return program;
  }
  _createShaderProgram(pipelineContext, vertexShader, fragmentShader, context, transformFeedbackVaryings = null) {
    const shaderProgram = context.createProgram();
    pipelineContext.program = shaderProgram;
    if (!shaderProgram) {
      throw new Error("Unable to create program");
    }
    context.attachShader(shaderProgram, vertexShader);
    context.attachShader(shaderProgram, fragmentShader);
    if (this.webGLVersion > 1 && transformFeedbackVaryings) {
      const transformFeedback = this.createTransformFeedback();
      this.bindTransformFeedback(transformFeedback);
      this.setTranformFeedbackVaryings(shaderProgram, transformFeedbackVaryings);
      pipelineContext.transformFeedback = transformFeedback;
    }
    context.linkProgram(shaderProgram);
    if (this.webGLVersion > 1 && transformFeedbackVaryings) {
      this.bindTransformFeedback(null);
    }
    pipelineContext.context = context;
    pipelineContext.vertexShader = vertexShader;
    pipelineContext.fragmentShader = fragmentShader;
    if (!pipelineContext.isParallelCompiled) {
      this._finalizePipelineContext(pipelineContext);
    }
    return shaderProgram;
  }
  /**
   * @internal
   */
  _releaseTexture(texture) {
    super._releaseTexture(texture);
  }
  /**
   * @internal
   */
  _releaseRenderTargetWrapper(rtWrapper) {
    super._releaseRenderTargetWrapper(rtWrapper);
    this.scenes.forEach((scene) => {
      scene.postProcesses.forEach((postProcess) => {
        if (postProcess._outputTexture === rtWrapper) {
          postProcess._outputTexture = null;
        }
      });
      scene.cameras.forEach((camera) => {
        camera._postProcesses.forEach((postProcess) => {
          if (postProcess) {
            if (postProcess._outputTexture === rtWrapper) {
              postProcess._outputTexture = null;
            }
          }
        });
      });
    });
  }
  /**
   * @internal
   * Rescales a texture
   * @param source input texture
   * @param destination destination texture
   * @param scene scene to use to render the resize
   * @param internalFormat format to use when resizing
   * @param onComplete callback to be called when resize has completed
   */
  _rescaleTexture(source, destination, scene, internalFormat, onComplete) {
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MAG_FILTER, this._gl.LINEAR);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_MIN_FILTER, this._gl.LINEAR);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_WRAP_S, this._gl.CLAMP_TO_EDGE);
    this._gl.texParameteri(this._gl.TEXTURE_2D, this._gl.TEXTURE_WRAP_T, this._gl.CLAMP_TO_EDGE);
    const rtt = this.createRenderTargetTexture({
      width: destination.width,
      height: destination.height
    }, {
      generateMipMaps: false,
      type: 0,
      samplingMode: 2,
      generateDepthBuffer: false,
      generateStencilBuffer: false
    });
    if (!this._rescalePostProcess && _Engine._RescalePostProcessFactory) {
      this._rescalePostProcess = _Engine._RescalePostProcessFactory(this);
    }
    if (this._rescalePostProcess) {
      this._rescalePostProcess.externalTextureSamplerBinding = true;
      const onCompiled = () => {
        this._rescalePostProcess.onApply = function(effect2) {
          effect2._bindTexture("textureSampler", source);
        };
        let hostingScene = scene;
        if (!hostingScene) {
          hostingScene = this.scenes[this.scenes.length - 1];
        }
        hostingScene.postProcessManager.directRender([this._rescalePostProcess], rtt, true);
        this._bindTextureDirectly(this._gl.TEXTURE_2D, destination, true);
        this._gl.copyTexImage2D(this._gl.TEXTURE_2D, 0, internalFormat, 0, 0, destination.width, destination.height, 0);
        this.unBindFramebuffer(rtt);
        rtt.dispose();
        if (onComplete) {
          onComplete();
        }
      };
      const effect = this._rescalePostProcess.getEffect();
      if (effect) {
        effect.executeWhenCompiled(onCompiled);
      } else {
        this._rescalePostProcess.onEffectCreatedObservable.addOnce((effect2) => {
          effect2.executeWhenCompiled(onCompiled);
        });
      }
    }
  }
  /**
   * Wraps an external web gl texture in a Babylon texture.
   * @param texture defines the external texture
   * @param hasMipMaps defines whether the external texture has mip maps (default: false)
   * @param samplingMode defines the sampling mode for the external texture (default: 3)
   * @param width defines the width for the external texture (default: 0)
   * @param height defines the height for the external texture (default: 0)
   * @returns the babylon internal texture
   */
  wrapWebGLTexture(texture, hasMipMaps = false, samplingMode = 3, width = 0, height = 0) {
    const hardwareTexture = new WebGLHardwareTexture(texture, this._gl);
    const internalTexture = new InternalTexture(this, 0, true);
    internalTexture._hardwareTexture = hardwareTexture;
    internalTexture.baseWidth = width;
    internalTexture.baseHeight = height;
    internalTexture.width = width;
    internalTexture.height = height;
    internalTexture.isReady = true;
    internalTexture.useMipMaps = hasMipMaps;
    this.updateTextureSamplingMode(samplingMode, internalTexture);
    return internalTexture;
  }
  /**
   * @internal
   */
  _uploadImageToTexture(texture, image, faceIndex = 0, lod = 0) {
    const gl = this._gl;
    const textureType = this._getWebGLTextureType(texture.type);
    const format = this._getInternalFormat(texture.format);
    const internalFormat = this._getRGBABufferInternalSizedFormat(texture.type, format);
    const bindTarget = texture.isCube ? gl.TEXTURE_CUBE_MAP : gl.TEXTURE_2D;
    this._bindTextureDirectly(bindTarget, texture, true);
    this._unpackFlipY(texture.invertY);
    let target = gl.TEXTURE_2D;
    if (texture.isCube) {
      target = gl.TEXTURE_CUBE_MAP_POSITIVE_X + faceIndex;
    }
    gl.texImage2D(target, lod, internalFormat, format, textureType, image);
    this._bindTextureDirectly(bindTarget, null, true);
  }
  /**
   * Updates a depth texture Comparison Mode and Function.
   * If the comparison Function is equal to 0, the mode will be set to none.
   * Otherwise, this only works in webgl 2 and requires a shadow sampler in the shader.
   * @param texture The texture to set the comparison function for
   * @param comparisonFunction The comparison function to set, 0 if no comparison required
   */
  updateTextureComparisonFunction(texture, comparisonFunction) {
    if (this.webGLVersion === 1) {
      Logger.Error("WebGL 1 does not support texture comparison.");
      return;
    }
    const gl = this._gl;
    if (texture.isCube) {
      this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, texture, true);
      if (comparisonFunction === 0) {
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_FUNC, 515);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_MODE, gl.NONE);
      } else {
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_FUNC, comparisonFunction);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_COMPARE_MODE, gl.COMPARE_REF_TO_TEXTURE);
      }
      this._bindTextureDirectly(this._gl.TEXTURE_CUBE_MAP, null);
    } else {
      this._bindTextureDirectly(this._gl.TEXTURE_2D, texture, true);
      if (comparisonFunction === 0) {
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_FUNC, 515);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_MODE, gl.NONE);
      } else {
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_FUNC, comparisonFunction);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_COMPARE_MODE, gl.COMPARE_REF_TO_TEXTURE);
      }
      this._bindTextureDirectly(this._gl.TEXTURE_2D, null);
    }
    texture._comparisonFunction = comparisonFunction;
  }
  /**
   * Creates a webGL buffer to use with instantiation
   * @param capacity defines the size of the buffer
   * @returns the webGL buffer
   */
  createInstancesBuffer(capacity) {
    const buffer = this._gl.createBuffer();
    if (!buffer) {
      throw new Error("Unable to create instance buffer");
    }
    const result = new WebGLDataBuffer(buffer);
    result.capacity = capacity;
    this.bindArrayBuffer(result);
    this._gl.bufferData(this._gl.ARRAY_BUFFER, capacity, this._gl.DYNAMIC_DRAW);
    result.references = 1;
    return result;
  }
  /**
   * Delete a webGL buffer used with instantiation
   * @param buffer defines the webGL buffer to delete
   */
  deleteInstancesBuffer(buffer) {
    this._gl.deleteBuffer(buffer);
  }
  _clientWaitAsync(sync, flags = 0, intervalms = 10) {
    const gl = this._gl;
    return new Promise((resolve, reject) => {
      _retryWithInterval(() => {
        const res = gl.clientWaitSync(sync, flags, 0);
        if (res == gl.WAIT_FAILED) {
          throw new Error("clientWaitSync failed");
        }
        if (res == gl.TIMEOUT_EXPIRED) {
          return false;
        }
        return true;
      }, resolve, reject, intervalms);
    });
  }
  /**
   * @internal
   */
  _readPixelsAsync(x, y, w, h, format, type, outputBuffer) {
    if (this._webGLVersion < 2) {
      throw new Error("_readPixelsAsync only work on WebGL2+");
    }
    const gl = this._gl;
    const buf = gl.createBuffer();
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
    gl.bufferData(gl.PIXEL_PACK_BUFFER, outputBuffer.byteLength, gl.STREAM_READ);
    gl.readPixels(x, y, w, h, format, type, 0);
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
    const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
    if (!sync) {
      return null;
    }
    gl.flush();
    return this._clientWaitAsync(sync, 0, 10).then(() => {
      gl.deleteSync(sync);
      gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
      gl.getBufferSubData(gl.PIXEL_PACK_BUFFER, 0, outputBuffer);
      gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
      gl.deleteBuffer(buf);
      return outputBuffer;
    });
  }
  dispose() {
    this.hideLoadingUI();
    if (this._rescalePostProcess) {
      this._rescalePostProcess.dispose();
    }
    _CommonDispose(this, this._renderingCanvas);
    super.dispose();
  }
};
Engine.ALPHA_DISABLE = 0;
Engine.ALPHA_ADD = 1;
Engine.ALPHA_COMBINE = 2;
Engine.ALPHA_SUBTRACT = 3;
Engine.ALPHA_MULTIPLY = 4;
Engine.ALPHA_MAXIMIZED = 5;
Engine.ALPHA_ONEONE = 6;
Engine.ALPHA_PREMULTIPLIED = 7;
Engine.ALPHA_PREMULTIPLIED_PORTERDUFF = 8;
Engine.ALPHA_INTERPOLATE = 9;
Engine.ALPHA_SCREENMODE = 10;
Engine.DELAYLOADSTATE_NONE = 0;
Engine.DELAYLOADSTATE_LOADED = 1;
Engine.DELAYLOADSTATE_LOADING = 2;
Engine.DELAYLOADSTATE_NOTLOADED = 4;
Engine.NEVER = 512;
Engine.ALWAYS = 519;
Engine.LESS = 513;
Engine.EQUAL = 514;
Engine.LEQUAL = 515;
Engine.GREATER = 516;
Engine.GEQUAL = 518;
Engine.NOTEQUAL = 517;
Engine.KEEP = 7680;
Engine.REPLACE = 7681;
Engine.INCR = 7682;
Engine.DECR = 7683;
Engine.INVERT = 5386;
Engine.INCR_WRAP = 34055;
Engine.DECR_WRAP = 34056;
Engine.TEXTURE_CLAMP_ADDRESSMODE = 0;
Engine.TEXTURE_WRAP_ADDRESSMODE = 1;
Engine.TEXTURE_MIRROR_ADDRESSMODE = 2;
Engine.TEXTUREFORMAT_ALPHA = 0;
Engine.TEXTUREFORMAT_LUMINANCE = 1;
Engine.TEXTUREFORMAT_LUMINANCE_ALPHA = 2;
Engine.TEXTUREFORMAT_RGB = 4;
Engine.TEXTUREFORMAT_RGBA = 5;
Engine.TEXTUREFORMAT_RED = 6;
Engine.TEXTUREFORMAT_R = 6;
Engine.TEXTUREFORMAT_R16_UNORM = 33322;
Engine.TEXTUREFORMAT_RG16_UNORM = 33324;
Engine.TEXTUREFORMAT_RGB16_UNORM = 32852;
Engine.TEXTUREFORMAT_RGBA16_UNORM = 32859;
Engine.TEXTUREFORMAT_R16_SNORM = 36760;
Engine.TEXTUREFORMAT_RG16_SNORM = 36761;
Engine.TEXTUREFORMAT_RGB16_SNORM = 36762;
Engine.TEXTUREFORMAT_RGBA16_SNORM = 36763;
Engine.TEXTUREFORMAT_RG = 7;
Engine.TEXTUREFORMAT_RED_INTEGER = 8;
Engine.TEXTUREFORMAT_R_INTEGER = 8;
Engine.TEXTUREFORMAT_RG_INTEGER = 9;
Engine.TEXTUREFORMAT_RGB_INTEGER = 10;
Engine.TEXTUREFORMAT_RGBA_INTEGER = 11;
Engine.TEXTURETYPE_UNSIGNED_BYTE = 0;
Engine.TEXTURETYPE_UNSIGNED_INT = 0;
Engine.TEXTURETYPE_FLOAT = 1;
Engine.TEXTURETYPE_HALF_FLOAT = 2;
Engine.TEXTURETYPE_BYTE = 3;
Engine.TEXTURETYPE_SHORT = 4;
Engine.TEXTURETYPE_UNSIGNED_SHORT = 5;
Engine.TEXTURETYPE_INT = 6;
Engine.TEXTURETYPE_UNSIGNED_INTEGER = 7;
Engine.TEXTURETYPE_UNSIGNED_SHORT_4_4_4_4 = 8;
Engine.TEXTURETYPE_UNSIGNED_SHORT_5_5_5_1 = 9;
Engine.TEXTURETYPE_UNSIGNED_SHORT_5_6_5 = 10;
Engine.TEXTURETYPE_UNSIGNED_INT_2_10_10_10_REV = 11;
Engine.TEXTURETYPE_UNSIGNED_INT_24_8 = 12;
Engine.TEXTURETYPE_UNSIGNED_INT_10F_11F_11F_REV = 13;
Engine.TEXTURETYPE_UNSIGNED_INT_5_9_9_9_REV = 14;
Engine.TEXTURETYPE_FLOAT_32_UNSIGNED_INT_24_8_REV = 15;
Engine.TEXTURE_NEAREST_SAMPLINGMODE = 1;
Engine.TEXTURE_BILINEAR_SAMPLINGMODE = 2;
Engine.TEXTURE_TRILINEAR_SAMPLINGMODE = 3;
Engine.TEXTURE_NEAREST_NEAREST_MIPLINEAR = 8;
Engine.TEXTURE_LINEAR_LINEAR_MIPNEAREST = 11;
Engine.TEXTURE_LINEAR_LINEAR_MIPLINEAR = 3;
Engine.TEXTURE_NEAREST_NEAREST_MIPNEAREST = 4;
Engine.TEXTURE_NEAREST_LINEAR_MIPNEAREST = 5;
Engine.TEXTURE_NEAREST_LINEAR_MIPLINEAR = 6;
Engine.TEXTURE_NEAREST_LINEAR = 7;
Engine.TEXTURE_NEAREST_NEAREST = 1;
Engine.TEXTURE_LINEAR_NEAREST_MIPNEAREST = 9;
Engine.TEXTURE_LINEAR_NEAREST_MIPLINEAR = 10;
Engine.TEXTURE_LINEAR_LINEAR = 2;
Engine.TEXTURE_LINEAR_NEAREST = 12;
Engine.TEXTURE_EXPLICIT_MODE = 0;
Engine.TEXTURE_SPHERICAL_MODE = 1;
Engine.TEXTURE_PLANAR_MODE = 2;
Engine.TEXTURE_CUBIC_MODE = 3;
Engine.TEXTURE_PROJECTION_MODE = 4;
Engine.TEXTURE_SKYBOX_MODE = 5;
Engine.TEXTURE_INVCUBIC_MODE = 6;
Engine.TEXTURE_EQUIRECTANGULAR_MODE = 7;
Engine.TEXTURE_FIXED_EQUIRECTANGULAR_MODE = 8;
Engine.TEXTURE_FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
Engine.SCALEMODE_FLOOR = 1;
Engine.SCALEMODE_NEAREST = 2;
Engine.SCALEMODE_CEILING = 3;

// node_modules/@babylonjs/core/PostProcesses/thinPassPostProcess.js
var ThinPassPostProcess = class _ThinPassPostProcess extends EffectWrapper {
  _gatherImports(useWebGPU, list) {
    if (useWebGPU) {
      this._webGPUReady = true;
      list.push(Promise.all([import("./pass.fragment-SEWSX62O.js")]));
    } else {
      list.push(Promise.all([import("./pass.fragment-5HHADSLF.js")]));
    }
    super._gatherImports(useWebGPU, list);
  }
  /**
   * Constructs a new pass post process
   * @param name Name of the effect
   * @param engine Engine to use to render the effect. If not provided, the last created engine will be used
   * @param options Options to configure the effect
   */
  constructor(name, engine = null, options) {
    super({
      ...options,
      name,
      engine: engine || Engine.LastCreatedEngine,
      useShaderStore: true,
      useAsPostProcess: true,
      fragmentShader: _ThinPassPostProcess.FragmentUrl
    });
  }
};
ThinPassPostProcess.FragmentUrl = "pass";
var ThinPassCubePostProcess = class _ThinPassCubePostProcess extends EffectWrapper {
  _gatherImports(useWebGPU, list) {
    if (useWebGPU) {
      this._webGPUReady = true;
      list.push(Promise.all([import("./passCube.fragment-FBK4KLVN.js")]));
    } else {
      list.push(Promise.all([import("./passCube.fragment-YRC54QZC.js")]));
    }
    super._gatherImports(useWebGPU, list);
  }
  /**
   * Creates the PassCubePostProcess
   * @param name Name of the effect
   * @param engine Engine to use to render the effect. If not provided, the last created engine will be used
   * @param options Options to configure the effect
   */
  constructor(name, engine = null, options) {
    super({
      ...options,
      name,
      engine: engine || Engine.LastCreatedEngine,
      useShaderStore: true,
      useAsPostProcess: true,
      fragmentShader: _ThinPassCubePostProcess.FragmentUrl,
      defines: "#define POSITIVEX"
    });
    this._face = 0;
  }
  /**
   * Gets or sets the cube face to display.
   *  * 0 is +X
   *  * 1 is -X
   *  * 2 is +Y
   *  * 3 is -Y
   *  * 4 is +Z
   *  * 5 is -Z
   */
  get face() {
    return this._face;
  }
  set face(value) {
    if (value < 0 || value > 5) {
      return;
    }
    this._face = value;
    switch (this._face) {
      case 0:
        this.updateEffect("#define POSITIVEX");
        break;
      case 1:
        this.updateEffect("#define NEGATIVEX");
        break;
      case 2:
        this.updateEffect("#define POSITIVEY");
        break;
      case 3:
        this.updateEffect("#define NEGATIVEY");
        break;
      case 4:
        this.updateEffect("#define POSITIVEZ");
        break;
      case 5:
        this.updateEffect("#define NEGATIVEZ");
        break;
    }
  }
};
ThinPassCubePostProcess.FragmentUrl = "passCube";

// node_modules/@babylonjs/core/PostProcesses/passPostProcess.js
var PassPostProcess = class _PassPostProcess extends PostProcess {
  /**
   * Gets a string identifying the name of the class
   * @returns "PassPostProcess" string
   */
  getClassName() {
    return "PassPostProcess";
  }
  /**
   * Creates the PassPostProcess
   * @param name The name of the effect.
   * @param options The required width/height ratio to downsize to before computing the render pass.
   * @param camera The camera to apply the render pass to.
   * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
   * @param engine The engine which the post process will be applied. (default: current engine)
   * @param reusable If the post process can be reused on the same frame. (default: false)
   * @param textureType The type of texture to be used when performing the post processing.
   * @param blockCompilation If compilation of the shader should not be done in the constructor. The updateEffect method can be used to compile the shader at a later time. (default: false)
   */
  constructor(name, options, camera = null, samplingMode, engine, reusable, textureType = 0, blockCompilation = false) {
    const localOptions = {
      size: typeof options === "number" ? options : void 0,
      camera,
      samplingMode,
      engine,
      reusable,
      textureType,
      blockCompilation,
      ...options
    };
    super(name, ThinPassPostProcess.FragmentUrl, {
      effectWrapper: typeof options === "number" || !options.effectWrapper ? new ThinPassPostProcess(name, engine, localOptions) : void 0,
      ...localOptions
    });
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PassPostProcess(parsedPostProcess.name, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable);
    }, parsedPostProcess, scene, rootUrl);
  }
};
RegisterClass("BABYLON.PassPostProcess", PassPostProcess);
var PassCubePostProcess = class _PassCubePostProcess extends PostProcess {
  /**
   * Gets or sets the cube face to display.
   *  * 0 is +X
   *  * 1 is -X
   *  * 2 is +Y
   *  * 3 is -Y
   *  * 4 is +Z
   *  * 5 is -Z
   */
  get face() {
    return this._effectWrapper.face;
  }
  set face(value) {
    this._effectWrapper.face = value;
  }
  /**
   * Gets a string identifying the name of the class
   * @returns "PassCubePostProcess" string
   */
  getClassName() {
    return "PassCubePostProcess";
  }
  /**
   * Creates the PassCubePostProcess
   * @param name The name of the effect.
   * @param options The required width/height ratio to downsize to before computing the render pass.
   * @param camera The camera to apply the render pass to.
   * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
   * @param engine The engine which the post process will be applied. (default: current engine)
   * @param reusable If the post process can be reused on the same frame. (default: false)
   * @param textureType The type of texture to be used when performing the post processing.
   * @param blockCompilation If compilation of the shader should not be done in the constructor. The updateEffect method can be used to compile the shader at a later time. (default: false)
   */
  constructor(name, options, camera = null, samplingMode, engine, reusable, textureType = 0, blockCompilation = false) {
    const localOptions = {
      size: typeof options === "number" ? options : void 0,
      camera,
      samplingMode,
      engine,
      reusable,
      textureType,
      blockCompilation,
      ...options
    };
    super(name, ThinPassPostProcess.FragmentUrl, {
      effectWrapper: typeof options === "number" || !options.effectWrapper ? new ThinPassCubePostProcess(name, engine, localOptions) : void 0,
      ...localOptions
    });
  }
  /**
   * @internal
   */
  static _Parse(parsedPostProcess, targetCamera, scene, rootUrl) {
    return SerializationHelper.Parse(() => {
      return new _PassCubePostProcess(parsedPostProcess.name, parsedPostProcess.options, targetCamera, parsedPostProcess.renderTargetSamplingMode, parsedPostProcess._engine, parsedPostProcess.reusable);
    }, parsedPostProcess, scene, rootUrl);
  }
};
__decorate([
  serialize()
], PassCubePostProcess.prototype, "face", null);
AbstractEngine._RescalePostProcessFactory = (engine) => {
  return new PassPostProcess("rescale", 1, null, 2, engine, false, 0);
};

// node_modules/@babylonjs/core/Misc/textureTools.js
function CreateResizedCopy(texture, width, height, useBilinearMode = true) {
  const scene = texture.getScene();
  const engine = scene.getEngine();
  const rtt = new RenderTargetTexture("resized" + texture.name, { width, height }, scene, !texture.noMipmap, true, texture._texture.type, false, texture.samplingMode, false);
  rtt.wrapU = texture.wrapU;
  rtt.wrapV = texture.wrapV;
  rtt.uOffset = texture.uOffset;
  rtt.vOffset = texture.vOffset;
  rtt.uScale = texture.uScale;
  rtt.vScale = texture.vScale;
  rtt.uAng = texture.uAng;
  rtt.vAng = texture.vAng;
  rtt.wAng = texture.wAng;
  rtt.coordinatesIndex = texture.coordinatesIndex;
  rtt.level = texture.level;
  rtt.anisotropicFilteringLevel = texture.anisotropicFilteringLevel;
  rtt._texture.isReady = false;
  texture.wrapU = Texture.CLAMP_ADDRESSMODE;
  texture.wrapV = Texture.CLAMP_ADDRESSMODE;
  const passPostProcess = new PassPostProcess("pass", 1, null, useBilinearMode ? Texture.BILINEAR_SAMPLINGMODE : Texture.NEAREST_SAMPLINGMODE, engine, false, 0);
  passPostProcess.externalTextureSamplerBinding = true;
  passPostProcess.onEffectCreatedObservable.addOnce((e) => {
    e.executeWhenCompiled(() => {
      passPostProcess.onApply = function(effect) {
        effect.setTexture("textureSampler", texture);
      };
      const internalTexture = rtt.renderTarget;
      if (internalTexture) {
        scene.postProcessManager.directRender([passPostProcess], internalTexture);
        engine.unBindFramebuffer(internalTexture);
        rtt.disposeFramebufferObjects();
        passPostProcess.dispose();
        rtt.getInternalTexture().isReady = true;
      }
    });
  });
  return rtt;
}
function ApplyPostProcess(postProcessName, internalTexture, scene, type, samplingMode, format, width, height) {
  const engine = internalTexture.getEngine();
  internalTexture.isReady = false;
  samplingMode = samplingMode ?? internalTexture.samplingMode;
  type = type ?? internalTexture.type;
  format = format ?? internalTexture.format;
  width = width ?? internalTexture.width;
  height = height ?? internalTexture.height;
  if (type === -1) {
    type = 0;
  }
  return new Promise((resolve) => {
    const postProcess = new PostProcess("postprocess", postProcessName, null, null, 1, null, samplingMode, engine, false, void 0, type, void 0, null, false, format);
    postProcess.externalTextureSamplerBinding = true;
    const encodedTexture = engine.createRenderTargetTexture({ width, height }, {
      generateDepthBuffer: false,
      generateMipMaps: false,
      generateStencilBuffer: false,
      samplingMode,
      type,
      format
    });
    postProcess.onEffectCreatedObservable.addOnce((e) => {
      e.executeWhenCompiled(() => {
        postProcess.onApply = (effect) => {
          effect._bindTexture("textureSampler", internalTexture);
          effect.setFloat2("scale", 1, 1);
        };
        scene.postProcessManager.directRender([postProcess], encodedTexture, true);
        engine.restoreDefaultFramebuffer();
        engine._releaseTexture(internalTexture);
        if (postProcess) {
          postProcess.dispose();
        }
        encodedTexture._swapAndDie(internalTexture);
        internalTexture.type = type;
        internalTexture.format = 5;
        internalTexture.isReady = true;
        resolve(internalTexture);
      });
    });
  });
}
var floatView;
var int32View;
function ToHalfFloat(value) {
  if (!floatView) {
    floatView = new Float32Array(1);
    int32View = new Int32Array(floatView.buffer);
  }
  floatView[0] = value;
  const x = int32View[0];
  let bits = x >> 16 & 32768;
  let m = x >> 12 & 2047;
  const e = x >> 23 & 255;
  if (e < 103) {
    return bits;
  }
  if (e > 142) {
    bits |= 31744;
    bits |= (e == 255 ? 0 : 1) && x & 8388607;
    return bits;
  }
  if (e < 113) {
    m |= 2048;
    bits |= (m >> 114 - e) + (m >> 113 - e & 1);
    return bits;
  }
  bits |= e - 112 << 10 | m >> 1;
  bits += m & 1;
  return bits;
}
function FromHalfFloat(value) {
  const s = (value & 32768) >> 15;
  const e = (value & 31744) >> 10;
  const f = value & 1023;
  if (e === 0) {
    return (s ? -1 : 1) * Math.pow(2, -14) * (f / Math.pow(2, 10));
  } else if (e == 31) {
    return f ? NaN : (s ? -1 : 1) * Infinity;
  }
  return (s ? -1 : 1) * Math.pow(2, e - 15) * (1 + f / Math.pow(2, 10));
}
var ProcessAsync = async (texture, width, height, face, lod) => {
  const scene = texture.getScene();
  const engine = scene.getEngine();
  if (!engine.isWebGPU) {
    if (texture.isCube) {
      await import("./lodCube.fragment-M5CXHMQ3.js");
    } else {
      await import("./lod.fragment-QEGR63UX.js");
    }
  } else {
    if (texture.isCube) {
      await import("./lodCube.fragment-CMZGCZXF.js");
    } else {
      await import("./lod.fragment-E73FULBV.js");
    }
  }
  let lodPostProcess;
  if (!texture.isCube) {
    lodPostProcess = new PostProcess("lod", "lod", {
      uniforms: ["lod", "gamma"],
      samplingMode: Texture.NEAREST_NEAREST_MIPNEAREST,
      engine,
      shaderLanguage: engine.isWebGPU ? 1 : 0
    });
  } else {
    const faceDefines = ["#define POSITIVEX", "#define NEGATIVEX", "#define POSITIVEY", "#define NEGATIVEY", "#define POSITIVEZ", "#define NEGATIVEZ"];
    lodPostProcess = new PostProcess("lodCube", "lodCube", {
      uniforms: ["lod", "gamma"],
      samplingMode: Texture.NEAREST_NEAREST_MIPNEAREST,
      engine,
      defines: faceDefines[face],
      shaderLanguage: engine.isWebGPU ? 1 : 0
    });
  }
  await new Promise((resolve) => {
    lodPostProcess.onEffectCreatedObservable.addOnce((e) => {
      e.executeWhenCompiled(() => {
        resolve(0);
      });
    });
  });
  const rtt = new RenderTargetTexture("temp", { width, height }, scene, false);
  lodPostProcess.onApply = function(effect) {
    effect.setTexture("textureSampler", texture);
    effect.setFloat("lod", lod);
    effect.setInt("gamma", texture.gammaSpace ? 1 : 0);
  };
  const internalTexture = texture.getInternalTexture();
  try {
    if (rtt.renderTarget && internalTexture) {
      const samplingMode = internalTexture.samplingMode;
      if (lod !== 0) {
        texture.updateSamplingMode(Texture.NEAREST_NEAREST_MIPNEAREST);
      } else {
        texture.updateSamplingMode(Texture.NEAREST_NEAREST);
      }
      scene.postProcessManager.directRender([lodPostProcess], rtt.renderTarget, true);
      texture.updateSamplingMode(samplingMode);
      const bufferView = await engine.readPixels(0, 0, width, height);
      const data = new Uint8Array(bufferView.buffer, 0, bufferView.byteLength);
      engine.unBindFramebuffer(rtt.renderTarget);
      return data;
    } else {
      throw Error("Render to texture failed.");
    }
  } finally {
    rtt.dispose();
    lodPostProcess.dispose();
  }
};
async function GetTextureDataAsync(texture, width, height, face = 0, lod = 0) {
  if (!texture.isReady() && texture._texture) {
    await new Promise((resolve, reject) => {
      if (texture._texture === null) {
        reject(0);
        return;
      }
      texture._texture.onLoadedObservable.addOnce(() => {
        resolve(0);
      });
    });
  }
  return await ProcessAsync(texture, width, height, face, lod);
}
var TextureTools = {
  /**
   * Uses the GPU to create a copy texture rescaled at a given size
   * @param texture Texture to copy from
   * @param width defines the desired width
   * @param height defines the desired height
   * @param useBilinearMode defines if bilinear mode has to be used
   * @returns the generated texture
   */
  CreateResizedCopy,
  /**
   * Apply a post process to a texture
   * @param postProcessName name of the fragment post process
   * @param internalTexture the texture to encode
   * @param scene the scene hosting the texture
   * @param type type of the output texture. If not provided, use the one from internalTexture
   * @param samplingMode sampling mode to use to sample the source texture. If not provided, use the one from internalTexture
   * @param format format of the output texture. If not provided, use the one from internalTexture
   * @returns a promise with the internalTexture having its texture replaced by the result of the processing
   */
  ApplyPostProcess,
  /**
   * Converts a number to half float
   * @param value number to convert
   * @returns converted number
   */
  ToHalfFloat,
  /**
   * Converts a half float to a number
   * @param value half float to convert
   * @returns converted half float
   */
  FromHalfFloat,
  /**
   * Gets the data of the specified texture by rendering it to an intermediate RGBA texture and retrieving the bytes from it.
   * This is convienent to get 8-bit RGBA values for a texture in a GPU compressed format.
   * @param texture the source texture
   * @param width the width of the result, which does not have to match the source texture width
   * @param height the height of the result, which does not have to match the source texture height
   * @param face if the texture has multiple faces, the face index to use for the source
   * @param channels a filter for which of the RGBA channels to return in the result
   * @param lod if the texture has multiple LODs, the lod index to use for the source
   * @returns the 8-bit texture data
   */
  GetTextureDataAsync
};

export {
  SphericalHarmonics,
  SphericalPolynomial,
  CubeMapToSphericalPolynomialTools,
  ObjectRenderer,
  RenderTargetTexture,
  PostProcess,
  PerformanceMonitor,
  RollingAverage,
  RenderTargetWrapper,
  _CommonInit,
  _CommonDispose,
  GetFontOffset,
  CreateImageBitmapFromSource,
  ResizeImageBitmap,
  RequestFullscreen,
  ExitFullscreen,
  RequestPointerlock,
  ExitPointerlock,
  Engine,
  ThinPassPostProcess,
  ThinPassCubePostProcess,
  PassPostProcess,
  PassCubePostProcess,
  CreateResizedCopy,
  ApplyPostProcess,
  ToHalfFloat,
  FromHalfFloat,
  GetTextureDataAsync,
  TextureTools
};
//# sourceMappingURL=chunk-YFFCUWOF.js.map
