import {
  Color3,
  Color4,
  GetMergedStore,
  __decorate,
  serialize,
  serializeAsTexture
} from "./chunk-F2Q6VL66.js";
import {
  Matrix,
  Quaternion,
  TmpVectors,
  Vector2,
  Vector3
} from "./chunk-KGK6CYQL.js";
import {
  EncodeArrayBufferToBase64,
  InstantiationTools,
  RandomGUID
} from "./chunk-KB3YWRYD.js";
import {
  GetClass,
  RegisterClass
} from "./chunk-LMH7SWDS.js";
import {
  TimingTools,
  _WarnImport
} from "./chunk-3EDTXWHH.js";
import {
  EngineStore,
  Observable
} from "./chunk-RUCF343I.js";

// node_modules/@babylonjs/core/Misc/andOrNotEvaluator.js
var AndOrNotEvaluator = class _AndOrNotEvaluator {
  /**
   * Evaluate a query
   * @param query defines the query to evaluate
   * @param evaluateCallback defines the callback used to filter result
   * @returns true if the query matches
   */
  static Eval(query, evaluateCallback) {
    if (!query.match(/\([^()]*\)/g)) {
      query = _AndOrNotEvaluator._HandleParenthesisContent(query, evaluateCallback);
    } else {
      query = query.replace(/\([^()]*\)/g, (r) => {
        r = r.slice(1, r.length - 1);
        return _AndOrNotEvaluator._HandleParenthesisContent(r, evaluateCallback);
      });
    }
    if (query === "true") {
      return true;
    }
    if (query === "false") {
      return false;
    }
    return _AndOrNotEvaluator.Eval(query, evaluateCallback);
  }
  static _HandleParenthesisContent(parenthesisContent, evaluateCallback) {
    evaluateCallback = evaluateCallback || ((r) => {
      return r === "true" ? true : false;
    });
    let result;
    const or = parenthesisContent.split("||");
    for (const i in or) {
      if (Object.prototype.hasOwnProperty.call(or, i)) {
        let ori = _AndOrNotEvaluator._SimplifyNegation(or[i].trim());
        const and = ori.split("&&");
        if (and.length > 1) {
          for (let j = 0; j < and.length; ++j) {
            const andj = _AndOrNotEvaluator._SimplifyNegation(and[j].trim());
            if (andj !== "true" && andj !== "false") {
              if (andj[0] === "!") {
                result = !evaluateCallback(andj.substring(1));
              } else {
                result = evaluateCallback(andj);
              }
            } else {
              result = andj === "true" ? true : false;
            }
            if (!result) {
              ori = "false";
              break;
            }
          }
        }
        if (result || ori === "true") {
          result = true;
          break;
        }
        if (ori !== "true" && ori !== "false") {
          if (ori[0] === "!") {
            result = !evaluateCallback(ori.substring(1));
          } else {
            result = evaluateCallback(ori);
          }
        } else {
          result = ori === "true" ? true : false;
        }
      }
    }
    return result ? "true" : "false";
  }
  static _SimplifyNegation(booleanString) {
    booleanString = booleanString.replace(/^[\s!]+/, (r) => {
      r = r.replace(/[\s]/g, () => "");
      return r.length % 2 ? "!" : "";
    });
    booleanString = booleanString.trim();
    if (booleanString === "!true") {
      booleanString = "false";
    } else if (booleanString === "!false") {
      booleanString = "true";
    }
    return booleanString;
  }
};

// node_modules/@babylonjs/core/Misc/tags.js
var Tags = class _Tags {
  /**
   * Adds support for tags on the given object
   * @param obj defines the object to use
   */
  static EnableFor(obj) {
    obj._tags = obj._tags || {};
    obj.hasTags = () => {
      return _Tags.HasTags(obj);
    };
    obj.addTags = (tagsString) => {
      return _Tags.AddTagsTo(obj, tagsString);
    };
    obj.removeTags = (tagsString) => {
      return _Tags.RemoveTagsFrom(obj, tagsString);
    };
    obj.matchesTagsQuery = (tagsQuery) => {
      return _Tags.MatchesQuery(obj, tagsQuery);
    };
  }
  /**
   * Removes tags support
   * @param obj defines the object to use
   */
  static DisableFor(obj) {
    delete obj._tags;
    delete obj.hasTags;
    delete obj.addTags;
    delete obj.removeTags;
    delete obj.matchesTagsQuery;
  }
  /**
   * Gets a boolean indicating if the given object has tags
   * @param obj defines the object to use
   * @returns a boolean
   */
  static HasTags(obj) {
    if (!obj._tags) {
      return false;
    }
    const tags = obj._tags;
    for (const i in tags) {
      if (Object.prototype.hasOwnProperty.call(tags, i)) {
        return true;
      }
    }
    return false;
  }
  /**
   * Gets the tags available on a given object
   * @param obj defines the object to use
   * @param asString defines if the tags must be returned as a string instead of an array of strings
   * @returns the tags
   */
  static GetTags(obj, asString = true) {
    if (!obj._tags) {
      return null;
    }
    if (asString) {
      const tagsArray = [];
      for (const tag in obj._tags) {
        if (Object.prototype.hasOwnProperty.call(obj._tags, tag) && obj._tags[tag] === true) {
          tagsArray.push(tag);
        }
      }
      return tagsArray.join(" ");
    } else {
      return obj._tags;
    }
  }
  /**
   * Adds tags to an object
   * @param obj defines the object to use
   * @param tagsString defines the tag string. The tags 'true' and 'false' are reserved and cannot be used as tags.
   * A tag cannot start with '||', '&&', and '!'. It cannot contain whitespaces
   */
  static AddTagsTo(obj, tagsString) {
    if (!tagsString) {
      return;
    }
    if (typeof tagsString !== "string") {
      return;
    }
    const tags = tagsString.split(" ");
    tags.forEach(function(tag) {
      _Tags._AddTagTo(obj, tag);
    });
  }
  /**
   * @internal
   */
  static _AddTagTo(obj, tag) {
    tag = tag.trim();
    if (tag === "" || tag === "true" || tag === "false") {
      return;
    }
    if (tag.match(/[\s]/) || tag.match(/^([!]|([|]|[&]){2})/)) {
      return;
    }
    _Tags.EnableFor(obj);
    obj._tags[tag] = true;
  }
  /**
   * Removes specific tags from a specific object
   * @param obj defines the object to use
   * @param tagsString defines the tags to remove
   */
  static RemoveTagsFrom(obj, tagsString) {
    if (!_Tags.HasTags(obj)) {
      return;
    }
    const tags = tagsString.split(" ");
    for (const t in tags) {
      _Tags._RemoveTagFrom(obj, tags[t]);
    }
  }
  /**
   * @internal
   */
  static _RemoveTagFrom(obj, tag) {
    delete obj._tags[tag];
  }
  /**
   * Defines if tags hosted on an object match a given query
   * @param obj defines the object to use
   * @param tagsQuery defines the tag query
   * @returns a boolean
   */
  static MatchesQuery(obj, tagsQuery) {
    if (tagsQuery === void 0) {
      return true;
    }
    if (tagsQuery === "") {
      return _Tags.HasTags(obj);
    }
    return AndOrNotEvaluator.Eval(tagsQuery, (r) => _Tags.HasTags(obj) && obj._tags[r]);
  }
};

// node_modules/@babylonjs/core/Misc/decorators.serialization.js
var _copySource = function(creationFunction, source, instanciate, options = {}) {
  const destination = creationFunction();
  if (Tags && Tags.HasTags(source)) {
    Tags.AddTagsTo(destination, Tags.GetTags(source, true));
  }
  const classStore = GetMergedStore(destination);
  const textureMap = {};
  for (const property in classStore) {
    const propertyDescriptor = classStore[property];
    const sourceProperty = source[property];
    const propertyType = propertyDescriptor.type;
    if (sourceProperty !== void 0 && sourceProperty !== null && (property !== "uniqueId" || SerializationHelper.AllowLoadingUniqueId)) {
      switch (propertyType) {
        case 0:
        // Value
        case 6:
        // Mesh reference
        case 9:
        // Image processing configuration reference
        case 11:
          destination[property] = sourceProperty;
          break;
        case 1:
          if (options.cloneTexturesOnlyOnce && textureMap[sourceProperty.uniqueId]) {
            destination[property] = textureMap[sourceProperty.uniqueId];
          } else {
            destination[property] = instanciate || sourceProperty.isRenderTarget ? sourceProperty : sourceProperty.clone();
            textureMap[sourceProperty.uniqueId] = destination[property];
          }
          break;
        case 2:
        // Color3
        case 3:
        // FresnelParameters
        case 4:
        // Vector2
        case 5:
        // Vector3
        case 7:
        // Color Curves
        case 8:
        // Color 4
        case 10:
        // Quaternion
        case 12:
          destination[property] = instanciate ? sourceProperty : sourceProperty.clone();
          break;
      }
    }
  }
  return destination;
};
var SerializationHelper = class _SerializationHelper {
  /**
   * Appends the serialized animations from the source animations
   * @param source Source containing the animations
   * @param destination Target to store the animations
   */
  static AppendSerializedAnimations(source, destination) {
    if (source.animations) {
      destination.animations = [];
      for (let animationIndex = 0; animationIndex < source.animations.length; animationIndex++) {
        const animation = source.animations[animationIndex];
        destination.animations.push(animation.serialize());
      }
    }
  }
  /**
   * Static function used to serialized a specific entity
   * @param entity defines the entity to serialize
   * @param serializationObject defines the optional target object where serialization data will be stored
   * @returns a JSON compatible object representing the serialization of the entity
   */
  static Serialize(entity, serializationObject) {
    if (!serializationObject) {
      serializationObject = {};
    }
    if (Tags) {
      serializationObject.tags = Tags.GetTags(entity);
    }
    const serializedProperties = GetMergedStore(entity);
    for (const property in serializedProperties) {
      const propertyDescriptor = serializedProperties[property];
      const targetPropertyName = propertyDescriptor.sourceName || property;
      const propertyType = propertyDescriptor.type;
      const sourceProperty = entity[property];
      if (sourceProperty !== void 0 && sourceProperty !== null && (property !== "uniqueId" || _SerializationHelper.AllowLoadingUniqueId)) {
        switch (propertyType) {
          case 0:
            serializationObject[targetPropertyName] = sourceProperty;
            break;
          case 1:
            serializationObject[targetPropertyName] = sourceProperty.serialize();
            break;
          case 2:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
          case 3:
            serializationObject[targetPropertyName] = sourceProperty.serialize();
            break;
          case 4:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
          case 5:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
          case 6:
            serializationObject[targetPropertyName] = sourceProperty.id;
            break;
          case 7:
            serializationObject[targetPropertyName] = sourceProperty.serialize();
            break;
          case 8:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
          case 9:
            serializationObject[targetPropertyName] = sourceProperty.serialize();
            break;
          case 10:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
          case 11:
            serializationObject[targetPropertyName] = sourceProperty.id;
            break;
          case 12:
            serializationObject[targetPropertyName] = sourceProperty.asArray();
            break;
        }
      }
    }
    return serializationObject;
  }
  /**
   * Given a source json and a destination object in a scene, this function will parse the source and will try to apply its content to the destination object
   * @param source the source json data
   * @param destination the destination object
   * @param scene the scene where the object is
   * @param rootUrl root url to use to load assets
   */
  static ParseProperties(source, destination, scene, rootUrl) {
    if (!rootUrl) {
      rootUrl = "";
    }
    const classStore = GetMergedStore(destination);
    for (const property in classStore) {
      const propertyDescriptor = classStore[property];
      const sourceProperty = source[propertyDescriptor.sourceName || property];
      const propertyType = propertyDescriptor.type;
      if (sourceProperty !== void 0 && sourceProperty !== null && (property !== "uniqueId" || _SerializationHelper.AllowLoadingUniqueId)) {
        const dest = destination;
        switch (propertyType) {
          case 0:
            dest[property] = sourceProperty;
            break;
          case 1:
            if (scene) {
              dest[property] = _SerializationHelper._TextureParser(sourceProperty, scene, rootUrl);
            }
            break;
          case 2:
            dest[property] = Color3.FromArray(sourceProperty);
            break;
          case 3:
            dest[property] = _SerializationHelper._FresnelParametersParser(sourceProperty);
            break;
          case 4:
            dest[property] = Vector2.FromArray(sourceProperty);
            break;
          case 5:
            dest[property] = Vector3.FromArray(sourceProperty);
            break;
          case 6:
            if (scene) {
              dest[property] = scene.getLastMeshById(sourceProperty);
            }
            break;
          case 7:
            dest[property] = _SerializationHelper._ColorCurvesParser(sourceProperty);
            break;
          case 8:
            dest[property] = Color4.FromArray(sourceProperty);
            break;
          case 9:
            dest[property] = _SerializationHelper._ImageProcessingConfigurationParser(sourceProperty);
            break;
          case 10:
            dest[property] = Quaternion.FromArray(sourceProperty);
            break;
          case 11:
            if (scene) {
              dest[property] = scene.getCameraById(sourceProperty);
            }
            break;
          case 12:
            dest[property] = Matrix.FromArray(sourceProperty);
            break;
        }
      }
    }
  }
  /**
   * Creates a new entity from a serialization data object
   * @param creationFunction defines a function used to instanciated the new entity
   * @param source defines the source serialization data
   * @param scene defines the hosting scene
   * @param rootUrl defines the root url for resources
   * @returns a new entity
   */
  static Parse(creationFunction, source, scene, rootUrl = null) {
    const destination = creationFunction();
    if (Tags) {
      Tags.AddTagsTo(destination, source.tags);
    }
    _SerializationHelper.ParseProperties(source, destination, scene, rootUrl);
    return destination;
  }
  /**
   * Clones an object
   * @param creationFunction defines the function used to instanciate the new object
   * @param source defines the source object
   * @param options defines the options to use
   * @returns the cloned object
   */
  static Clone(creationFunction, source, options = {}) {
    return _copySource(creationFunction, source, false, options);
  }
  /**
   * Instanciates a new object based on a source one (some data will be shared between both object)
   * @param creationFunction defines the function used to instanciate the new object
   * @param source defines the source object
   * @returns the new object
   */
  static Instanciate(creationFunction, source) {
    return _copySource(creationFunction, source, true);
  }
};
SerializationHelper.AllowLoadingUniqueId = false;
SerializationHelper._ImageProcessingConfigurationParser = (sourceProperty) => {
  throw _WarnImport("ImageProcessingConfiguration");
};
SerializationHelper._FresnelParametersParser = (sourceProperty) => {
  throw _WarnImport("FresnelParameters");
};
SerializationHelper._ColorCurvesParser = (sourceProperty) => {
  throw _WarnImport("ColorCurves");
};
SerializationHelper._TextureParser = (sourceProperty, scene, rootUrl) => {
  throw _WarnImport("Texture");
};

// node_modules/@babylonjs/core/Maths/math.size.js
var Size = class _Size {
  /**
   * Creates a Size object from the given width and height (floats).
   * @param width width of the new size
   * @param height height of the new size
   */
  constructor(width, height) {
    this.width = width;
    this.height = height;
  }
  /**
   * Returns a string with the Size width and height
   * @returns a string with the Size width and height
   */
  toString() {
    return `{W: ${this.width}, H: ${this.height}}`;
  }
  /**
   * "Size"
   * @returns the string "Size"
   */
  getClassName() {
    return "Size";
  }
  /**
   * Returns the Size hash code.
   * @returns a hash code for a unique width and height
   */
  getHashCode() {
    let hash = this.width | 0;
    hash = hash * 397 ^ (this.height | 0);
    return hash;
  }
  /**
   * Updates the current size from the given one.
   * @param src the given size
   */
  copyFrom(src) {
    this.width = src.width;
    this.height = src.height;
  }
  /**
   * Updates in place the current Size from the given floats.
   * @param width width of the new size
   * @param height height of the new size
   * @returns the updated Size.
   */
  copyFromFloats(width, height) {
    this.width = width;
    this.height = height;
    return this;
  }
  /**
   * Updates in place the current Size from the given floats.
   * @param width width to set
   * @param height height to set
   * @returns the updated Size.
   */
  set(width, height) {
    return this.copyFromFloats(width, height);
  }
  /**
   * Multiplies the width and height by numbers
   * @param w factor to multiple the width by
   * @param h factor to multiple the height by
   * @returns a new Size set with the multiplication result of the current Size and the given floats.
   */
  multiplyByFloats(w, h) {
    return new _Size(this.width * w, this.height * h);
  }
  /**
   * Clones the size
   * @returns a new Size copied from the given one.
   */
  clone() {
    return new _Size(this.width, this.height);
  }
  /**
   * True if the current Size and the given one width and height are strictly equal.
   * @param other the other size to compare against
   * @returns True if the current Size and the given one width and height are strictly equal.
   */
  equals(other) {
    if (!other) {
      return false;
    }
    return this.width === other.width && this.height === other.height;
  }
  /**
   * The surface of the Size : width * height (float).
   */
  get surface() {
    return this.width * this.height;
  }
  /**
   * Create a new size of zero
   * @returns a new Size set to (0.0, 0.0)
   */
  static Zero() {
    return new _Size(0, 0);
  }
  /**
   * Sums the width and height of two sizes
   * @param otherSize size to add to this size
   * @returns a new Size set as the addition result of the current Size and the given one.
   */
  add(otherSize) {
    const r = new _Size(this.width + otherSize.width, this.height + otherSize.height);
    return r;
  }
  /**
   * Subtracts the width and height of two
   * @param otherSize size to subtract to this size
   * @returns a new Size set as the subtraction result of  the given one from the current Size.
   */
  subtract(otherSize) {
    const r = new _Size(this.width - otherSize.width, this.height - otherSize.height);
    return r;
  }
  /**
   * Scales the width and height
   * @param scale the scale to multiply the width and height by
   * @returns a new Size set with the multiplication result of the current Size and the given floats.
   */
  scale(scale) {
    return new _Size(this.width * scale, this.height * scale);
  }
  /**
   * Creates a new Size set at the linear interpolation "amount" between "start" and "end"
   * @param start starting size to lerp between
   * @param end end size to lerp between
   * @param amount amount to lerp between the start and end values
   * @returns a new Size set at the linear interpolation "amount" between "start" and "end"
   */
  static Lerp(start, end, amount) {
    const w = start.width + (end.width - start.width) * amount;
    const h = start.height + (end.height - start.height) * amount;
    return new _Size(w, h);
  }
};

// node_modules/@babylonjs/core/Maths/math.plane.js
var Plane = class _Plane {
  /**
   * Creates a Plane object according to the given floats a, b, c, d and the plane equation : ax + by + cz + d = 0
   * @param a a component of the plane
   * @param b b component of the plane
   * @param c c component of the plane
   * @param d d component of the plane
   */
  constructor(a, b, c, d) {
    this.normal = new Vector3(a, b, c);
    this.d = d;
  }
  /**
   * @returns the plane coordinates as a new array of 4 elements [a, b, c, d].
   */
  asArray() {
    return [this.normal.x, this.normal.y, this.normal.z, this.d];
  }
  // Methods
  /**
   * @returns a new plane copied from the current Plane.
   */
  clone() {
    return new _Plane(this.normal.x, this.normal.y, this.normal.z, this.d);
  }
  /**
   * @returns the string "Plane".
   */
  getClassName() {
    return "Plane";
  }
  /**
   * @returns the Plane hash code.
   */
  getHashCode() {
    let hash = this.normal.getHashCode();
    hash = hash * 397 ^ (this.d | 0);
    return hash;
  }
  /**
   * Normalize the current Plane in place.
   * @returns the updated Plane.
   */
  normalize() {
    const norm = Math.sqrt(this.normal.x * this.normal.x + this.normal.y * this.normal.y + this.normal.z * this.normal.z);
    let magnitude = 0;
    if (norm !== 0) {
      magnitude = 1 / norm;
    }
    this.normal.x *= magnitude;
    this.normal.y *= magnitude;
    this.normal.z *= magnitude;
    this.d *= magnitude;
    return this;
  }
  /**
   * Applies a transformation the plane and returns the result
   * @param transformation the transformation matrix to be applied to the plane
   * @returns a new Plane as the result of the transformation of the current Plane by the given matrix.
   */
  transform(transformation) {
    const invertedMatrix = _Plane._TmpMatrix;
    transformation.invertToRef(invertedMatrix);
    const m = invertedMatrix.m;
    const x = this.normal.x;
    const y = this.normal.y;
    const z = this.normal.z;
    const d = this.d;
    const normalX = x * m[0] + y * m[1] + z * m[2] + d * m[3];
    const normalY = x * m[4] + y * m[5] + z * m[6] + d * m[7];
    const normalZ = x * m[8] + y * m[9] + z * m[10] + d * m[11];
    const finalD = x * m[12] + y * m[13] + z * m[14] + d * m[15];
    return new _Plane(normalX, normalY, normalZ, finalD);
  }
  /**
   * Compute the dot product between the point and the plane normal
   * @param point point to calculate the dot product with
   * @returns the dot product (float) of the point coordinates and the plane normal.
   */
  dotCoordinate(point) {
    return this.normal.x * point.x + this.normal.y * point.y + this.normal.z * point.z + this.d;
  }
  /**
   * Updates the current Plane from the plane defined by the three given points.
   * @param point1 one of the points used to construct the plane
   * @param point2 one of the points used to construct the plane
   * @param point3 one of the points used to construct the plane
   * @returns the updated Plane.
   */
  copyFromPoints(point1, point2, point3) {
    const x1 = point2.x - point1.x;
    const y1 = point2.y - point1.y;
    const z1 = point2.z - point1.z;
    const x2 = point3.x - point1.x;
    const y2 = point3.y - point1.y;
    const z2 = point3.z - point1.z;
    const yz = y1 * z2 - z1 * y2;
    const xz = z1 * x2 - x1 * z2;
    const xy = x1 * y2 - y1 * x2;
    const pyth = Math.sqrt(yz * yz + xz * xz + xy * xy);
    let invPyth;
    if (pyth !== 0) {
      invPyth = 1 / pyth;
    } else {
      invPyth = 0;
    }
    this.normal.x = yz * invPyth;
    this.normal.y = xz * invPyth;
    this.normal.z = xy * invPyth;
    this.d = -(this.normal.x * point1.x + this.normal.y * point1.y + this.normal.z * point1.z);
    return this;
  }
  /**
   * Checks if the plane is facing a given direction (meaning if the plane's normal is pointing in the opposite direction of the given vector).
   * Note that for this function to work as expected you should make sure that:
   *   - direction and the plane normal are normalized
   *   - epsilon is a number just bigger than -1, something like -0.99 for eg
   * @param direction the direction to check if the plane is facing
   * @param epsilon value the dot product is compared against (returns true if dot <= epsilon)
   * @returns True if the plane is facing the given direction
   */
  isFrontFacingTo(direction, epsilon) {
    const dot = Vector3.Dot(this.normal, direction);
    return dot <= epsilon;
  }
  /**
   * Calculates the distance to a point
   * @param point point to calculate distance to
   * @returns the signed distance (float) from the given point to the Plane.
   */
  signedDistanceTo(point) {
    return Vector3.Dot(point, this.normal) + this.d;
  }
  // Statics
  /**
   * Creates a plane from an  array
   * @param array the array to create a plane from
   * @returns a new Plane from the given array.
   */
  static FromArray(array) {
    return new _Plane(array[0], array[1], array[2], array[3]);
  }
  /**
   * Creates a plane from three points
   * @param point1 point used to create the plane
   * @param point2 point used to create the plane
   * @param point3 point used to create the plane
   * @returns a new Plane defined by the three given points.
   */
  static FromPoints(point1, point2, point3) {
    const result = new _Plane(0, 0, 0, 0);
    result.copyFromPoints(point1, point2, point3);
    return result;
  }
  /**
   * Creates a plane from an origin point and a normal
   * @param origin origin of the plane to be constructed
   * @param normal normal of the plane to be constructed
   * @returns a new Plane the normal vector to this plane at the given origin point.
   */
  static FromPositionAndNormal(origin, normal) {
    const plane = new _Plane(0, 0, 0, 0);
    return this.FromPositionAndNormalToRef(origin, normal, plane);
  }
  /**
   * Updates the given Plane "result" from an origin point and a normal.
   * @param origin origin of the plane to be constructed
   * @param normal the normalized normals of the plane to be constructed
   * @param result defines the Plane where to store the result
   * @returns result input
   */
  static FromPositionAndNormalToRef(origin, normal, result) {
    result.normal.copyFrom(normal);
    result.normal.normalize();
    result.d = -origin.dot(result.normal);
    return result;
  }
  /**
   * Calculates the distance from a plane and a point
   * @param origin origin of the plane to be constructed
   * @param normal normal of the plane to be constructed
   * @param point point to calculate distance to
   * @returns the signed distance between the plane defined by the normal vector at the "origin"" point and the given other point.
   */
  static SignedDistanceToPlaneFromPositionAndNormal(origin, normal, point) {
    const d = -(normal.x * origin.x + normal.y * origin.y + normal.z * origin.z);
    return Vector3.Dot(point, normal) + d;
  }
};
Plane._TmpMatrix = Matrix.Identity();

// node_modules/@babylonjs/core/Materials/Textures/thinTexture.js
var ThinTexture = class _ThinTexture {
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapU() {
    return this._wrapU;
  }
  set wrapU(value) {
    this._wrapU = value;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapV() {
    return this._wrapV;
  }
  set wrapV(value) {
    this._wrapV = value;
  }
  /**
   * How a texture is mapped.
   * Unused in thin texture mode.
   */
  get coordinatesMode() {
    return 0;
  }
  /**
   * Define if the texture is a cube texture or if false a 2d texture.
   */
  get isCube() {
    if (!this._texture) {
      return false;
    }
    return this._texture.isCube;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set isCube(value) {
    if (!this._texture) {
      return;
    }
    this._texture.isCube = value;
  }
  /**
   * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
   */
  get is3D() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is3D;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is3D(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is3D = value;
  }
  /**
   * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
   */
  get is2DArray() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is2DArray;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is2DArray(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is2DArray = value;
  }
  /**
   * Get the class name of the texture.
   * @returns "ThinTexture"
   */
  getClassName() {
    return "ThinTexture";
  }
  static _IsRenderTargetWrapper(texture) {
    return (texture == null ? void 0 : texture.shareDepth) !== void 0;
  }
  /**
   * Instantiates a new ThinTexture.
   * Base class of all the textures in babylon.
   * This can be used as an internal texture wrapper in AbstractEngine to benefit from the cache
   * @param internalTexture Define the internalTexture to wrap. You can also pass a RenderTargetWrapper, in which case the texture will be the render target's texture
   */
  constructor(internalTexture) {
    this._wrapU = 1;
    this._wrapV = 1;
    this.wrapR = 1;
    this.anisotropicFilteringLevel = 4;
    this.delayLoadState = 0;
    this._texture = null;
    this._engine = null;
    this._cachedSize = Size.Zero();
    this._cachedBaseSize = Size.Zero();
    this._initialSamplingMode = 2;
    this._texture = _ThinTexture._IsRenderTargetWrapper(internalTexture) ? internalTexture.texture : internalTexture;
    if (this._texture) {
      this._engine = this._texture.getEngine();
    }
  }
  /**
   * Get if the texture is ready to be used (downloaded, converted, mip mapped...).
   * @returns true if fully ready
   */
  isReady() {
    if (this.delayLoadState === 4) {
      this.delayLoad();
      return false;
    }
    if (this._texture) {
      return this._texture.isReady;
    }
    return false;
  }
  /**
   * Triggers the load sequence in delayed load mode.
   */
  delayLoad() {
  }
  /**
   * Get the underlying lower level texture from Babylon.
   * @returns the internal texture
   */
  getInternalTexture() {
    return this._texture;
  }
  /**
   * Get the size of the texture.
   * @returns the texture size.
   */
  getSize() {
    if (this._texture) {
      if (this._texture.width) {
        this._cachedSize.width = this._texture.width;
        this._cachedSize.height = this._texture.height;
        return this._cachedSize;
      }
      if (this._texture._size) {
        this._cachedSize.width = this._texture._size;
        this._cachedSize.height = this._texture._size;
        return this._cachedSize;
      }
    }
    return this._cachedSize;
  }
  /**
   * Get the base size of the texture.
   * It can be different from the size if the texture has been resized for POT for instance
   * @returns the base size
   */
  getBaseSize() {
    if (!this.isReady() || !this._texture) {
      this._cachedBaseSize.width = 0;
      this._cachedBaseSize.height = 0;
      return this._cachedBaseSize;
    }
    if (this._texture._size) {
      this._cachedBaseSize.width = this._texture._size;
      this._cachedBaseSize.height = this._texture._size;
      return this._cachedBaseSize;
    }
    this._cachedBaseSize.width = this._texture.baseWidth;
    this._cachedBaseSize.height = this._texture.baseHeight;
    return this._cachedBaseSize;
  }
  /**
   * Get the current sampling mode associated with the texture.
   */
  get samplingMode() {
    if (!this._texture) {
      return this._initialSamplingMode;
    }
    return this._texture.samplingMode;
  }
  /**
   * Update the sampling mode of the texture.
   * Default is Trilinear mode.
   *
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 1     | NEAREST_SAMPLINGMODE or NEAREST_NEAREST_MIPLINEAR  | Nearest is: mag = nearest, min = nearest, mip = linear |
   * | 2     | BILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPNEAREST | Bilinear is: mag = linear, min = linear, mip = nearest |
   * | 3     | TRILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPLINEAR | Trilinear is: mag = linear, min = linear, mip = linear |
   * | 4     | NEAREST_NEAREST_MIPNEAREST |             |
   * | 5    | NEAREST_LINEAR_MIPNEAREST |             |
   * | 6    | NEAREST_LINEAR_MIPLINEAR |             |
   * | 7    | NEAREST_LINEAR |             |
   * | 8    | NEAREST_NEAREST |             |
   * | 9   | LINEAR_NEAREST_MIPNEAREST |             |
   * | 10   | LINEAR_NEAREST_MIPLINEAR |             |
   * | 11   | LINEAR_LINEAR |             |
   * | 12   | LINEAR_NEAREST |             |
   *
   *    > _mag_: magnification filter (close to the viewer)
   *    > _min_: minification filter (far from the viewer)
   *    > _mip_: filter used between mip map levels
   *@param samplingMode Define the new sampling mode of the texture
   */
  updateSamplingMode(samplingMode) {
    if (this._texture && this._engine) {
      this._engine.updateTextureSamplingMode(samplingMode, this._texture);
    }
  }
  /**
   * Release and destroy the underlying lower level texture aka internalTexture.
   */
  releaseInternalTexture() {
    if (this._texture) {
      this._texture.dispose();
      this._texture = null;
    }
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    if (this._texture) {
      this.releaseInternalTexture();
      this._engine = null;
    }
  }
};

// node_modules/@babylonjs/core/Materials/Textures/baseTexture.js
var BaseTexture = class _BaseTexture extends ThinTexture {
  /**
   * Define if the texture is having a usable alpha value (can be use for transparency or glossiness for instance).
   */
  set hasAlpha(value) {
    if (this._hasAlpha === value) {
      return;
    }
    this._hasAlpha = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get hasAlpha() {
    return this._hasAlpha;
  }
  /**
   * Defines if the alpha value should be determined via the rgb values.
   * If true the luminance of the pixel might be used to find the corresponding alpha value.
   */
  set getAlphaFromRGB(value) {
    if (this._getAlphaFromRGB === value) {
      return;
    }
    this._getAlphaFromRGB = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get getAlphaFromRGB() {
    return this._getAlphaFromRGB;
  }
  /**
   * Define the UV channel to use starting from 0 and defaulting to 0.
   * This is part of the texture as textures usually maps to one uv set.
   */
  set coordinatesIndex(value) {
    if (this._coordinatesIndex === value) {
      return;
    }
    this._coordinatesIndex = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get coordinatesIndex() {
    return this._coordinatesIndex;
  }
  /**
   * How a texture is mapped.
   *
   * | Value | Type                                | Description |
   * | ----- | ----------------------------------- | ----------- |
   * | 0     | EXPLICIT_MODE                       |             |
   * | 1     | SPHERICAL_MODE                      |             |
   * | 2     | PLANAR_MODE                         |             |
   * | 3     | CUBIC_MODE                          |             |
   * | 4     | PROJECTION_MODE                     |             |
   * | 5     | SKYBOX_MODE                         |             |
   * | 6     | INVCUBIC_MODE                       |             |
   * | 7     | EQUIRECTANGULAR_MODE                |             |
   * | 8     | FIXED_EQUIRECTANGULAR_MODE          |             |
   * | 9     | FIXED_EQUIRECTANGULAR_MIRRORED_MODE |             |
   */
  set coordinatesMode(value) {
    if (this._coordinatesMode === value) {
      return;
    }
    this._coordinatesMode = value;
    if (this._scene) {
      this._scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
  }
  get coordinatesMode() {
    return this._coordinatesMode;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapU() {
    return this._wrapU;
  }
  set wrapU(value) {
    this._wrapU = value;
  }
  /**
   * | Value | Type               | Description |
   * | ----- | ------------------ | ----------- |
   * | 0     | CLAMP_ADDRESSMODE  |             |
   * | 1     | WRAP_ADDRESSMODE   |             |
   * | 2     | MIRROR_ADDRESSMODE |             |
   */
  get wrapV() {
    return this._wrapV;
  }
  set wrapV(value) {
    this._wrapV = value;
  }
  /**
   * Define if the texture is a cube texture or if false a 2d texture.
   */
  get isCube() {
    if (!this._texture) {
      return this._isCube;
    }
    return this._texture.isCube;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set isCube(value) {
    if (!this._texture) {
      this._isCube = value;
    } else {
      this._texture.isCube = value;
    }
  }
  /**
   * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
   */
  get is3D() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is3D;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is3D(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is3D = value;
  }
  /**
   * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
   */
  get is2DArray() {
    if (!this._texture) {
      return false;
    }
    return this._texture.is2DArray;
  }
  // eslint-disable-next-line @typescript-eslint/naming-convention
  set is2DArray(value) {
    if (!this._texture) {
      return;
    }
    this._texture.is2DArray = value;
  }
  /**
   * Define if the texture contains data in gamma space (most of the png/jpg aside bump).
   * HDR texture are usually stored in linear space.
   * This only impacts the PBR and Background materials
   */
  get gammaSpace() {
    if (!this._texture) {
      return this._gammaSpace;
    } else {
      if (this._texture._gammaSpace === null) {
        this._texture._gammaSpace = this._gammaSpace;
      }
    }
    return this._texture._gammaSpace && !this._texture._useSRGBBuffer;
  }
  set gammaSpace(gamma) {
    var _a;
    if (!this._texture) {
      if (this._gammaSpace === gamma) {
        return;
      }
      this._gammaSpace = gamma;
    } else {
      if (this._texture._gammaSpace === gamma) {
        return;
      }
      this._texture._gammaSpace = gamma;
    }
    (_a = this.getScene()) == null ? void 0 : _a.markAllMaterialsAsDirty(1, (mat) => {
      return mat.hasTexture(this);
    });
  }
  /**
   * Gets or sets whether or not the texture contains RGBD data.
   */
  get isRGBD() {
    return this._texture != null && this._texture._isRGBD;
  }
  set isRGBD(value) {
    var _a;
    if (value === this.isRGBD) {
      return;
    }
    if (this._texture) {
      this._texture._isRGBD = value;
    }
    (_a = this.getScene()) == null ? void 0 : _a.markAllMaterialsAsDirty(1, (mat) => {
      return mat.hasTexture(this);
    });
  }
  /**
   * Are mip maps generated for this texture or not.
   */
  get noMipmap() {
    return false;
  }
  /**
   * With prefiltered texture, defined the offset used during the prefiltering steps.
   */
  get lodGenerationOffset() {
    if (this._texture) {
      return this._texture._lodGenerationOffset;
    }
    return 0;
  }
  set lodGenerationOffset(value) {
    if (this._texture) {
      this._texture._lodGenerationOffset = value;
    }
  }
  /**
   * With prefiltered texture, defined the scale used during the prefiltering steps.
   */
  get lodGenerationScale() {
    if (this._texture) {
      return this._texture._lodGenerationScale;
    }
    return 0;
  }
  set lodGenerationScale(value) {
    if (this._texture) {
      this._texture._lodGenerationScale = value;
    }
  }
  /**
   * With prefiltered texture, defined if the specular generation is based on a linear ramp.
   * By default we are using a log2 of the linear roughness helping to keep a better resolution for
   * average roughness values.
   */
  get linearSpecularLOD() {
    if (this._texture) {
      return this._texture._linearSpecularLOD;
    }
    return false;
  }
  set linearSpecularLOD(value) {
    if (this._texture) {
      this._texture._linearSpecularLOD = value;
    }
  }
  /**
   * In case a better definition than spherical harmonics is required for the diffuse part of the environment.
   * You can set the irradiance texture to rely on a texture instead of the spherical approach.
   * This texture need to have the same characteristics than its parent (Cube vs 2d, coordinates mode, Gamma/Linear, RGBD).
   */
  get irradianceTexture() {
    if (this._texture) {
      return this._texture._irradianceTexture;
    }
    return null;
  }
  set irradianceTexture(value) {
    if (this._texture) {
      this._texture._irradianceTexture = value;
    }
  }
  /**
   * Define the unique id of the texture in the scene.
   */
  get uid() {
    if (!this._uid) {
      this._uid = RandomGUID();
    }
    return this._uid;
  }
  /**
   * Return a string representation of the texture.
   * @returns the texture as a string
   */
  toString() {
    return this.name;
  }
  /**
   * Get the class name of the texture.
   * @returns "BaseTexture"
   */
  getClassName() {
    return "BaseTexture";
  }
  /**
   * Callback triggered when the texture has been disposed.
   * Kept for back compatibility, you can use the onDisposeObservable instead.
   */
  set onDispose(callback) {
    if (this._onDisposeObserver) {
      this.onDisposeObservable.remove(this._onDisposeObserver);
    }
    this._onDisposeObserver = this.onDisposeObservable.add(callback);
  }
  /**
   * Define if the texture is preventing a material to render or not.
   * If not and the texture is not ready, the engine will use a default black texture instead.
   */
  get isBlocking() {
    return true;
  }
  /**
   * Was there any loading error?
   */
  get loadingError() {
    return this._loadingError;
  }
  /**
   * If a loading error occurred this object will be populated with information about the error.
   */
  get errorObject() {
    return this._errorObject;
  }
  /**
   * Instantiates a new BaseTexture.
   * Base class of all the textures in babylon.
   * It groups all the common properties the materials, post process, lights... might need
   * in order to make a correct use of the texture.
   * @param sceneOrEngine Define the scene or engine the texture belongs to
   * @param internalTexture Define the internal texture associated with the texture
   */
  constructor(sceneOrEngine, internalTexture = null) {
    super(null);
    this.metadata = null;
    this.reservedDataStore = null;
    this._hasAlpha = false;
    this._getAlphaFromRGB = false;
    this.level = 1;
    this._coordinatesIndex = 0;
    this.optimizeUVAllocation = true;
    this._coordinatesMode = 0;
    this.wrapR = 1;
    this.anisotropicFilteringLevel = _BaseTexture.DEFAULT_ANISOTROPIC_FILTERING_LEVEL;
    this._isCube = false;
    this._gammaSpace = true;
    this.invertZ = false;
    this.lodLevelInAlpha = false;
    this.isRenderTarget = false;
    this._prefiltered = false;
    this._forceSerialize = false;
    this.animations = [];
    this.onDisposeObservable = new Observable();
    this._onDisposeObserver = null;
    this._scene = null;
    this._uid = null;
    this._parentContainer = null;
    this._loadingError = false;
    if (sceneOrEngine) {
      if (_BaseTexture._IsScene(sceneOrEngine)) {
        this._scene = sceneOrEngine;
      } else {
        this._engine = sceneOrEngine;
      }
    } else {
      this._scene = EngineStore.LastCreatedScene;
    }
    if (this._scene) {
      this.uniqueId = this._scene.getUniqueId();
      this._scene.addTexture(this);
      this._engine = this._scene.getEngine();
    }
    this._texture = internalTexture;
    this._uid = null;
  }
  /**
   * Get the scene the texture belongs to.
   * @returns the scene or null if undefined
   */
  getScene() {
    return this._scene;
  }
  /** @internal */
  _getEngine() {
    return this._engine;
  }
  /**
   * Get the texture transform matrix used to offset tile the texture for instance.
   * @returns the transformation matrix
   */
  getTextureMatrix() {
    return Matrix.IdentityReadOnly;
  }
  /**
   * Get the texture reflection matrix used to rotate/transform the reflection.
   * @returns the reflection matrix
   */
  getReflectionTextureMatrix() {
    return Matrix.IdentityReadOnly;
  }
  /**
   * Gets a suitable rotate/transform matrix when the texture is used for refraction.
   * There's a separate function from getReflectionTextureMatrix because refraction requires a special configuration of the matrix in right-handed mode.
   * @returns The refraction matrix
   */
  getRefractionTextureMatrix() {
    return this.getReflectionTextureMatrix();
  }
  /**
   * Get if the texture is ready to be consumed (either it is ready or it is not blocking)
   * @returns true if ready, not blocking or if there was an error loading the texture
   */
  isReadyOrNotBlocking() {
    return !this.isBlocking || this.isReady() || this.loadingError;
  }
  /**
   * Scales the texture if is `canRescale()`
   * @param ratio the resize factor we want to use to rescale
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  scale(ratio) {
  }
  /**
   * Get if the texture can rescale.
   */
  get canRescale() {
    return false;
  }
  /**
   * @internal
   */
  _getFromCache(url, noMipmap, sampling, invertY, useSRGBBuffer, isCube) {
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    const correctedUseSRGBBuffer = engine._getUseSRGBBuffer(!!useSRGBBuffer, noMipmap);
    const texturesCache = engine.getLoadedTexturesCache();
    for (let index = 0; index < texturesCache.length; index++) {
      const texturesCacheEntry = texturesCache[index];
      if (useSRGBBuffer === void 0 || correctedUseSRGBBuffer === texturesCacheEntry._useSRGBBuffer) {
        if (invertY === void 0 || invertY === texturesCacheEntry.invertY) {
          if (texturesCacheEntry.url === url && texturesCacheEntry.generateMipMaps === !noMipmap) {
            if (!sampling || sampling === texturesCacheEntry.samplingMode) {
              if (isCube === void 0 || isCube === texturesCacheEntry.isCube) {
                texturesCacheEntry.incrementReferences();
                return texturesCacheEntry;
              }
            }
          }
        }
      }
    }
    return null;
  }
  /** @internal */
  _rebuild(_fromContextLost = false) {
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    return null;
  }
  /**
   * Get the texture underlying type (INT, FLOAT...)
   */
  get textureType() {
    if (!this._texture) {
      return 0;
    }
    return this._texture.type !== void 0 ? this._texture.type : 0;
  }
  /**
   * Get the texture underlying format (RGB, RGBA...)
   */
  get textureFormat() {
    if (!this._texture) {
      return 5;
    }
    return this._texture.format !== void 0 ? this._texture.format : 5;
  }
  /**
   * Indicates that textures need to be re-calculated for all materials
   */
  _markAllSubMeshesAsTexturesDirty() {
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    scene.markAllMaterialsAsDirty(1);
  }
  /**
   * Reads the pixels stored in the webgl texture and returns them as an ArrayBuffer.
   * This will returns an RGBA array buffer containing either in values (0-255) or
   * float values (0-1) depending of the underlying buffer type.
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @param buffer defines a user defined buffer to fill with data (can be null)
   * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
   * @param noDataConversion false to convert the data to Uint8Array (if texture type is UNSIGNED_BYTE) or to Float32Array (if texture type is anything but UNSIGNED_BYTE). If true, the type of the generated buffer (if buffer==null) will depend on the type of the texture
   * @param x defines the region x coordinates to start reading from (default to 0)
   * @param y defines the region y coordinates to start reading from (default to 0)
   * @param width defines the region width to read from (default to the texture size at level)
   * @param height defines the region width to read from (default to the texture size at level)
   * @returns The Array buffer promise containing the pixels data.
   */
  readPixels(faceIndex = 0, level = 0, buffer = null, flushRenderer = true, noDataConversion = false, x = 0, y = 0, width = Number.MAX_VALUE, height = Number.MAX_VALUE) {
    if (!this._texture) {
      return null;
    }
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    const size = this.getSize();
    let maxWidth = size.width;
    let maxHeight = size.height;
    if (level !== 0) {
      maxWidth = maxWidth / Math.pow(2, level);
      maxHeight = maxHeight / Math.pow(2, level);
      maxWidth = Math.round(maxWidth);
      maxHeight = Math.round(maxHeight);
    }
    width = Math.min(maxWidth, width);
    height = Math.min(maxHeight, height);
    try {
      if (this._texture.isCube) {
        return engine._readTexturePixels(this._texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion, x, y);
      }
      return engine._readTexturePixels(this._texture, width, height, -1, level, buffer, flushRenderer, noDataConversion, x, y);
    } catch (e) {
      return null;
    }
  }
  /**
   * @internal
   */
  _readPixelsSync(faceIndex = 0, level = 0, buffer = null, flushRenderer = true, noDataConversion = false) {
    if (!this._texture) {
      return null;
    }
    const size = this.getSize();
    let width = size.width;
    let height = size.height;
    const engine = this._getEngine();
    if (!engine) {
      return null;
    }
    if (level != 0) {
      width = width / Math.pow(2, level);
      height = height / Math.pow(2, level);
      width = Math.round(width);
      height = Math.round(height);
    }
    try {
      if (this._texture.isCube) {
        return engine._readTexturePixelsSync(this._texture, width, height, faceIndex, level, buffer, flushRenderer, noDataConversion);
      }
      return engine._readTexturePixelsSync(this._texture, width, height, -1, level, buffer, flushRenderer, noDataConversion);
    } catch (e) {
      return null;
    }
  }
  /** @internal */
  get _lodTextureHigh() {
    if (this._texture) {
      return this._texture._lodTextureHigh;
    }
    return null;
  }
  /** @internal */
  get _lodTextureMid() {
    if (this._texture) {
      return this._texture._lodTextureMid;
    }
    return null;
  }
  /** @internal */
  get _lodTextureLow() {
    if (this._texture) {
      return this._texture._lodTextureLow;
    }
    return null;
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    if (this._scene) {
      if (this._scene.stopAnimation) {
        this._scene.stopAnimation(this);
      }
      this._scene.removePendingData(this);
      const index = this._scene.textures.indexOf(this);
      if (index >= 0) {
        this._scene.textures.splice(index, 1);
      }
      this._scene.onTextureRemovedObservable.notifyObservers(this);
      this._scene = null;
      if (this._parentContainer) {
        const index2 = this._parentContainer.textures.indexOf(this);
        if (index2 > -1) {
          this._parentContainer.textures.splice(index2, 1);
        }
        this._parentContainer = null;
      }
    }
    this.onDisposeObservable.notifyObservers(this);
    this.onDisposeObservable.clear();
    this.metadata = null;
    super.dispose();
  }
  /**
   * Serialize the texture into a JSON representation that can be parsed later on.
   * @param allowEmptyName True to force serialization even if name is empty. Default: false
   * @returns the JSON representation of the texture
   */
  serialize(allowEmptyName = false) {
    if (!this.name && !allowEmptyName) {
      return null;
    }
    const serializationObject = SerializationHelper.Serialize(this);
    SerializationHelper.AppendSerializedAnimations(this, serializationObject);
    return serializationObject;
  }
  /**
   * Helper function to be called back once a list of texture contains only ready textures.
   * @param textures Define the list of textures to wait for
   * @param callback Define the callback triggered once the entire list will be ready
   */
  static WhenAllReady(textures, callback) {
    let numRemaining = textures.length;
    if (numRemaining === 0) {
      callback();
      return;
    }
    for (let i = 0; i < textures.length; i++) {
      const texture = textures[i];
      if (texture.isReady()) {
        if (--numRemaining === 0) {
          callback();
        }
      } else {
        const onLoadObservable = texture.onLoadObservable;
        if (onLoadObservable) {
          onLoadObservable.addOnce(() => {
            if (--numRemaining === 0) {
              callback();
            }
          });
        } else {
          if (--numRemaining === 0) {
            callback();
          }
        }
      }
    }
  }
  static _IsScene(sceneOrEngine) {
    return sceneOrEngine.getClassName() === "Scene";
  }
};
BaseTexture.DEFAULT_ANISOTROPIC_FILTERING_LEVEL = 4;
__decorate([
  serialize()
], BaseTexture.prototype, "uniqueId", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "name", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "displayName", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "metadata", void 0);
__decorate([
  serialize("hasAlpha")
], BaseTexture.prototype, "_hasAlpha", void 0);
__decorate([
  serialize("getAlphaFromRGB")
], BaseTexture.prototype, "_getAlphaFromRGB", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "level", void 0);
__decorate([
  serialize("coordinatesIndex")
], BaseTexture.prototype, "_coordinatesIndex", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "optimizeUVAllocation", void 0);
__decorate([
  serialize("coordinatesMode")
], BaseTexture.prototype, "_coordinatesMode", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapU", null);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapV", null);
__decorate([
  serialize()
], BaseTexture.prototype, "wrapR", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "anisotropicFilteringLevel", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "isCube", null);
__decorate([
  serialize()
], BaseTexture.prototype, "is3D", null);
__decorate([
  serialize()
], BaseTexture.prototype, "is2DArray", null);
__decorate([
  serialize()
], BaseTexture.prototype, "gammaSpace", null);
__decorate([
  serialize()
], BaseTexture.prototype, "invertZ", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "lodLevelInAlpha", void 0);
__decorate([
  serialize()
], BaseTexture.prototype, "lodGenerationOffset", null);
__decorate([
  serialize()
], BaseTexture.prototype, "lodGenerationScale", null);
__decorate([
  serialize()
], BaseTexture.prototype, "linearSpecularLOD", null);
__decorate([
  serializeAsTexture()
], BaseTexture.prototype, "irradianceTexture", null);
__decorate([
  serialize()
], BaseTexture.prototype, "isRenderTarget", void 0);

// node_modules/@babylonjs/core/Misc/copyTools.js
function GenerateBase64StringFromPixelData(pixels, size, invertY = false) {
  const width = size.width;
  const height = size.height;
  if (pixels instanceof Float32Array) {
    let len = pixels.byteLength / pixels.BYTES_PER_ELEMENT;
    const npixels = new Uint8Array(len);
    while (--len >= 0) {
      let val = pixels[len];
      if (val < 0) {
        val = 0;
      } else if (val > 1) {
        val = 1;
      }
      npixels[len] = val * 255;
    }
    pixels = npixels;
  }
  const canvas = document.createElement("canvas");
  canvas.width = width;
  canvas.height = height;
  const ctx = canvas.getContext("2d");
  if (!ctx) {
    return null;
  }
  const imageData = ctx.createImageData(width, height);
  const castData = imageData.data;
  castData.set(pixels);
  ctx.putImageData(imageData, 0, 0);
  if (invertY) {
    const canvas2 = document.createElement("canvas");
    canvas2.width = width;
    canvas2.height = height;
    const ctx2 = canvas2.getContext("2d");
    if (!ctx2) {
      return null;
    }
    ctx2.translate(0, height);
    ctx2.scale(1, -1);
    ctx2.drawImage(canvas, 0, 0);
    return canvas2.toDataURL("image/png");
  }
  return canvas.toDataURL("image/png");
}
function GenerateBase64StringFromTexture(texture, faceIndex = 0, level = 0) {
  const internalTexture = texture.getInternalTexture();
  if (!internalTexture) {
    return null;
  }
  const pixels = texture._readPixelsSync(faceIndex, level);
  if (!pixels) {
    return null;
  }
  return GenerateBase64StringFromPixelData(pixels, texture.getSize(), internalTexture.invertY);
}
async function GenerateBase64StringFromTextureAsync(texture, faceIndex = 0, level = 0) {
  const internalTexture = texture.getInternalTexture();
  if (!internalTexture) {
    return null;
  }
  const pixels = await texture.readPixels(faceIndex, level);
  if (!pixels) {
    return null;
  }
  return GenerateBase64StringFromPixelData(pixels, texture.getSize(), internalTexture.invertY);
}
var CopyTools = {
  /**
   * Transform some pixel data to a base64 string
   * @param pixels defines the pixel data to transform to base64
   * @param size defines the width and height of the (texture) data
   * @param invertY true if the data must be inverted for the Y coordinate during the conversion
   * @returns The base64 encoded string or null
   */
  GenerateBase64StringFromPixelData,
  /**
   * Reads the pixels stored in the webgl texture and returns them as a base64 string
   * @param texture defines the texture to read pixels from
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @returns The base64 encoded string or null
   */
  GenerateBase64StringFromTexture,
  /**
   * Reads the pixels stored in the webgl texture and returns them as a base64 string
   * @param texture defines the texture to read pixels from
   * @param faceIndex defines the face of the texture to read (in case of cube texture)
   * @param level defines the LOD level of the texture to read (in case of Mip Maps)
   * @returns The base64 encoded string or null wrapped in a promise
   */
  GenerateBase64StringFromTextureAsync
};

// node_modules/@babylonjs/core/Compat/compatibilityOptions.js
var useOpenGLOrientationForUV = false;
function setOpenGLOrientationForUV(value) {
  useOpenGLOrientationForUV = value;
}
var CompatibilityOptions = {
  /* eslint-disable @typescript-eslint/naming-convention */
  get UseOpenGLOrientationForUV() {
    return useOpenGLOrientationForUV;
  },
  set UseOpenGLOrientationForUV(value) {
    useOpenGLOrientationForUV = value;
  }
  /* eslint-enable @typescript-eslint/naming-convention */
};

// node_modules/@babylonjs/core/Materials/Textures/texture.js
var Texture = class _Texture extends BaseTexture {
  /**
   * @internal
   */
  static _CreateVideoTexture(name, src, scene, generateMipMaps = false, invertY = false, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, settings = {}, onError, format = 5) {
    throw _WarnImport("VideoTexture");
  }
  /**
   * Are mip maps generated for this texture or not.
   */
  get noMipmap() {
    return this._noMipmap;
  }
  /** Returns the texture mime type if it was defined by a loader (undefined else) */
  get mimeType() {
    return this._mimeType;
  }
  /**
   * Is the texture preventing material to render while loading.
   * If false, a default texture will be used instead of the loading one during the preparation step.
   */
  set isBlocking(value) {
    this._isBlocking = value;
  }
  get isBlocking() {
    return this._isBlocking;
  }
  /**
   * Gets a boolean indicating if the texture needs to be inverted on the y axis during loading
   */
  get invertY() {
    return this._invertY;
  }
  /**
   * Instantiates a new texture.
   * This represents a texture in babylon. It can be easily loaded from a network, base64 or html input.
   * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#texture
   * @param url defines the url of the picture to load as a texture
   * @param sceneOrEngine defines the scene or engine the texture will belong to
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY defines if the texture needs to be inverted on the y axis during loading
   * @param samplingMode defines the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad defines a callback triggered when the texture has been loaded
   * @param onError defines a callback triggered when an error occurred during the loading session
   * @param buffer defines the buffer to load the texture from in case the texture is loaded from a buffer representation
   * @param deleteBuffer defines if the buffer we are loading the texture from should be deleted after load
   * @param format defines the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param mimeType defines an optional mime type information
   * @param loaderOptions options to be passed to the loader
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @param forcedExtension defines the extension to use to pick the right loader
   */
  constructor(url, sceneOrEngine, noMipmapOrOptions, invertY, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, buffer = null, deleteBuffer = false, format, mimeType, loaderOptions, creationFlags, forcedExtension) {
    super(sceneOrEngine);
    this.url = null;
    this.uOffset = 0;
    this.vOffset = 0;
    this.uScale = 1;
    this.vScale = 1;
    this.uAng = 0;
    this.vAng = 0;
    this.wAng = 0;
    this.uRotationCenter = 0.5;
    this.vRotationCenter = 0.5;
    this.wRotationCenter = 0.5;
    this.homogeneousRotationInUVTransform = false;
    this.inspectableCustomProperties = null;
    this._noMipmap = false;
    this._invertY = false;
    this._rowGenerationMatrix = null;
    this._cachedTextureMatrix = null;
    this._projectionModeMatrix = null;
    this._t0 = null;
    this._t1 = null;
    this._t2 = null;
    this._cachedUOffset = -1;
    this._cachedVOffset = -1;
    this._cachedUScale = 0;
    this._cachedVScale = 0;
    this._cachedUAng = -1;
    this._cachedVAng = -1;
    this._cachedWAng = -1;
    this._cachedReflectionProjectionMatrixId = -1;
    this._cachedURotationCenter = -1;
    this._cachedVRotationCenter = -1;
    this._cachedWRotationCenter = -1;
    this._cachedHomogeneousRotationInUVTransform = false;
    this._cachedIdentity3x2 = true;
    this._cachedReflectionTextureMatrix = null;
    this._cachedReflectionUOffset = -1;
    this._cachedReflectionVOffset = -1;
    this._cachedReflectionUScale = 0;
    this._cachedReflectionVScale = 0;
    this._cachedReflectionCoordinatesMode = -1;
    this._buffer = null;
    this._deleteBuffer = false;
    this._format = null;
    this._delayedOnLoad = null;
    this._delayedOnError = null;
    this.onLoadObservable = new Observable();
    this._isBlocking = true;
    this.name = url || "";
    this.url = url;
    let noMipmap;
    let useSRGBBuffer = false;
    let internalTexture = null;
    let gammaSpace = true;
    if (typeof noMipmapOrOptions === "object" && noMipmapOrOptions !== null) {
      noMipmap = noMipmapOrOptions.noMipmap ?? false;
      invertY = noMipmapOrOptions.invertY ?? !useOpenGLOrientationForUV;
      samplingMode = noMipmapOrOptions.samplingMode ?? _Texture.TRILINEAR_SAMPLINGMODE;
      onLoad = noMipmapOrOptions.onLoad ?? null;
      onError = noMipmapOrOptions.onError ?? null;
      buffer = noMipmapOrOptions.buffer ?? null;
      deleteBuffer = noMipmapOrOptions.deleteBuffer ?? false;
      format = noMipmapOrOptions.format;
      mimeType = noMipmapOrOptions.mimeType;
      loaderOptions = noMipmapOrOptions.loaderOptions;
      creationFlags = noMipmapOrOptions.creationFlags;
      useSRGBBuffer = noMipmapOrOptions.useSRGBBuffer ?? false;
      internalTexture = noMipmapOrOptions.internalTexture ?? null;
      gammaSpace = noMipmapOrOptions.gammaSpace ?? gammaSpace;
      forcedExtension = noMipmapOrOptions.forcedExtension ?? forcedExtension;
    } else {
      noMipmap = !!noMipmapOrOptions;
    }
    this._gammaSpace = gammaSpace;
    this._noMipmap = noMipmap;
    this._invertY = invertY === void 0 ? !useOpenGLOrientationForUV : invertY;
    this._initialSamplingMode = samplingMode;
    this._buffer = buffer;
    this._deleteBuffer = deleteBuffer;
    this._mimeType = mimeType;
    this._loaderOptions = loaderOptions;
    this._creationFlags = creationFlags;
    this._useSRGBBuffer = useSRGBBuffer;
    this._forcedExtension = forcedExtension;
    if (format) {
      this._format = format;
    }
    const scene = this.getScene();
    const engine = this._getEngine();
    if (!engine) {
      return;
    }
    engine.onBeforeTextureInitObservable.notifyObservers(this);
    const load = () => {
      if (this._texture) {
        if (this._texture._invertVScale) {
          this.vScale *= -1;
          this.vOffset += 1;
        }
        if (this._texture._cachedWrapU !== null) {
          this.wrapU = this._texture._cachedWrapU;
          this._texture._cachedWrapU = null;
        }
        if (this._texture._cachedWrapV !== null) {
          this.wrapV = this._texture._cachedWrapV;
          this._texture._cachedWrapV = null;
        }
        if (this._texture._cachedWrapR !== null) {
          this.wrapR = this._texture._cachedWrapR;
          this._texture._cachedWrapR = null;
        }
      }
      if (this.onLoadObservable.hasObservers()) {
        this.onLoadObservable.notifyObservers(this);
      }
      if (onLoad) {
        onLoad();
      }
      if (!this.isBlocking && scene) {
        scene.resetCachedMaterial();
      }
    };
    const errorHandler = (message, exception) => {
      this._loadingError = true;
      this._errorObject = { message, exception };
      if (onError) {
        onError(message, exception);
      }
      _Texture.OnTextureLoadErrorObservable.notifyObservers(this);
    };
    if (!this.url && !internalTexture) {
      this._delayedOnLoad = load;
      this._delayedOnError = errorHandler;
      return;
    }
    this._texture = internalTexture ?? this._getFromCache(this.url, noMipmap, samplingMode, this._invertY, useSRGBBuffer, this.isCube);
    if (!this._texture) {
      if (!scene || !scene.useDelayedTextureLoading) {
        try {
          this._texture = engine.createTexture(this.url, noMipmap, this._invertY, scene, samplingMode, load, errorHandler, this._buffer, void 0, this._format, this._forcedExtension, mimeType, loaderOptions, creationFlags, useSRGBBuffer);
        } catch (e) {
          errorHandler("error loading", e);
          throw e;
        }
        if (deleteBuffer) {
          this._buffer = null;
        }
      } else {
        this.delayLoadState = 4;
        this._delayedOnLoad = load;
        this._delayedOnError = errorHandler;
      }
    } else {
      if (this._texture.isReady) {
        TimingTools.SetImmediate(() => load());
      } else {
        const loadObserver = this._texture.onLoadedObservable.add(load);
        this._texture.onErrorObservable.add((e) => {
          var _a;
          errorHandler(e.message, e.exception);
          (_a = this._texture) == null ? void 0 : _a.onLoadedObservable.remove(loadObserver);
        });
      }
    }
  }
  /**
   * Update the url (and optional buffer) of this texture if url was null during construction.
   * @param url the url of the texture
   * @param buffer the buffer of the texture (defaults to null)
   * @param onLoad callback called when the texture is loaded  (defaults to null)
   * @param forcedExtension defines the extension to use to pick the right loader
   */
  updateURL(url, buffer = null, onLoad, forcedExtension) {
    if (this.url) {
      this.releaseInternalTexture();
      this.getScene().markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    if (!this.name || this.name.startsWith("data:")) {
      this.name = url;
    }
    this.url = url;
    this._buffer = buffer;
    this._forcedExtension = forcedExtension;
    this.delayLoadState = 4;
    if (onLoad) {
      this._delayedOnLoad = onLoad;
    }
    this.delayLoad();
  }
  /**
   * Finish the loading sequence of a texture flagged as delayed load.
   * @internal
   */
  delayLoad() {
    if (this.delayLoadState !== 4) {
      return;
    }
    const scene = this.getScene();
    if (!scene) {
      return;
    }
    this.delayLoadState = 1;
    this._texture = this._getFromCache(this.url, this._noMipmap, this.samplingMode, this._invertY, this._useSRGBBuffer, this.isCube);
    if (!this._texture) {
      this._texture = scene.getEngine().createTexture(this.url, this._noMipmap, this._invertY, scene, this.samplingMode, this._delayedOnLoad, this._delayedOnError, this._buffer, null, this._format, this._forcedExtension, this._mimeType, this._loaderOptions, this._creationFlags, this._useSRGBBuffer);
      if (this._deleteBuffer) {
        this._buffer = null;
      }
    } else {
      if (this._delayedOnLoad) {
        if (this._texture.isReady) {
          TimingTools.SetImmediate(this._delayedOnLoad);
        } else {
          this._texture.onLoadedObservable.add(this._delayedOnLoad);
        }
      }
    }
    this._delayedOnLoad = null;
    this._delayedOnError = null;
  }
  _prepareRowForTextureGeneration(x, y, z, t) {
    x *= this._cachedUScale;
    y *= this._cachedVScale;
    x -= this.uRotationCenter * this._cachedUScale;
    y -= this.vRotationCenter * this._cachedVScale;
    z -= this.wRotationCenter;
    Vector3.TransformCoordinatesFromFloatsToRef(x, y, z, this._rowGenerationMatrix, t);
    t.x += this.uRotationCenter * this._cachedUScale + this._cachedUOffset;
    t.y += this.vRotationCenter * this._cachedVScale + this._cachedVOffset;
    t.z += this.wRotationCenter;
  }
  /**
   * Get the current texture matrix which includes the requested offsetting, tiling and rotation components.
   * @param uBase The horizontal base offset multiplier (1 by default)
   * @returns the transform matrix of the texture.
   */
  getTextureMatrix(uBase = 1) {
    if (this.uOffset === this._cachedUOffset && this.vOffset === this._cachedVOffset && this.uScale * uBase === this._cachedUScale && this.vScale === this._cachedVScale && this.uAng === this._cachedUAng && this.vAng === this._cachedVAng && this.wAng === this._cachedWAng && this.uRotationCenter === this._cachedURotationCenter && this.vRotationCenter === this._cachedVRotationCenter && this.wRotationCenter === this._cachedWRotationCenter && this.homogeneousRotationInUVTransform === this._cachedHomogeneousRotationInUVTransform) {
      return this._cachedTextureMatrix;
    }
    this._cachedUOffset = this.uOffset;
    this._cachedVOffset = this.vOffset;
    this._cachedUScale = this.uScale * uBase;
    this._cachedVScale = this.vScale;
    this._cachedUAng = this.uAng;
    this._cachedVAng = this.vAng;
    this._cachedWAng = this.wAng;
    this._cachedURotationCenter = this.uRotationCenter;
    this._cachedVRotationCenter = this.vRotationCenter;
    this._cachedWRotationCenter = this.wRotationCenter;
    this._cachedHomogeneousRotationInUVTransform = this.homogeneousRotationInUVTransform;
    if (!this._cachedTextureMatrix || !this._rowGenerationMatrix) {
      this._cachedTextureMatrix = Matrix.Zero();
      this._rowGenerationMatrix = new Matrix();
      this._t0 = Vector3.Zero();
      this._t1 = Vector3.Zero();
      this._t2 = Vector3.Zero();
    }
    Matrix.RotationYawPitchRollToRef(this.vAng, this.uAng, this.wAng, this._rowGenerationMatrix);
    if (this.homogeneousRotationInUVTransform) {
      Matrix.TranslationToRef(-this._cachedURotationCenter, -this._cachedVRotationCenter, -this._cachedWRotationCenter, TmpVectors.Matrix[0]);
      Matrix.TranslationToRef(this._cachedURotationCenter, this._cachedVRotationCenter, this._cachedWRotationCenter, TmpVectors.Matrix[1]);
      Matrix.ScalingToRef(this._cachedUScale, this._cachedVScale, 0, TmpVectors.Matrix[2]);
      Matrix.TranslationToRef(this._cachedUOffset, this._cachedVOffset, 0, TmpVectors.Matrix[3]);
      TmpVectors.Matrix[0].multiplyToRef(this._rowGenerationMatrix, this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[1], this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[2], this._cachedTextureMatrix);
      this._cachedTextureMatrix.multiplyToRef(TmpVectors.Matrix[3], this._cachedTextureMatrix);
      this._cachedTextureMatrix.setRowFromFloats(2, this._cachedTextureMatrix.m[12], this._cachedTextureMatrix.m[13], this._cachedTextureMatrix.m[14], 1);
    } else {
      this._prepareRowForTextureGeneration(0, 0, 0, this._t0);
      this._prepareRowForTextureGeneration(1, 0, 0, this._t1);
      this._prepareRowForTextureGeneration(0, 1, 0, this._t2);
      this._t1.subtractInPlace(this._t0);
      this._t2.subtractInPlace(this._t0);
      Matrix.FromValuesToRef(this._t1.x, this._t1.y, this._t1.z, 0, this._t2.x, this._t2.y, this._t2.z, 0, this._t0.x, this._t0.y, this._t0.z, 0, 0, 0, 0, 1, this._cachedTextureMatrix);
    }
    const scene = this.getScene();
    if (!scene) {
      return this._cachedTextureMatrix;
    }
    const previousIdentity3x2 = this._cachedIdentity3x2;
    this._cachedIdentity3x2 = this._cachedTextureMatrix.isIdentityAs3x2();
    if (this.optimizeUVAllocation && previousIdentity3x2 !== this._cachedIdentity3x2) {
      scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    return this._cachedTextureMatrix;
  }
  /**
   * Get the current matrix used to apply reflection. This is useful to rotate an environment texture for instance.
   * @returns The reflection texture transform
   */
  getReflectionTextureMatrix() {
    const scene = this.getScene();
    if (!scene) {
      return this._cachedReflectionTextureMatrix;
    }
    if (this.uOffset === this._cachedReflectionUOffset && this.vOffset === this._cachedReflectionVOffset && this.uScale === this._cachedReflectionUScale && this.vScale === this._cachedReflectionVScale && this.coordinatesMode === this._cachedReflectionCoordinatesMode) {
      if (this.coordinatesMode === _Texture.PROJECTION_MODE) {
        if (this._cachedReflectionProjectionMatrixId === scene.getProjectionMatrix().updateFlag) {
          return this._cachedReflectionTextureMatrix;
        }
      } else {
        return this._cachedReflectionTextureMatrix;
      }
    }
    if (!this._cachedReflectionTextureMatrix) {
      this._cachedReflectionTextureMatrix = Matrix.Zero();
    }
    if (!this._projectionModeMatrix) {
      this._projectionModeMatrix = Matrix.Zero();
    }
    const flagMaterialsAsTextureDirty = this._cachedReflectionCoordinatesMode !== this.coordinatesMode;
    this._cachedReflectionUOffset = this.uOffset;
    this._cachedReflectionVOffset = this.vOffset;
    this._cachedReflectionUScale = this.uScale;
    this._cachedReflectionVScale = this.vScale;
    this._cachedReflectionCoordinatesMode = this.coordinatesMode;
    switch (this.coordinatesMode) {
      case _Texture.PLANAR_MODE: {
        Matrix.IdentityToRef(this._cachedReflectionTextureMatrix);
        this._cachedReflectionTextureMatrix[0] = this.uScale;
        this._cachedReflectionTextureMatrix[5] = this.vScale;
        this._cachedReflectionTextureMatrix[12] = this.uOffset;
        this._cachedReflectionTextureMatrix[13] = this.vOffset;
        break;
      }
      case _Texture.PROJECTION_MODE: {
        Matrix.FromValuesToRef(0.5, 0, 0, 0, 0, -0.5, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, this._projectionModeMatrix);
        const projectionMatrix = scene.getProjectionMatrix();
        this._cachedReflectionProjectionMatrixId = projectionMatrix.updateFlag;
        projectionMatrix.multiplyToRef(this._projectionModeMatrix, this._cachedReflectionTextureMatrix);
        break;
      }
      default:
        Matrix.IdentityToRef(this._cachedReflectionTextureMatrix);
        break;
    }
    if (flagMaterialsAsTextureDirty) {
      scene.markAllMaterialsAsDirty(1, (mat) => {
        return mat.hasTexture(this);
      });
    }
    return this._cachedReflectionTextureMatrix;
  }
  /**
   * Clones the texture.
   * @returns the cloned texture
   */
  clone() {
    const options = {
      noMipmap: this._noMipmap,
      invertY: this._invertY,
      samplingMode: this.samplingMode,
      onLoad: void 0,
      onError: void 0,
      buffer: this._texture ? this._texture._buffer : void 0,
      deleteBuffer: this._deleteBuffer,
      format: this.textureFormat,
      mimeType: this.mimeType,
      loaderOptions: this._loaderOptions,
      creationFlags: this._creationFlags,
      useSRGBBuffer: this._useSRGBBuffer
    };
    return SerializationHelper.Clone(() => {
      return new _Texture(this._texture ? this._texture.url : null, this.getScene(), options);
    }, this);
  }
  /**
   * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
   * @returns The JSON representation of the texture
   */
  serialize() {
    var _a, _b;
    const savedName = this.name;
    if (!_Texture.SerializeBuffers) {
      if (this.name.startsWith("data:")) {
        this.name = "";
      }
    }
    if (this.name.startsWith("data:") && this.url === this.name) {
      this.url = "";
    }
    const serializationObject = super.serialize(_Texture._SerializeInternalTextureUniqueId);
    if (!serializationObject) {
      return null;
    }
    if (_Texture.SerializeBuffers || _Texture.ForceSerializeBuffers) {
      if (typeof this._buffer === "string" && this._buffer.substring(0, 5) === "data:") {
        serializationObject.base64String = this._buffer;
        serializationObject.name = serializationObject.name.replace("data:", "");
      } else if (this.url && this.url.startsWith("data:") && this._buffer instanceof Uint8Array) {
        serializationObject.base64String = "data:image/png;base64," + EncodeArrayBufferToBase64(this._buffer);
      } else if (_Texture.ForceSerializeBuffers || this.url && this.url.startsWith("blob:") || this._forceSerialize) {
        serializationObject.base64String = !this._engine || this._engine._features.supportSyncTextureRead ? GenerateBase64StringFromTexture(this) : GenerateBase64StringFromTextureAsync(this);
      }
    }
    serializationObject.invertY = this._invertY;
    serializationObject.samplingMode = this.samplingMode;
    serializationObject._creationFlags = this._creationFlags;
    serializationObject._useSRGBBuffer = this._useSRGBBuffer;
    if (_Texture._SerializeInternalTextureUniqueId) {
      serializationObject.internalTextureUniqueId = (_a = this._texture) == null ? void 0 : _a.uniqueId;
    }
    serializationObject.internalTextureLabel = (_b = this._texture) == null ? void 0 : _b.label;
    serializationObject.noMipmap = this._noMipmap;
    this.name = savedName;
    return serializationObject;
  }
  /**
   * Get the current class name of the texture useful for serialization or dynamic coding.
   * @returns "Texture"
   */
  getClassName() {
    return "Texture";
  }
  /**
   * Dispose the texture and release its associated resources.
   */
  dispose() {
    super.dispose();
    this.onLoadObservable.clear();
    this._delayedOnLoad = null;
    this._delayedOnError = null;
    this._buffer = null;
  }
  /**
   * Parse the JSON representation of a texture in order to recreate the texture in the given scene.
   * @param parsedTexture Define the JSON representation of the texture
   * @param scene Define the scene the parsed texture should be instantiated in
   * @param rootUrl Define the root url of the parsing sequence in the case of relative dependencies
   * @returns The parsed texture if successful
   */
  static Parse(parsedTexture, scene, rootUrl) {
    if (parsedTexture.customType) {
      const customTexture = InstantiationTools.Instantiate(parsedTexture.customType);
      const parsedCustomTexture = customTexture.Parse(parsedTexture, scene, rootUrl);
      if (parsedTexture.samplingMode && parsedCustomTexture.updateSamplingMode && parsedCustomTexture._samplingMode) {
        if (parsedCustomTexture._samplingMode !== parsedTexture.samplingMode) {
          parsedCustomTexture.updateSamplingMode(parsedTexture.samplingMode);
        }
      }
      return parsedCustomTexture;
    }
    if (parsedTexture.isCube && !parsedTexture.isRenderTarget) {
      return _Texture._CubeTextureParser(parsedTexture, scene, rootUrl);
    }
    const hasInternalTextureUniqueId = parsedTexture.internalTextureUniqueId !== void 0;
    if (!parsedTexture.name && !parsedTexture.isRenderTarget && !hasInternalTextureUniqueId) {
      return null;
    }
    let internalTexture;
    if (hasInternalTextureUniqueId) {
      const cache = scene.getEngine().getLoadedTexturesCache();
      for (const texture2 of cache) {
        if (texture2.uniqueId === parsedTexture.internalTextureUniqueId) {
          internalTexture = texture2;
          break;
        }
      }
    }
    const onLoaded = (texture2) => {
      if (texture2 && texture2._texture) {
        texture2._texture._cachedWrapU = null;
        texture2._texture._cachedWrapV = null;
        texture2._texture._cachedWrapR = null;
      }
      if (parsedTexture.samplingMode) {
        const sampling = parsedTexture.samplingMode;
        if (texture2 && texture2.samplingMode !== sampling) {
          texture2.updateSamplingMode(sampling);
        }
      }
      if (texture2 && parsedTexture.animations) {
        for (let animationIndex = 0; animationIndex < parsedTexture.animations.length; animationIndex++) {
          const parsedAnimation = parsedTexture.animations[animationIndex];
          const internalClass = GetClass("BABYLON.Animation");
          if (internalClass) {
            texture2.animations.push(internalClass.Parse(parsedAnimation));
          }
        }
      }
      if (texture2 && texture2._texture) {
        if (hasInternalTextureUniqueId && !internalTexture) {
          texture2._texture._setUniqueId(parsedTexture.internalTextureUniqueId);
        }
        texture2._texture.label = parsedTexture.internalTextureLabel;
      }
    };
    const texture = SerializationHelper.Parse(() => {
      let generateMipMaps = true;
      if (parsedTexture.noMipmap) {
        generateMipMaps = false;
      }
      if (parsedTexture.mirrorPlane) {
        const mirrorTexture = _Texture._CreateMirror(parsedTexture.name, parsedTexture.renderTargetSize, scene, generateMipMaps);
        mirrorTexture._waitingRenderList = parsedTexture.renderList;
        mirrorTexture.mirrorPlane = Plane.FromArray(parsedTexture.mirrorPlane);
        onLoaded(mirrorTexture);
        return mirrorTexture;
      } else if (parsedTexture.isRenderTarget) {
        let renderTargetTexture = null;
        if (parsedTexture.isCube) {
          if (scene.reflectionProbes) {
            for (let index = 0; index < scene.reflectionProbes.length; index++) {
              const probe = scene.reflectionProbes[index];
              if (probe.name === parsedTexture.name) {
                return probe.cubeTexture;
              }
            }
          }
        } else {
          renderTargetTexture = _Texture._CreateRenderTargetTexture(parsedTexture.name, parsedTexture.renderTargetSize, scene, generateMipMaps, parsedTexture._creationFlags ?? 0);
          renderTargetTexture._waitingRenderList = parsedTexture.renderList;
        }
        onLoaded(renderTargetTexture);
        return renderTargetTexture;
      } else if (parsedTexture.isVideo) {
        const texture2 = _Texture._CreateVideoTexture(rootUrl + (parsedTexture.url || parsedTexture.name), rootUrl + (parsedTexture.src || parsedTexture.url), scene, generateMipMaps, parsedTexture.invertY, parsedTexture.samplingMode, parsedTexture.settings || {});
        onLoaded(texture2);
        return texture2;
      } else {
        let texture2;
        if (parsedTexture.base64String && !internalTexture) {
          texture2 = _Texture.CreateFromBase64String(parsedTexture.base64String, parsedTexture.base64String, scene, !generateMipMaps, parsedTexture.invertY, parsedTexture.samplingMode, () => {
            onLoaded(texture2);
          }, parsedTexture._creationFlags ?? 0, parsedTexture._useSRGBBuffer ?? false);
          texture2.name = parsedTexture.name;
        } else {
          let url;
          if (parsedTexture.name && (parsedTexture.name.indexOf("://") > 0 || parsedTexture.name.startsWith("data:"))) {
            url = parsedTexture.name;
          } else {
            url = rootUrl + parsedTexture.name;
          }
          if (parsedTexture.url && (parsedTexture.url.startsWith("data:") || _Texture.UseSerializedUrlIfAny)) {
            url = parsedTexture.url;
          }
          const options = {
            noMipmap: !generateMipMaps,
            invertY: parsedTexture.invertY,
            samplingMode: parsedTexture.samplingMode,
            onLoad: () => {
              onLoaded(texture2);
            },
            internalTexture
          };
          texture2 = new _Texture(url, scene, options);
        }
        return texture2;
      }
    }, parsedTexture, scene);
    return texture;
  }
  /**
   * Creates a texture from its base 64 representation.
   * @param data Define the base64 payload without the data: prefix
   * @param name Define the name of the texture in the scene useful fo caching purpose for instance
   * @param scene Define the scene the texture should belong to
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY define if the texture needs to be inverted on the y axis during loading
   * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad define a callback triggered when the texture has been loaded
   * @param onError define a callback triggered when an error occurred during the loading session
   * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @param forcedExtension defines the extension to use to pick the right loader
   * @returns the created texture
   */
  static CreateFromBase64String(data, name, scene, noMipmapOrOptions, invertY, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, format = 5, creationFlags, forcedExtension) {
    return new _Texture("data:" + name, scene, noMipmapOrOptions, invertY, samplingMode, onLoad, onError, data, false, format, void 0, void 0, creationFlags, forcedExtension);
  }
  /**
   * Creates a texture from its data: representation. (data: will be added in case only the payload has been passed in)
   * @param name Define the name of the texture in the scene useful fo caching purpose for instance
   * @param buffer define the buffer to load the texture from in case the texture is loaded from a buffer representation
   * @param scene Define the scene the texture should belong to
   * @param deleteBuffer define if the buffer we are loading the texture from should be deleted after load
   * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
   * @param invertY define if the texture needs to be inverted on the y axis during loading
   * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
   * @param onLoad define a callback triggered when the texture has been loaded
   * @param onError define a callback triggered when an error occurred during the loading session
   * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
   * @param creationFlags specific flags to use when creating the texture (1 for storage textures, for eg)
   * @param forcedExtension defines the extension to use to pick the right loader
   * @returns the created texture
   */
  static LoadFromDataString(name, buffer, scene, deleteBuffer = false, noMipmapOrOptions, invertY = true, samplingMode = _Texture.TRILINEAR_SAMPLINGMODE, onLoad = null, onError = null, format = 5, creationFlags, forcedExtension) {
    if (name.substring(0, 5) !== "data:") {
      name = "data:" + name;
    }
    return new _Texture(name, scene, noMipmapOrOptions, invertY, samplingMode, onLoad, onError, buffer, deleteBuffer, format, void 0, void 0, creationFlags, forcedExtension);
  }
};
Texture.SerializeBuffers = true;
Texture.ForceSerializeBuffers = false;
Texture.OnTextureLoadErrorObservable = new Observable();
Texture._SerializeInternalTextureUniqueId = false;
Texture._CubeTextureParser = (jsonTexture, scene, rootUrl) => {
  throw _WarnImport("CubeTexture");
};
Texture._CreateMirror = (name, renderTargetSize, scene, generateMipMaps) => {
  throw _WarnImport("MirrorTexture");
};
Texture._CreateRenderTargetTexture = (name, renderTargetSize, scene, generateMipMaps, creationFlags) => {
  throw _WarnImport("RenderTargetTexture");
};
Texture.NEAREST_SAMPLINGMODE = 1;
Texture.NEAREST_NEAREST_MIPLINEAR = 8;
Texture.BILINEAR_SAMPLINGMODE = 2;
Texture.LINEAR_LINEAR_MIPNEAREST = 11;
Texture.TRILINEAR_SAMPLINGMODE = 3;
Texture.LINEAR_LINEAR_MIPLINEAR = 3;
Texture.NEAREST_NEAREST_MIPNEAREST = 4;
Texture.NEAREST_LINEAR_MIPNEAREST = 5;
Texture.NEAREST_LINEAR_MIPLINEAR = 6;
Texture.NEAREST_LINEAR = 7;
Texture.NEAREST_NEAREST = 1;
Texture.LINEAR_NEAREST_MIPNEAREST = 9;
Texture.LINEAR_NEAREST_MIPLINEAR = 10;
Texture.LINEAR_LINEAR = 2;
Texture.LINEAR_NEAREST = 12;
Texture.EXPLICIT_MODE = 0;
Texture.SPHERICAL_MODE = 1;
Texture.PLANAR_MODE = 2;
Texture.CUBIC_MODE = 3;
Texture.PROJECTION_MODE = 4;
Texture.SKYBOX_MODE = 5;
Texture.INVCUBIC_MODE = 6;
Texture.EQUIRECTANGULAR_MODE = 7;
Texture.FIXED_EQUIRECTANGULAR_MODE = 8;
Texture.FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
Texture.CLAMP_ADDRESSMODE = 0;
Texture.WRAP_ADDRESSMODE = 1;
Texture.MIRROR_ADDRESSMODE = 2;
Texture.UseSerializedUrlIfAny = false;
__decorate([
  serialize()
], Texture.prototype, "url", void 0);
__decorate([
  serialize()
], Texture.prototype, "uOffset", void 0);
__decorate([
  serialize()
], Texture.prototype, "vOffset", void 0);
__decorate([
  serialize()
], Texture.prototype, "uScale", void 0);
__decorate([
  serialize()
], Texture.prototype, "vScale", void 0);
__decorate([
  serialize()
], Texture.prototype, "uAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "vAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "wAng", void 0);
__decorate([
  serialize()
], Texture.prototype, "uRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "vRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "wRotationCenter", void 0);
__decorate([
  serialize()
], Texture.prototype, "homogeneousRotationInUVTransform", void 0);
__decorate([
  serialize()
], Texture.prototype, "isBlocking", null);
RegisterClass("BABYLON.Texture", Texture);
SerializationHelper._TextureParser = Texture.Parse;

export {
  AndOrNotEvaluator,
  Tags,
  SerializationHelper,
  Size,
  Plane,
  ThinTexture,
  BaseTexture,
  GenerateBase64StringFromPixelData,
  GenerateBase64StringFromTexture,
  GenerateBase64StringFromTextureAsync,
  CopyTools,
  useOpenGLOrientationForUV,
  setOpenGLOrientationForUV,
  CompatibilityOptions,
  Texture
};
//# sourceMappingURL=chunk-2TFE2SGV.js.map
